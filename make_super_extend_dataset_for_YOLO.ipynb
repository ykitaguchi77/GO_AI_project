{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOVDwhatwTzR4G7yfO49bCw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykitaguchi77/GO_AI_project/blob/main/make_super_extend_dataset_for_YOLO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Create extended dataset for YOLOv5 implementation**\n",
        "\n",
        "#Olympia\n",
        "ãƒ»Olympia dataset\n",
        "\n",
        "Treated 640px: 561æžšã€‚ãƒ†ã‚¹ãƒˆã«50æžšã‚’æ®‹ã™ï¼ˆtest_olympiaï¼‰ã€æ®‹ã‚Šã®511æžšã‚’train/valã«å›žã™\n",
        "\n",
        "Control 640px: 169æžšã€‚ãƒ†ã‚¹ãƒˆã«50æžšã‚’æ®‹ã™(test_control)ã€æ®‹ã‚Šã®119æžšã‚’train/valã«å›žã™\n",
        "\n",
        "#Handai\n",
        "ãƒ»GO_extended_dataset\n",
        "\n",
        "control: 1886æžšã€‚ãƒ†ã‚¹ãƒˆã«50æžšã‚’æ®‹ã™(test_handai)ã€æ®‹ã‚Šã®1836æžšã‚’train/valã«å›žã™\n",
        "\n",
        "treatable: 1879æžšã€‚ãƒ†ã‚¹ãƒˆã«50æžšã‚’æ®‹ã™(test_handai)ã€æ®‹ã‚Šã®1829æžšã‚’train/valã«å›žã™\n",
        "\n",
        "\n",
        "#åˆè¨ˆï¼š\n",
        "treatable: 1829 + 119\n",
        "\n",
        "control: 1836 + 511\n",
        "\n",
        "testset: Olympia treated 50, control 50, Handai treated 50, control 50\n",
        "\n",
        "##æ—¢å­˜ã®YOLOã§bounding boxã‚’ä½œæˆ --> classã¯æ—¢çŸ¥ã®ã‚‚ã®ã§ã€‚Glaucomaã®repositoryã‚’å‚è€ƒã«ã—ã¦YOLO datasetã‚’ä½œæˆã€‚"
      ],
      "metadata": {
        "id": "BW6BkO088P6u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ds7rvBFs8LcO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4dde21b-3249-4c49-d6de-9d2569c35e60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "import glob\n",
        "import random\n",
        "from PIL import Image\n",
        "import time\n",
        "%matplotlib inline\n",
        "\n",
        "#ã‚µãƒãƒ¼ãƒˆãƒ‘ãƒƒãƒã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "\n",
        "\n",
        "# Google Driveã‚’ãƒžã‚¦ãƒ³ãƒˆ\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ãƒ•ã‚¡ã‚¤ãƒ«æ•°ç¢ºèªç”¨\n",
        "import os\n",
        "\n",
        "def countfile(name, path):\n",
        "    print(f\"path: {path}\")\n",
        "    print(f\"number: {len(os.listdir(path))}\")\n",
        "    print(\"\")\n",
        "\n",
        "if not os.path.exists(\"/content/GO_extended_dataset\"):\n",
        "    !unzip /content/drive/MyDrive/Deep_learning/GO_extended_dataset/GO_extended_dataset.zip -d /content/\n",
        "\n",
        "\n",
        "olympia_cont_dir = \"/content/drive/MyDrive/Deep_learning/Olympia_dataset/control_640px\"\n",
        "olympia_grav_dir = \"/content/drive/MyDrive/Deep_learning/Olympia_dataset/treated_640px\"\n",
        "handai_cont_dir = \"/content/GO_extended_dataset/Control_photo_1886mai\"\n",
        "handai_grav_dir = \"/content/GO_extended_dataset/treatable\"\n",
        "\n",
        "\n",
        "countfile(\"control_640px_olympia\", olympia_cont_dir)\n",
        "countfile(\"treated_640px_olympia\", olympia_grav_dir)\n",
        "\n",
        "countfile(\"control_handai\", handai_cont_dir)\n",
        "countfile(\"treated_handai\", handai_grav_dir)\n"
      ],
      "metadata": {
        "id": "JFEWXrZrz_CY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Handai dataset, Olympia dataset --> super_extend_datase_for_YOLO**"
      ],
      "metadata": {
        "id": "6pYCYtrN79vn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dst_dir = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO\"\n",
        "\n",
        "if os.path.exists(dst_dir):\n",
        "    shutil.rmtree(dst_dir)\n",
        "os.makedirs(dst_dir)\n",
        "os.makedirs(f\"{dst_dir}/train_val\")\n",
        "os.makedirs(f\"{dst_dir}/train_val/grav\")\n",
        "os.makedirs(f\"{dst_dir}/train_val/cont\")\n",
        "os.makedirs(f\"{dst_dir}/test\")\n",
        "os.makedirs(f\"{dst_dir}/test/handai/grav\")\n",
        "os.makedirs(f\"{dst_dir}/test/handai/cont\")\n",
        "os.makedirs(f\"{dst_dir}/test/olympia/grav\")\n",
        "os.makedirs(f\"{dst_dir}/test/olympia/cont\")"
      ],
      "metadata": {
        "id": "FlAqRIZbCDRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "\n",
        "random_state = 1\n",
        "\n",
        "# Control images\n",
        "src_cont = olympia_cont_dir\n",
        "test_cont = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO/test/olympia/cont\"\n",
        "trainval_cont = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO/train_val/cont\"\n",
        "\n",
        "cont_images = os.listdir(src_cont)\n",
        "random.Random(random_state).shuffle(cont_images)\n",
        "\n",
        "test_cont_images = cont_images[:50]\n",
        "trainval_cont_images = cont_images[50:]\n",
        "\n",
        "for image in tqdm(test_cont_images, desc=\"Copying test cont images\"):\n",
        "    src_path = os.path.join(src_cont, image)\n",
        "    dst_path = os.path.join(test_cont, image)\n",
        "    shutil.copy(src_path, dst_path)\n",
        "\n",
        "for image in tqdm(trainval_cont_images, desc=\"Copying trainval cont images\"):\n",
        "    src_path = os.path.join(src_cont, image)\n",
        "    dst_path = os.path.join(trainval_cont, image)\n",
        "    shutil.copy(src_path, dst_path)\n",
        "\n",
        "\n",
        "# Grav images\n",
        "src_grav = olympia_grav_dir\n",
        "test_grav = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO/test/olympia/grav\"\n",
        "trainval_grav = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO/train_val/grav\"\n",
        "\n",
        "grav_images = os.listdir(src_grav)\n",
        "random.Random(random_state).shuffle(grav_images)\n",
        "\n",
        "test_grav_images = grav_images[:50]\n",
        "trainval_grav_images = grav_images[50:]\n",
        "\n",
        "for image in tqdm(test_grav_images, desc=\"Copying test grav images\"):\n",
        "    src_path = os.path.join(src_grav, image)\n",
        "    dst_path = os.path.join(test_grav, image)\n",
        "    shutil.copy(src_path, dst_path)\n",
        "\n",
        "for image in tqdm(trainval_grav_images, desc=\"Copying trainval grav images\"):\n",
        "    src_path = os.path.join(src_grav, image)\n",
        "    dst_path = os.path.join(trainval_grav, image)\n",
        "    shutil.copy(src_path, dst_path)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sta5Z-LLC01f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0039c378-9ab5-4461-989e-3a24e78544d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Copying test cont images: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:01<00:00, 29.43it/s]\n",
            "Copying trainval cont images: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 119/119 [00:04<00:00, 29.13it/s]\n",
            "Copying test grav images: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:04<00:00, 12.35it/s]\n",
            "Copying trainval grav images: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 511/511 [00:18<00:00, 27.83it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from shutil import copyfile\n",
        "from tqdm import tqdm\n",
        "\n",
        "grav_dir = olympia_grav_dir\n",
        "cont_dir = olympia_cont_dir\n",
        "test_grav_dir = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO/test/olympia/grav\"\n",
        "test_cont_dir = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO/test/olympia/cont\"\n",
        "train_val_grav_dir = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO/train_val/grav\"\n",
        "train_val_cont_dir = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO/train_val/cont\"\n",
        "\n",
        "# Check if files in grav_dir are in test_grav_dir\n",
        "for filename in tqdm(os.listdir(grav_dir)):\n",
        "    basename = os.path.basename(filename)\n",
        "    if os.path.exists(os.path.join(test_grav_dir, basename)):\n",
        "        print(\"coooool!!!\")\n",
        "        continue\n",
        "    else:\n",
        "        copyfile(os.path.join(grav_dir, filename), os.path.join(train_val_grav_dir, filename))\n",
        "\n",
        "# Check if files in cont_dir are in test_cont_dir\n",
        "for filename in tqdm(os.listdir(cont_dir)):\n",
        "    basename = os.path.basename(filename)\n",
        "    if os.path.exists(os.path.join(test_cont_dir, basename)):\n",
        "        print(\"hotttttt!!!\")\n",
        "        continue\n",
        "    else:\n",
        "        copyfile(os.path.join(cont_dir, filename), os.path.join(train_val_cont_dir, filename))\n"
      ],
      "metadata": {
        "id": "-Ll-LhlRKSQN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#####################\n",
        "# rename\n",
        "#æŒ‡å®šã•ã‚ŒãŸãƒ•ã‚©ãƒ«ãƒ€å†…ã«ã‚ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«åãŒ\"olympia_\"ã‹ã‚‰å§‹ã¾ã‚‰ãªã„å ´åˆã«ã€\"olympia_\"ã‚’å…ˆé ­ã«ã¤ã‘ãŸãƒ•ã‚¡ã‚¤ãƒ«åã«ãƒªãƒãƒ¼ãƒ ã™ã‚‹å‡¦ç†ã‚’è¡Œã†ã€‚\n",
        "#####################\n",
        "\n",
        "import os\n",
        "\n",
        "# ãƒ•ã‚©ãƒ«ãƒ€ã®ãƒ‘ã‚¹ã‚’æŒ‡å®š\n",
        "test_grav_dir = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO/test/olympia/grav\"\n",
        "test_cont_dir = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO/test/olympia/cont\"\n",
        "train_val_grav_dir = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO/train_val/grav\"\n",
        "train_val_cont_dir = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO/train_val/cont\"\n",
        "\n",
        "# ãƒ•ã‚¡ã‚¤ãƒ«åãŒ \"olympia_\" ã‹ã‚‰å§‹ã¾ã‚‰ãªã„å ´åˆã€\"olympia_\" ã‚’å…ˆé ­ã«ã¤ã‘ãŸãƒ•ã‚¡ã‚¤ãƒ«åã«ãƒªãƒãƒ¼ãƒ ã™ã‚‹\n",
        "def rename_file(path):\n",
        "    for filename in os.listdir(path):\n",
        "        if not filename.startswith(\"oly_\"):\n",
        "            new_filename = \"oly_\" + filename\n",
        "            os.rename(os.path.join(path, filename), os.path.join(path, new_filename))\n",
        "\n",
        "# ãƒªãƒãƒ¼ãƒ å‡¦ç†ã‚’å®Ÿè¡Œ\n",
        "rename_file(test_grav_dir)\n",
        "rename_file(test_cont_dir)\n",
        "rename_file(train_val_grav_dir)\n",
        "rename_file(train_val_cont_dir)\n"
      ],
      "metadata": {
        "id": "AleU8QFERy6K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(os.listdir(\"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO/train_val/grav\")))\n",
        "print(len(os.listdir(\"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO/train_val/cont\")))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQ3tV45TLy95",
        "outputId": "82c34187-2939-4b46-9cad-89f8c06bdbf4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "511\n",
            "119\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "import os\n",
        "import random\n",
        "import shutil\n",
        "from tqdm import tqdm\n",
        "\n",
        "############################\n",
        "# Handai GO_extended_dataset\n",
        "#\n",
        "# /treatable â†’ /train_val/grav\n",
        "# /control â†’ /train_val/Control_photo_1886mai\n",
        "#\n",
        "############################\n",
        "\n",
        "if not os.path.exists(\"/content/GO_extended_dataset\"):\n",
        "    !unzip /content/drive/MyDrive/Deep_learning/GO_extended_dataset/GO_extended_dataset.zip -d /content/\n",
        "\n",
        "#file_name, class, idxã®ã‚Šã‚¹ãƒˆã‚’ä½œæˆ\n",
        "def get_file_info(src_dir, class_id):\n",
        "    file_list = os.listdir(src_dir)\n",
        "    ids_list = [int(file_name.split('.')[0].split('-')[0]) for file_name in file_list]\n",
        "    class_list = [class_id] * len(file_list)\n",
        "    return file_list, ids_list, class_list\n",
        "\n",
        "# Contãƒ•ã‚©ãƒ«ãƒ€ã®æƒ…å ±\n",
        "cont_dir = '/content/GO_extended_dataset/Control_photo_1886mai'\n",
        "file_list_cont, ids_list_cont, class_list_cont = get_file_info(cont_dir, 0)\n",
        "\n",
        "# Gravãƒ•ã‚©ãƒ«ãƒ€ã®æƒ…å ±\n",
        "grav_dir = '/content/GO_extended_dataset/treatable'\n",
        "file_list_grav, ids_list_grav, class_list_grav = get_file_info(grav_dir, 1)\n",
        "\n",
        "# çµåˆ\n",
        "file_list = file_list_cont + file_list_grav\n",
        "ids_list = ids_list_cont + ids_list_grav\n",
        "class_list = class_list_cont + class_list_grav\n",
        "\n",
        "print(file_list)\n",
        "print(ids_list)\n",
        "print(class_list)\n",
        "\n",
        "\n",
        "\n",
        "import random\n",
        "\n",
        "# file_listã«ç”»åƒã®ãƒ‘ã‚¹ãŒã€ids_listã«æ‚£è€…ã®idãŒã€class_listã«gravã‹contã‹(0 or 1)ãŒæ ¼ç´ã•ã‚Œã¦ã„ã‚‹ã¨ä»®å®šã™ã‚‹\n",
        "# ä¾‹: file_list = ['/path/to/image1.jpg', '/path/to/image2.jpg', ...]\n",
        "#     ids_list = ['patient1', 'patient1', 'patient2', 'patient3', ...]\n",
        "#     class_list = [0, 1, 0, 1, ...]\n",
        "\n",
        "# ãƒ©ãƒ³ãƒ€ãƒ ã‚·ãƒ¼ãƒ‰ã‚’å›ºå®šã™ã‚‹\n",
        "random.seed(1234)\n",
        "\n",
        "# idã”ã¨ã«ç”»åƒã®ãƒªã‚¹ãƒˆã‚’ã¾ã¨ã‚ã‚‹\n",
        "id_to_files = {}\n",
        "for i, id in enumerate(ids_list):\n",
        "    if id not in id_to_files:\n",
        "        id_to_files[id] = []\n",
        "    id_to_files[id].append((file_list[i], class_list[i]))\n",
        "\n",
        "# idã”ã¨ã«ç”»åƒã‚’testã‹trainã«æŒ¯ã‚Šåˆ†ã‘ã‚‹\n",
        "test_files = []\n",
        "train_files = []\n",
        "for id in id_to_files:\n",
        "    files = id_to_files[id]\n",
        "    random.shuffle(files)  # åŒã˜idå†…ã®ç”»åƒã®é †ç•ªã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«ä¸¦ã¹æ›¿ãˆã‚‹\n",
        "    for file, cls in files:\n",
        "        if len(test_files) < 50 or cls == 0:\n",
        "            test_files.append((file, cls))\n",
        "        else:\n",
        "            train_files.append((file, cls))\n",
        "\n",
        "# ç¢ºèª\n",
        "print(len(test_files), len(train_files))  # 50 ä»¥ä¸Šã®å ´åˆã¯å†å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚"
      ],
      "metadata": {
        "id": "DjeQtXC5F_7d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "import numpy as np\n",
        "from sklearn.model_selection import GroupShuffleSplit\n",
        "\n",
        "############################\n",
        "# Handai GO_extended_dataset\n",
        "#\n",
        "# /treatable â†’ /train_val/grav\n",
        "# /control â†’ /train_val/Control_photo_1886mai\n",
        "#\n",
        "############################\n",
        "\n",
        "if not os.path.exists(\"/content/GO_extended_dataset\"):\n",
        "    !unzip /content/drive/MyDrive/Deep_learning/GO_extended_dataset/GO_extended_dataset.zip -d /content/\n",
        "\n",
        "# Contãƒ•ã‚©ãƒ«ãƒ€ã®ãƒ‘ã‚¹\n",
        "src_dir = '/content/GO_extended_dataset/Control_photo_1886mai'\n",
        "train_val_dir = '/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO/train_val/cont'\n",
        "test_dir = '/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO/test/handai/cont'\n",
        "\n",
        "# ãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆã‚’å–å¾—ã—ã€IDã‚’æŠ½å‡ºã—ã¦ãƒªã‚¹ãƒˆã«æ ¼ç´\n",
        "file_list = os.listdir(src_dir)\n",
        "ids = [int(file_name.split('.')[0].split('-', 1)[0]) for file_name in file_list]\n",
        "\n",
        "# IDã”ã¨ã«ã‚°ãƒ«ãƒ¼ãƒ—ã‚’ä½œæˆã—ã¦ã€group-stratifiedã«åˆ†å‰²\n",
        "splitter = GroupShuffleSplit(n_splits=1, test_size=50, random_state=2)\n",
        "train_val_indices, test_indices = next(splitter.split(file_list, groups=ids))\n",
        "\n",
        "# å­¦ç¿’ç”¨ã¨ãƒ†ã‚¹ãƒˆç”¨ã®ãƒ•ã‚©ãƒ«ãƒ€ã«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚³ãƒ”ãƒ¼\n",
        "for i, file_name in tqdm(enumerate(file_list), total=len(file_list)):\n",
        "    src_path = os.path.join(src_dir, file_name)\n",
        "    dst_dir = test_dir if i in test_indices else train_val_dir\n",
        "    dst_path = os.path.join(dst_dir, file_name)\n",
        "    shutil.copy(src_path, dst_path)\n",
        "\n",
        "# Gravãƒ•ã‚©ãƒ«ãƒ€ã®ãƒ‘ã‚¹\n",
        "src_dir = '/content/GO_extended_dataset/treatable'\n",
        "train_val_dir = '/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO/train_val/grav'\n",
        "test_dir = '/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO/test/handai/grav'\n",
        "\n",
        "# ãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆã‚’å–å¾—ã—ã€IDã‚’æŠ½å‡ºã—ã¦ãƒªã‚¹ãƒˆã«æ ¼ç´\n",
        "file_list = os.listdir(src_dir)\n",
        "ids = [int(file_name.split('.')[0].split('-', 1)[0]) for file_name in file_list]\n",
        "\n",
        "# IDã”ã¨ã«ã‚°ãƒ«ãƒ¼ãƒ—ã‚’ä½œæˆã—ã¦ã€group-stratifiedã«åˆ†å‰²\n",
        "splitter = GroupShuffleSplit(n_splits=1, test_size=15, random_state=4)\n",
        "train_val_indices, test_indices = next(splitter.split(file_list, groups=ids))\n",
        "print(len(test_indices))\n",
        "\n",
        "# å­¦ç¿’ç”¨ã¨ãƒ†ã‚¹ãƒˆç”¨ã®ãƒ•ã‚©ãƒ«ãƒ€ã«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚³ãƒ”ãƒ¼\n",
        "for i, file_name in tqdm(enumerate(file_list), total=len(file_list)):\n",
        "    src_path = os.path.join(src_dir, file_name)\n",
        "    dst_dir = test_dir if i in test_indices else train_val_dir\n",
        "    dst_path = os.path.join(dst_dir, file_name)\n",
        "    shutil.copy(src_path, dst_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dy5IinNPpPgO",
        "outputId": "e06a6648-32e7-4c03-ffc9-3ef8486a889d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1886/1886 [00:39<00:00, 48.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1879/1879 [00:49<00:00, 37.81it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #ï¼ˆGroupShuffleSplitãŒgroupã”ã¨ã«åˆ†å‰²ã™ã‚‹ã®ã§ï¼‰ç·æ•°ãŒ50ã«ãªã‚‹ã‚ˆã†ã«random_stateã¨test_sizeã‚’èª¿ç¯€\n",
        "# # çµæžœã®æ ¼ç´ç”¨ãƒªã‚¹ãƒˆ\n",
        "# # Gravãƒ•ã‚©ãƒ«ãƒ€ã®ãƒ‘ã‚¹\n",
        "# src_dir = '/content/GO_extended_dataset/treatable'\n",
        "# train_val_dir = '/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO/train_val/grav'\n",
        "# test_dir = '/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO/test/handai/grav'\n",
        "\n",
        "# # ãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆã‚’å–å¾—ã—ã€IDã‚’æŠ½å‡ºã—ã¦ãƒªã‚¹ãƒˆã«æ ¼ç´\n",
        "# file_list = os.listdir(src_dir)\n",
        "# ids = [int(file_name.split('.')[0].split('-', 1)[0]) for file_name in file_list]\n",
        "\n",
        "# results = []\n",
        "\n",
        "# for random_state in range(10):\n",
        "#     for test_size in range(1, 51):\n",
        "#         splitter = GroupShuffleSplit(n_splits=1, test_size=test_size, random_state=random_state)\n",
        "#         train_val_indices, test_indices = next(splitter.split(file_list, groups=ids))\n",
        "#         test_set_size = len(test_indices)\n",
        "#         print(f\"random_state: {random_state}, test_size: {test_size}, test_set_size: {test_set_size}\")\n",
        "#         if test_set_size == 50:\n",
        "#             print(\"Coooool!!\")\n",
        "#             results.append((random_state, test_size))\n",
        "\n",
        "# # çµæžœã®è¡¨ç¤º\n",
        "# for result in results:\n",
        "#     print(f\"random_state: {result[0]}, test_size: {result[1]}\")\n"
      ],
      "metadata": {
        "id": "MMk9fpa9zkZ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**ãƒ•ã‚¡ã‚¤ãƒ«æ•°ã®ç¢ºèª**"
      ],
      "metadata": {
        "id": "jQkGRfUO9omP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dir = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO\"\n",
        "print(len(os.listdir(f\"{dir}/train_val/grav\")))\n",
        "print(len(os.listdir(f\"{dir}/train_val/cont\")))\n",
        "print(len(os.listdir(f\"{dir}/test/olympia/grav\")))\n",
        "print(len(os.listdir(f\"{dir}/test/olympia/cont\")))\n",
        "print(len(os.listdir(f\"{dir}/test/handai/grav\")))\n",
        "print(len(os.listdir(f\"{dir}/test/handai/cont\")))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aGGR7_-P96mS",
        "outputId": "e06d93f9-2dbf-4ee5-cbfe-eaf40fdb9b6e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2342\n",
            "1958\n",
            "50\n",
            "50\n",
            "50\n",
            "50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**æ—¢å­˜ã®YOLOv5ãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ã¦ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã‚’è¨­å®š**"
      ],
      "metadata": {
        "id": "R6FT8pBYNvF7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dst_dir = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO/train_val/labels\"\n",
        "if os.path.exists(dst_dir):\n",
        "    shutil.rmtree(dst_dir)\n",
        "os.makedirs(f\"{dst_dir}/grav\")\n",
        "os.makedirs(f\"{dst_dir}/cont\")"
      ],
      "metadata": {
        "id": "-wggPJzAOBYf"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup YOLOv5\n",
        "%cd /content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training\n",
        "!git clone https://github.com/ultralytics/yolov5\n",
        "%cd yolov5\n",
        "%pip install -qr requirements.txt\n",
        "\n",
        "import torch\n",
        "import utils\n",
        "display = utils.notebook_init()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1gF6whZ7P5ax",
        "outputId": "add51d2d-cd46-4772-bb9e-ddf9e37a759a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv5 ðŸš€ v7.0-72-g064365d Python-3.10.11 torch-2.0.1+cu118 CPU\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete âœ… (2 CPUs, 12.7 GB RAM, 23.4/107.7 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from models.common import DetectMultiBackend\n",
        "#from utils.datasets import IMG_FORMATS, VID_FORMATS, LoadImages, LoadStreams\n",
        "from utils.general import (LOGGER, check_file, check_img_size, check_imshow, check_requirements, colorstr,\n",
        "                           increment_path, non_max_suppression, print_args, strip_optimizer, xyxy2xywh)\n",
        "#from utils.plots import Annotator, colors, save_one_box\n",
        "from utils.torch_utils import select_device, time_sync\n",
        "from utils.augmentations import letterbox #padding\n",
        "\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torchvision import models, transforms\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "#ã‚µãƒãƒ¼ãƒˆãƒ‘ãƒƒãƒã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "\n",
        "def interference(img, weight):\n",
        "    device = 'cpu'\n",
        "    device = select_device(device)\n",
        "    model = DetectMultiBackend(weight, device=device, dnn=False)\n",
        "    #stride, names, pt, jit, onnx, engine = model.stride, model.names, model.pt, model.jit, model.onnx, model.engine\n",
        "    #imgsz = check_img_size([640], s=stride)  # check image size\n",
        "\n",
        "    #class_names = {0:\"cont\", 1:\"grav\"}\n",
        "\n",
        "    # transform = transforms.Compose([\n",
        "    #             transforms.Resize(size=(480,640)),\n",
        "    #             transforms.ToTensor(),\n",
        "    #             # transforms.Normalize(\n",
        "    #             #     mean=[0.5, 0.5, 0.5],\n",
        "    #             #     std=[0.5, 0.5, 0.5]\n",
        "    #             #    )\n",
        "    #             ])\n",
        "\n",
        "    img_cv2 = cv2.imread(img) #CV2ã§é–‹ã\n",
        "    img_cv2 = letterbox(img_cv2, (640,640), stride=32, auto=False)[0] #resize, ä¸Šä¸‹padding (color 114)\n",
        "\n",
        "    #cv2_imshow(img_cv2)\n",
        "\n",
        "    img_cv2 = img_cv2.transpose((2, 0, 1))[::-1]  # HWC to CHW, BGR to RGB\n",
        "    img_cv2 = np.ascontiguousarray(img_cv2)\n",
        "    img_tensor = torch.from_numpy(img_cv2).float()\n",
        "\n",
        "    #img_tensor = transform(img_np)\n",
        "    img_tensor /= 255\n",
        "    #print(img_tensor.shape)\n",
        "\n",
        "    #print(img_tensor)\n",
        "    img_tensor = torch.unsqueeze(img_tensor, 0)  # ãƒãƒƒãƒå¯¾å¿œ\n",
        "\n",
        "\n",
        "    pred = model(img_tensor, visualize=False, augment=False)\n",
        "\n",
        "    pred = non_max_suppression(pred, conf_thres=0.25, iou_thres=0.45, classes=None,  max_det=1000)\n",
        "\n",
        "    print(f\"pred: {pred}\")\n",
        "\n",
        "    return pred"
      ],
      "metadata": {
        "id": "Yo05tVYVaD1N"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def interference_thres(img, weight):\n",
        "    device = 'cpu'\n",
        "    device = select_device(device)\n",
        "    model = DetectMultiBackend(weight, device=device, dnn=False)\n",
        "    #stride, names, pt, jit, onnx, engine = model.stride, model.names, model.pt, model.jit, model.onnx, model.engine\n",
        "    #imgsz = check_img_size([640], s=stride)  # check image size\n",
        "\n",
        "    #class_names = {0:\"cont\", 1:\"grav\"}\n",
        "\n",
        "    # transform = transforms.Compose([\n",
        "    #             transforms.Resize(size=(480,640)),\n",
        "    #             transforms.ToTensor(),\n",
        "    #             # transforms.Normalize(\n",
        "    #             #     mean=[0.5, 0.5, 0.5],\n",
        "    #             #     std=[0.5, 0.5, 0.5]\n",
        "    #             #    )\n",
        "    #             ])\n",
        "\n",
        "    img_cv2 = cv2.imread(img) #CV2ã§é–‹ã\n",
        "    img_cv2 = letterbox(img_cv2, (640,640), stride=32, auto=False)[0] #resize, ä¸Šä¸‹padding (color 114)\n",
        "\n",
        "    #cv2_imshow(img_cv2)\n",
        "\n",
        "    img_cv2 = img_cv2.transpose((2, 0, 1))[::-1]  # HWC to CHW, BGR to RGB\n",
        "    img_cv2 = np.ascontiguousarray(img_cv2)\n",
        "    img_tensor = torch.from_numpy(img_cv2).float()\n",
        "\n",
        "    #img_tensor = transform(img_np)\n",
        "    img_tensor /= 255\n",
        "    #print(img_tensor.shape)\n",
        "\n",
        "    #print(img_tensor)\n",
        "    img_tensor = torch.unsqueeze(img_tensor, 0)  # ãƒãƒƒãƒå¯¾å¿œ\n",
        "\n",
        "\n",
        "    pred = model(img_tensor, visualize=False, augment=False)\n",
        "\n",
        "    pred = non_max_suppression(pred, conf_thres=0.15, iou_thres=0.25, classes=None,  max_det=1000)\n",
        "\n",
        "    #print(f\"pred: {pred}\")\n",
        "\n",
        "    return pred"
      ],
      "metadata": {
        "id": "P-HTdamj-mfN"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "YOLOv5_model_path = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training/yolov5n_130epch.pt\"\n",
        "parent_dir = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO/train_val\"\n",
        "\n",
        "for class_name in [\"grav\", \"cont\"]:\n",
        "    if class_name == \"cont\":\n",
        "        class_num = 0\n",
        "    else:\n",
        "        class_num = 1\n",
        "    for image_path in glob.glob(f\"{parent_dir}/{class_name}/*\"):\n",
        "        name = os.path.splitext(os.path.basename(image_path))[0]\n",
        "        print(f\"image_name: {name}\")\n",
        "\n",
        "        #YOLOv5ã«ã‚ˆã‚Šãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã‚’æŠœãå‡ºã™\n",
        "        try:\n",
        "            pred = interference(image_path, YOLOv5_model_path)[0].tolist()[0]\n",
        "        except: #é€šå¸¸ã®é–¾å€¤è¨­å®šã§æ¤œå‡ºã•ã‚Œãªã„å ´åˆ\n",
        "            pred = interference_thres(image_path, YOLOv5_model_path)[0].tolist()[0]\n",
        "        pred = [max(num, 0) for num in pred] #0ã‚ˆã‚Šå°ã•ã„åº§æ¨™ã¯0ã«ä¿®æ­£ã™ã‚‹\n",
        "        pred = [min(num, 640) for num in pred] #640ã‚ˆã‚Šå°ã•ã„åº§æ¨™ã¯640ã«ä¿®æ­£ã™ã‚‹\n",
        "        xcenter = (pred[0]+pred[2])/2\n",
        "        ycenter = (pred[1]+pred[3])/2\n",
        "        xwidth = pred[2]-pred[0]\n",
        "        ywidth = pred[3]-pred[1]\n",
        "        \n",
        "        # ãƒ•ã‚¡ã‚¤ãƒ«åã¨ä½œæˆã™ã‚‹å†…å®¹ã‚’æŒ‡å®š\n",
        "        txt_name = f\"{parent_dir}/labels/{class_name}/{name}.txt\"\n",
        "        content = f\"{class_num} {round(xcenter)} {round(ycenter)} {round(xwidth)} {round(ywidth)}\"\n",
        "        with open(txt_name, \"w\") as file:\n",
        "            # ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãè¾¼ã‚€\n",
        "            file.write(content)\n",
        "            print(f\"text file successfully createdðŸ™† {content}\")\n",
        "            print(\"\")\n",
        "            print(\"\")\n",
        "        "
      ],
      "metadata": {
        "id": "wlGbrrAWRtHT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**YOLOv5ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ç”¨ã«ãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆ**\n",
        "\n",
        "ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹æ±ºå®šã«ã¯ä»¥å‰ã«ä½œæˆã—ãŸYOLOv5ãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ã‚‹\n"
      ],
      "metadata": {
        "id": "hPB-WI5z1agI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup YOLOv5\n",
        "%cd /content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training\n",
        "!git clone https://github.com/ultralytics/yolov5\n",
        "%cd yolov5\n",
        "%pip install -qr requirements.txt\n",
        "\n",
        "import torch\n",
        "import utils\n",
        "display = utils.notebook_init()"
      ],
      "metadata": {
        "id": "yCB5xW-2-H25",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57f2fad5-e9fe-4715-97c5-e682914ac231"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv5 ðŸš€ v7.0-72-g064365d Python-3.10.11 torch-2.0.1+cu118 CPU\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete âœ… (2 CPUs, 12.7 GB RAM, 30.8/107.7 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from models.common import DetectMultiBackend\n",
        "#from utils.datasets import IMG_FORMATS, VID_FORMATS, LoadImages, LoadStreams\n",
        "from utils.general import (LOGGER, check_file, check_img_size, check_imshow, check_requirements, colorstr,\n",
        "                           increment_path, non_max_suppression, print_args, strip_optimizer, xyxy2xywh)\n",
        "#from utils.plots import Annotator, colors, save_one_box\n",
        "from utils.torch_utils import select_device, time_sync\n",
        "from utils.augmentations import letterbox #padding\n",
        "\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torchvision import models, transforms\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "#ã‚µãƒãƒ¼ãƒˆãƒ‘ãƒƒãƒã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "\n",
        "def interference(img, weight):\n",
        "    device = 'cpu'\n",
        "    device = select_device(device)\n",
        "    model = DetectMultiBackend(weight, device=device, dnn=False)\n",
        "    #stride, names, pt, jit, onnx, engine = model.stride, model.names, model.pt, model.jit, model.onnx, model.engine\n",
        "    #imgsz = check_img_size([640], s=stride)  # check image size\n",
        "\n",
        "    #class_names = {0:\"cont\", 1:\"grav\"}\n",
        "\n",
        "    # transform = transforms.Compose([\n",
        "    #             transforms.Resize(size=(480,640)),\n",
        "    #             transforms.ToTensor(),\n",
        "    #             # transforms.Normalize(\n",
        "    #             #     mean=[0.5, 0.5, 0.5],\n",
        "    #             #     std=[0.5, 0.5, 0.5]\n",
        "    #             #    )\n",
        "    #             ])\n",
        "\n",
        "    img_cv2 = cv2.imread(img) #CV2ã§é–‹ã\n",
        "    img_cv2 = letterbox(img_cv2, (640,640), stride=32, auto=False)[0] #resize, ä¸Šä¸‹padding (color 114)\n",
        "\n",
        "    #cv2_imshow(img_cv2)\n",
        "\n",
        "    img_cv2 = img_cv2.transpose((2, 0, 1))[::-1]  # HWC to CHW, BGR to RGB\n",
        "    img_cv2 = np.ascontiguousarray(img_cv2)\n",
        "    img_tensor = torch.from_numpy(img_cv2).float()\n",
        "\n",
        "    #img_tensor = transform(img_np)\n",
        "    img_tensor /= 255\n",
        "    #print(img_tensor.shape)\n",
        "\n",
        "    #print(img_tensor)\n",
        "    img_tensor = torch.unsqueeze(img_tensor, 0)  # ãƒãƒƒãƒå¯¾å¿œ\n",
        "\n",
        "\n",
        "    pred = model(img_tensor, visualize=False, augment=False)\n",
        "\n",
        "    pred = non_max_suppression(pred, conf_thres=0.25, iou_thres=0.45, classes=None,  max_det=1000)\n",
        "\n",
        "    #print(f\"pred: {pred}\")\n",
        "\n",
        "    return pred"
      ],
      "metadata": {
        "id": "fGY-seX8674J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# image_path = image_list\n",
        "# img = image_path[102]\n",
        "\n",
        "YOLOv5_model_path = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training/yolov5n_130epch.pt\"\n",
        "\n",
        "parent_dir = \"/content/drive/MyDrive/Deep_learning/Olympia_dataset/for_validation/treated_640px\"\n",
        "img = f\"{parent_dir}/970.JPG\"\n",
        "\n",
        "class_names = {0:\"cont\", 1:\"grav\"}\n",
        "pred = interference(img, YOLOv5_model_path)\n",
        "\n",
        "# output result\n",
        "x1, y1, x2, y2, prob, class_num = torch.round(pred[0][0])\n",
        "\n",
        "# probability\n",
        "prob = pred[0][0][4].item()\n",
        "\n",
        "\n",
        "# class\n",
        "class_name = class_names[pred[0][0][5].item()]\n",
        "\n",
        "print(\"è¨ºæ–­ã¯ %sã€ç¢ºçŽ‡ã¯%.1fï¼…ã§ã™ã€‚\" %(class_name, prob*100))\n",
        "\n",
        "img_cv2 = cv2.imread(img) \n",
        "\n",
        "# æ¨ªå¹…ãŒ640pxã«ãªã‚‹ã‚ˆã†ã«ãƒªã‚µã‚¤ã‚º\n",
        "height, width, _ = img_cv2.shape\n",
        "resize_width = 640\n",
        "resize_height = int((height / width) * resize_width)\n",
        "resize_size = (resize_width, resize_height)\n",
        "img_cv2 = cv2.resize(img_cv2, resize_size)\n",
        "\n",
        "# calculate coordinates of the bounding box (640*640ã«paddingã•ã‚Œã¦ã„ã‚‹åˆ†ã®åº§æ¨™ã‚’è¶³ã™)\n",
        "img_height, img_width, _ = img_cv2.shape[:3]\n",
        "print(f\"img_height: {img_height}, img_width: {img_width}\")\n",
        "padding_x = (img_height - min(img_width, img_height))/2\n",
        "padding_y = (img_width - min(img_width, img_height))/2\n",
        "x1 = x1 - padding_x\n",
        "y1 = y1 - padding_y\n",
        "x2 = x2 - padding_x\n",
        "y2 = y2 - padding_y\n",
        "print(f\"x1: {x1}, y1: {y1}, x2: {x2}, y2: {y2}\")\n",
        "\n",
        "\n",
        "# draw bounding box\n",
        "cv2.rectangle(img_cv2, (int(x1), int(y1)), (int(x2), int(y2)), (255, 0, 0), 2)\n",
        "\n",
        "# show image\n",
        "cv2_imshow(img_cv2)"
      ],
      "metadata": {
        "id": "66_9Bbl069J1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**YOLOv5ç”¨ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ç”¨ãƒ•ã‚©ãƒ«ãƒ€ä½œæˆ**\n",
        "\n",
        "https://github.com/ykitaguchi77/GravCont_classification_colab/blob/master/Extend_dataset_YOLOv5%EF%BC%A0.ipynb\n",
        "\n",
        "https://book.st-hakky.com/docs/object-detection-yolov5-tutorial/"
      ],
      "metadata": {
        "id": "9XI1oisiBK1O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "\n",
        "---------------super_extend_for_YOLO_training --------train------labels\n",
        "                                              |           |--images\n",
        "                                              |            \n",
        "                                              |------valid ----labels\n",
        "                                              |           |--images\n",
        "                                              |\n",
        "                                              |--dataset.yaml\n",
        "                                              |--yolov5                                    \n",
        "\"\"\""
      ],
      "metadata": {
        "id": "nt3WfWu_Bb_p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dst_path = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_for_YOLO_training\"\n",
        "orig_grav_path = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO/train_val/grav\"\n",
        "orig_cont_path = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO/train_val/grav\""
      ],
      "metadata": {
        "id": "ZbyOJj3g_8Fj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if os.path.exists(dst_path):\n",
        "    shutil.rmtree(dst_path)\n",
        "os.makedirs(dst_path)\n",
        "os.makedirs(f\"{dst_path}/train/images\")\n",
        "os.makedirs(f\"{dst_path}/train/labels\")\n",
        "os.makedirs(f\"{dst_path}/valid/images\")\n",
        "os.makedirs(f\"{dst_path}/valid/labels\")"
      ],
      "metadata": {
        "id": "DtXJAAtsCjP3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd $dst_path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uVip7xMUEDgf",
        "outputId": "4e56f642-ee1d-4f6a-f593-d751435a9c33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_for_YOLO_training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile dataset.yaml\n",
        "# path\n",
        "train: /content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_for_YOLO_training/train/images\n",
        "val: /content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_for_YOLO_training/valid/images\n",
        "\n",
        "# num of classes\n",
        "nc: 2\n",
        "\n",
        "#class names\n",
        "names: ['cont', 'grav'] # classåã‚’å®šç¾©"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMwlnFiqCpxI",
        "outputId": "1deead05-a8b2-4839-b279-dedeaa5812d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing dataset.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# split dataset\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import glob\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "dataset_dir = dst_path = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_for_YOLO_training/train_val\"\n",
        "\n",
        "\n",
        "# def split_dataset(dataset_dir):\n",
        "#     img_list = glob.glob(f\"{dataset_dir}/images/*\")\n",
        "#     img_train, img_test = train_test_split(img_list, test_size=0.3, random_state=0)\n",
        "\n",
        "#     # img_train, img_testã«åå‰ãŒä¸€è‡´ã™ã‚‹txtãƒ•ã‚¡ã‚¤ãƒ«ã‚’æŠœãå‡ºã™\n",
        "#     label_train = [f\"{dataset_dir}/labels/{os.path.basename(i).split('.')[0]}.txt\" for i in img_train]\n",
        "#     label_test = [f\"{dataset_dir}/labels/{os.path.basename(i).split('.')[0]}.txt\" for i in img_test]\n",
        "\n",
        "#     print(f\"train: {len(label_train)},test: {len(label_test)}\")\n",
        "\n",
        "#     return img_train, img_test, label_train, label_test\n",
        "\n",
        "def make_path_list(dir, class_name):\n",
        "    image_list =  [file for file in glob.glob(f\"{dir}/{class_name}/images/*\") if os.path.isfile(file) == True ]\n",
        "    label_list =  [f\"{dir}/{class_name}/labels/{os.path.basename(i).split('.')[0]}.txt\" for i in image_list]\n",
        "\n",
        "    id_list = [os.path.basename(i).split(\"-\")[0].split(\".\")[0] for i in image_list]\n",
        "    \n",
        "    index = {}\n",
        "    id_idx = []\n",
        "    for item in id_list:\n",
        "        if item in index:\n",
        "            id_idx.append(index[item])\n",
        "        else:\n",
        "            index[item] = len(index) + 1\n",
        "            id_idx.append(index[item])\n",
        "    id_idx = [int(i) for i in id_idx]\n",
        "\n",
        "    return image_list, label_list, id_idx\n",
        "\n",
        "grav_image_list, grav_label_list, grav_id_idx = make_path_list(dataset_dir, \"grav\")\n",
        "cont_image_list, cont_label_list, cont_id_idx = make_path_list(dataset_dir, \"cont\")\n",
        "\n",
        "print(f\"grav: {len(grav_image_list)}\")\n",
        "print(f\"cont: {len(cont_image_list)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lb7vg1IfHSCT",
        "outputId": "866d78d4-0ae3-44b7-f007-679509292cf4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "grav: 0\n",
            "cont: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f8hUG0YRLnUq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM0B7cW3zW0PfqTUETa/rQK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykitaguchi77/GO_AI_project/blob/main/make_super_extend_dataset_for_YOLO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Create extended dataset for YOLOv5 implementation**\n",
        "\n",
        "#Olympia\n",
        "„ÉªOlympia dataset\n",
        "\n",
        "Treated 640px: 561Êûö„ÄÇ„ÉÜ„Çπ„Éà„Å´50Êûö„ÇíÊÆã„ÅôÔºàtest_olympiaÔºâ„ÄÅÊÆã„Çä„ÅÆ511Êûö„Çítrain/val„Å´Âõû„Åô\n",
        "\n",
        "Control 640px: 169Êûö„ÄÇ„ÉÜ„Çπ„Éà„Å´50Êûö„ÇíÊÆã„Åô(test_control)„ÄÅÊÆã„Çä„ÅÆ119Êûö„Çítrain/val„Å´Âõû„Åô\n",
        "\n",
        "#Handai\n",
        "„ÉªGO_extended_dataset\n",
        "\n",
        "control: 1886Êûö„ÄÇ„ÉÜ„Çπ„Éà„Å´50Êûö„ÇíÊÆã„Åô(test_handai)„ÄÅÊÆã„Çä„ÅÆ1836Êûö„Çítrain/val„Å´Âõû„Åô\n",
        "\n",
        "treatable: 1879Êûö„ÄÇ„ÉÜ„Çπ„Éà„Å´50Êûö„ÇíÊÆã„Åô(test_handai)„ÄÅÊÆã„Çä„ÅÆ1829Êûö„Çítrain/val„Å´Âõû„Åô\n",
        "\n",
        "\n",
        "#ÂêàË®àÔºö\n",
        "treatable: 1829 + 119\n",
        "\n",
        "control: 1836 + 511\n",
        "\n",
        "testset: Olympia treated 50, control 50, Handai treated 50, control 50\n",
        "\n",
        "##Êó¢Â≠ò„ÅÆYOLO„Åßbounding box„Çí‰ΩúÊàê --> class„ÅØÊó¢Áü•„ÅÆ„ÇÇ„ÅÆ„Åß„ÄÇGlaucoma„ÅÆrepository„ÇíÂèÇËÄÉ„Å´„Åó„Å¶YOLO dataset„Çí‰ΩúÊàê„ÄÇ"
      ],
      "metadata": {
        "id": "BW6BkO088P6u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ds7rvBFs8LcO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d43e7491-b203-4daa-d1a9-7c2ce1ee7f98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "import glob\n",
        "import random\n",
        "from PIL import Image\n",
        "import time\n",
        "%matplotlib inline\n",
        "\n",
        "#„Çµ„Éù„Éº„Éà„Éë„ÉÉ„ÉÅ„ÅÆ„Ç§„É≥„Éù„Éº„Éà\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "\n",
        "\n",
        "# Google Drive„Çí„Éû„Ç¶„É≥„Éà\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#„Éï„Ç°„Ç§„É´Êï∞Á¢∫Ë™çÁî®\n",
        "import os\n",
        "\n",
        "def countfile(name, path):\n",
        "    print(f\"path: {path}\")\n",
        "    print(f\"number: {len(os.listdir(path))}\")\n",
        "    print(\"\")\n",
        "\n",
        "if not os.path.exists(\"/content/GO_extended_dataset\"):\n",
        "    !unzip /content/drive/MyDrive/Deep_learning/GO_extended_dataset/GO_extended_dataset.zip -d /content/\n",
        "\n",
        "\n",
        "olympia_cont_dir = \"/content/drive/MyDrive/Deep_learning/Olympia_dataset/control_640px\"\n",
        "olympia_grav_dir = \"/content/drive/MyDrive/Deep_learning/Olympia_dataset/treated_640px\"\n",
        "handai_cont_dir = \"/content/GO_extended_dataset/Control_photo_1886mai\"\n",
        "handai_grav_dir = \"/content/GO_extended_dataset/treatable\"\n",
        "\n",
        "\n",
        "countfile(\"control_640px_olympia\", olympia_cont_dir)\n",
        "countfile(\"treated_640px_olympia\", olympia_grav_dir)\n",
        "\n",
        "countfile(\"control_handai\", handai_cont_dir)\n",
        "countfile(\"treated_handai\", handai_grav_dir)\n"
      ],
      "metadata": {
        "id": "JFEWXrZrz_CY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Handai dataset, Olympia dataset --> super_extend_datase_for_YOLO**"
      ],
      "metadata": {
        "id": "6pYCYtrN79vn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dst_dir = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO\"\n",
        "\n",
        "if os.path.exists(dst_dir):\n",
        "    shutil.rmtree(dst_dir)\n",
        "os.makedirs(dst_dir)\n",
        "os.makedirs(f\"{dst_dir}/train_val\")\n",
        "os.makedirs(f\"{dst_dir}/train_val/grav\")\n",
        "os.makedirs(f\"{dst_dir}/train_val/cont\")\n",
        "os.makedirs(f\"{dst_dir}/test\")\n",
        "os.makedirs(f\"{dst_dir}/test/handai/grav\")\n",
        "os.makedirs(f\"{dst_dir}/test/handai/cont\")\n",
        "os.makedirs(f\"{dst_dir}/test/olympia/grav\")\n",
        "os.makedirs(f\"{dst_dir}/test/olympia/cont\")"
      ],
      "metadata": {
        "id": "FlAqRIZbCDRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "\n",
        "random_state = 1\n",
        "\n",
        "# Control images\n",
        "src_cont = olympia_cont_dir\n",
        "test_cont = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO/test/olympia/cont\"\n",
        "trainval_cont = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO/train_val/cont\"\n",
        "\n",
        "cont_images = os.listdir(src_cont)\n",
        "random.Random(random_state).shuffle(cont_images)\n",
        "\n",
        "test_cont_images = cont_images[:50]\n",
        "trainval_cont_images = cont_images[50:]\n",
        "\n",
        "for image in tqdm(test_cont_images, desc=\"Copying test cont images\"):\n",
        "    src_path = os.path.join(src_cont, image)\n",
        "    dst_path = os.path.join(test_cont, image)\n",
        "    shutil.copy(src_path, dst_path)\n",
        "\n",
        "for image in tqdm(trainval_cont_images, desc=\"Copying trainval cont images\"):\n",
        "    src_path = os.path.join(src_cont, image)\n",
        "    dst_path = os.path.join(trainval_cont, image)\n",
        "    shutil.copy(src_path, dst_path)\n",
        "\n",
        "\n",
        "# Grav images\n",
        "src_grav = olympia_grav_dir\n",
        "test_grav = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO/test/olympia/grav\"\n",
        "trainval_grav = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO/train_val/grav\"\n",
        "\n",
        "grav_images = os.listdir(src_grav)\n",
        "random.Random(random_state).shuffle(grav_images)\n",
        "\n",
        "test_grav_images = grav_images[:50]\n",
        "trainval_grav_images = grav_images[50:]\n",
        "\n",
        "for image in tqdm(test_grav_images, desc=\"Copying test grav images\"):\n",
        "    src_path = os.path.join(src_grav, image)\n",
        "    dst_path = os.path.join(test_grav, image)\n",
        "    shutil.copy(src_path, dst_path)\n",
        "\n",
        "for image in tqdm(trainval_grav_images, desc=\"Copying trainval grav images\"):\n",
        "    src_path = os.path.join(src_grav, image)\n",
        "    dst_path = os.path.join(trainval_grav, image)\n",
        "    shutil.copy(src_path, dst_path)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sta5Z-LLC01f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0039c378-9ab5-4461-989e-3a24e78544d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Copying test cont images: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:01<00:00, 29.43it/s]\n",
            "Copying trainval cont images: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 119/119 [00:04<00:00, 29.13it/s]\n",
            "Copying test grav images: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:04<00:00, 12.35it/s]\n",
            "Copying trainval grav images: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 511/511 [00:18<00:00, 27.83it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from shutil import copyfile\n",
        "from tqdm import tqdm\n",
        "\n",
        "grav_dir = olympia_grav_dir\n",
        "cont_dir = olympia_cont_dir\n",
        "test_grav_dir = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO/test/olympia/grav\"\n",
        "test_cont_dir = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO/test/olympia/cont\"\n",
        "train_val_grav_dir = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO/train_val/grav\"\n",
        "train_val_cont_dir = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO/train_val/cont\"\n",
        "\n",
        "# Check if files in grav_dir are in test_grav_dir\n",
        "for filename in tqdm(os.listdir(grav_dir)):\n",
        "    basename = os.path.basename(filename)\n",
        "    if os.path.exists(os.path.join(test_grav_dir, basename)):\n",
        "        print(\"coooool!!!\")\n",
        "        continue\n",
        "    else:\n",
        "        copyfile(os.path.join(grav_dir, filename), os.path.join(train_val_grav_dir, filename))\n",
        "\n",
        "# Check if files in cont_dir are in test_cont_dir\n",
        "for filename in tqdm(os.listdir(cont_dir)):\n",
        "    basename = os.path.basename(filename)\n",
        "    if os.path.exists(os.path.join(test_cont_dir, basename)):\n",
        "        print(\"hotttttt!!!\")\n",
        "        continue\n",
        "    else:\n",
        "        copyfile(os.path.join(cont_dir, filename), os.path.join(train_val_cont_dir, filename))\n"
      ],
      "metadata": {
        "id": "-Ll-LhlRKSQN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#####################\n",
        "# rename\n",
        "#ÊåáÂÆö„Åï„Çå„Åü„Éï„Ç©„É´„ÉÄÂÜÖ„Å´„ÅÇ„Çã„Éï„Ç°„Ç§„É´Âêç„Åå\"olympia_\"„Åã„ÇâÂßã„Åæ„Çâ„Å™„ÅÑÂ†¥Âêà„Å´„ÄÅ\"olympia_\"„ÇíÂÖàÈ†≠„Å´„Å§„Åë„Åü„Éï„Ç°„Ç§„É´Âêç„Å´„É™„Éç„Éº„É†„Åô„ÇãÂá¶ÁêÜ„ÇíË°å„ÅÜ„ÄÇ\n",
        "#####################\n",
        "\n",
        "import os\n",
        "\n",
        "# „Éï„Ç©„É´„ÉÄ„ÅÆ„Éë„Çπ„ÇíÊåáÂÆö\n",
        "test_grav_dir = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO/test/olympia/grav\"\n",
        "test_cont_dir = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO/test/olympia/cont\"\n",
        "train_val_grav_dir = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO/train_val/grav\"\n",
        "train_val_cont_dir = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO/train_val/cont\"\n",
        "\n",
        "# „Éï„Ç°„Ç§„É´Âêç„Åå \"olympia_\" „Åã„ÇâÂßã„Åæ„Çâ„Å™„ÅÑÂ†¥Âêà„ÄÅ\"olympia_\" „ÇíÂÖàÈ†≠„Å´„Å§„Åë„Åü„Éï„Ç°„Ç§„É´Âêç„Å´„É™„Éç„Éº„É†„Åô„Çã\n",
        "def rename_file(path):\n",
        "    for filename in os.listdir(path):\n",
        "        if not filename.startswith(\"oly_\"):\n",
        "            new_filename = \"oly_\" + filename\n",
        "            os.rename(os.path.join(path, filename), os.path.join(path, new_filename))\n",
        "\n",
        "# „É™„Éç„Éº„É†Âá¶ÁêÜ„ÇíÂÆüË°å\n",
        "rename_file(test_grav_dir)\n",
        "rename_file(test_cont_dir)\n",
        "rename_file(train_val_grav_dir)\n",
        "rename_file(train_val_cont_dir)\n"
      ],
      "metadata": {
        "id": "AleU8QFERy6K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(os.listdir(\"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO/train_val/grav\")))\n",
        "print(len(os.listdir(\"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO/train_val/cont\")))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQ3tV45TLy95",
        "outputId": "82c34187-2939-4b46-9cad-89f8c06bdbf4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "511\n",
            "119\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "import os\n",
        "import random\n",
        "import shutil\n",
        "from tqdm import tqdm\n",
        "\n",
        "############################\n",
        "# Handai GO_extended_dataset\n",
        "#\n",
        "# /treatable ‚Üí /train_val/grav\n",
        "# /control ‚Üí /train_val/Control_photo_1886mai\n",
        "#\n",
        "############################\n",
        "\n",
        "if not os.path.exists(\"/content/GO_extended_dataset\"):\n",
        "    !unzip /content/drive/MyDrive/Deep_learning/GO_extended_dataset/GO_extended_dataset.zip -d /content/\n",
        "\n",
        "#file_name, class, idx„ÅÆ„Çä„Çπ„Éà„Çí‰ΩúÊàê\n",
        "def get_file_info(src_dir, class_id):\n",
        "    file_list = os.listdir(src_dir)\n",
        "    ids_list = [int(file_name.split('.')[0].split('-')[0]) for file_name in file_list]\n",
        "    class_list = [class_id] * len(file_list)\n",
        "    return file_list, ids_list, class_list\n",
        "\n",
        "# Cont„Éï„Ç©„É´„ÉÄ„ÅÆÊÉÖÂ†±\n",
        "cont_dir = '/content/GO_extended_dataset/Control_photo_1886mai'\n",
        "file_list_cont, ids_list_cont, class_list_cont = get_file_info(cont_dir, 0)\n",
        "\n",
        "# Grav„Éï„Ç©„É´„ÉÄ„ÅÆÊÉÖÂ†±\n",
        "grav_dir = '/content/GO_extended_dataset/treatable'\n",
        "file_list_grav, ids_list_grav, class_list_grav = get_file_info(grav_dir, 1)\n",
        "\n",
        "# ÁµêÂêà\n",
        "file_list = file_list_cont + file_list_grav\n",
        "ids_list = ids_list_cont + ids_list_grav\n",
        "class_list = class_list_cont + class_list_grav\n",
        "\n",
        "print(file_list)\n",
        "print(ids_list)\n",
        "print(class_list)\n",
        "\n",
        "\n",
        "\n",
        "import random\n",
        "\n",
        "# file_list„Å´ÁîªÂÉè„ÅÆ„Éë„Çπ„Åå„ÄÅids_list„Å´ÊÇ£ËÄÖ„ÅÆid„Åå„ÄÅclass_list„Å´grav„Åãcont„Åã(0 or 1)„ÅåÊ†ºÁ¥ç„Åï„Çå„Å¶„ÅÑ„Çã„Å®‰ªÆÂÆö„Åô„Çã\n",
        "# ‰æã: file_list = ['/path/to/image1.jpg', '/path/to/image2.jpg', ...]\n",
        "#     ids_list = ['patient1', 'patient1', 'patient2', 'patient3', ...]\n",
        "#     class_list = [0, 1, 0, 1, ...]\n",
        "\n",
        "# „É©„É≥„ÉÄ„É†„Ç∑„Éº„Éâ„ÇíÂõ∫ÂÆö„Åô„Çã\n",
        "random.seed(1234)\n",
        "\n",
        "# id„Åî„Å®„Å´ÁîªÂÉè„ÅÆ„É™„Çπ„Éà„Çí„Åæ„Å®„ÇÅ„Çã\n",
        "id_to_files = {}\n",
        "for i, id in enumerate(ids_list):\n",
        "    if id not in id_to_files:\n",
        "        id_to_files[id] = []\n",
        "    id_to_files[id].append((file_list[i], class_list[i]))\n",
        "\n",
        "# id„Åî„Å®„Å´ÁîªÂÉè„Çítest„Åãtrain„Å´ÊåØ„ÇäÂàÜ„Åë„Çã\n",
        "test_files = []\n",
        "train_files = []\n",
        "for id in id_to_files:\n",
        "    files = id_to_files[id]\n",
        "    random.shuffle(files)  # Âêå„ÅòidÂÜÖ„ÅÆÁîªÂÉè„ÅÆÈ†ÜÁï™„Çí„É©„É≥„ÉÄ„É†„Å´‰∏¶„ÅπÊõø„Åà„Çã\n",
        "    for file, cls in files:\n",
        "        if len(test_files) < 50 or cls == 0:\n",
        "            test_files.append((file, cls))\n",
        "        else:\n",
        "            train_files.append((file, cls))\n",
        "\n",
        "# Á¢∫Ë™ç\n",
        "print(len(test_files), len(train_files))  # 50 ‰ª•‰∏ä„ÅÆÂ†¥Âêà„ÅØÂÜçÂÆüË°å„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ"
      ],
      "metadata": {
        "id": "DjeQtXC5F_7d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "import numpy as np\n",
        "from sklearn.model_selection import GroupShuffleSplit\n",
        "\n",
        "############################\n",
        "# Handai GO_extended_dataset\n",
        "#\n",
        "# /treatable ‚Üí /train_val/grav\n",
        "# /control ‚Üí /train_val/Control_photo_1886mai\n",
        "#\n",
        "############################\n",
        "\n",
        "if not os.path.exists(\"/content/GO_extended_dataset\"):\n",
        "    !unzip /content/drive/MyDrive/Deep_learning/GO_extended_dataset/GO_extended_dataset.zip -d /content/\n",
        "\n",
        "# Cont„Éï„Ç©„É´„ÉÄ„ÅÆ„Éë„Çπ\n",
        "src_dir = '/content/GO_extended_dataset/Control_photo_1886mai'\n",
        "train_val_dir = '/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO/train_val/cont'\n",
        "test_dir = '/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO/test/handai/cont'\n",
        "\n",
        "# „Éï„Ç°„Ç§„É´„É™„Çπ„Éà„ÇíÂèñÂæó„Åó„ÄÅID„ÇíÊäΩÂá∫„Åó„Å¶„É™„Çπ„Éà„Å´Ê†ºÁ¥ç\n",
        "file_list = os.listdir(src_dir)\n",
        "ids = [int(file_name.split('.')[0].split('-', 1)[0]) for file_name in file_list]\n",
        "\n",
        "# ID„Åî„Å®„Å´„Ç∞„É´„Éº„Éó„Çí‰ΩúÊàê„Åó„Å¶„ÄÅgroup-stratified„Å´ÂàÜÂâ≤\n",
        "splitter = GroupShuffleSplit(n_splits=1, test_size=50, random_state=2)\n",
        "train_val_indices, test_indices = next(splitter.split(file_list, groups=ids))\n",
        "\n",
        "# Â≠¶ÁøíÁî®„Å®„ÉÜ„Çπ„ÉàÁî®„ÅÆ„Éï„Ç©„É´„ÉÄ„Å´„Éï„Ç°„Ç§„É´„Çí„Ç≥„Éî„Éº\n",
        "for i, file_name in tqdm(enumerate(file_list), total=len(file_list)):\n",
        "    src_path = os.path.join(src_dir, file_name)\n",
        "    dst_dir = test_dir if i in test_indices else train_val_dir\n",
        "    dst_path = os.path.join(dst_dir, file_name)\n",
        "    shutil.copy(src_path, dst_path)\n",
        "\n",
        "# Grav„Éï„Ç©„É´„ÉÄ„ÅÆ„Éë„Çπ\n",
        "src_dir = '/content/GO_extended_dataset/treatable'\n",
        "train_val_dir = '/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO/train_val/grav'\n",
        "test_dir = '/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO/test/handai/grav'\n",
        "\n",
        "# „Éï„Ç°„Ç§„É´„É™„Çπ„Éà„ÇíÂèñÂæó„Åó„ÄÅID„ÇíÊäΩÂá∫„Åó„Å¶„É™„Çπ„Éà„Å´Ê†ºÁ¥ç\n",
        "file_list = os.listdir(src_dir)\n",
        "ids = [int(file_name.split('.')[0].split('-', 1)[0]) for file_name in file_list]\n",
        "\n",
        "# ID„Åî„Å®„Å´„Ç∞„É´„Éº„Éó„Çí‰ΩúÊàê„Åó„Å¶„ÄÅgroup-stratified„Å´ÂàÜÂâ≤\n",
        "splitter = GroupShuffleSplit(n_splits=1, test_size=15, random_state=4)\n",
        "train_val_indices, test_indices = next(splitter.split(file_list, groups=ids))\n",
        "print(len(test_indices))\n",
        "\n",
        "# Â≠¶ÁøíÁî®„Å®„ÉÜ„Çπ„ÉàÁî®„ÅÆ„Éï„Ç©„É´„ÉÄ„Å´„Éï„Ç°„Ç§„É´„Çí„Ç≥„Éî„Éº\n",
        "for i, file_name in tqdm(enumerate(file_list), total=len(file_list)):\n",
        "    src_path = os.path.join(src_dir, file_name)\n",
        "    dst_dir = test_dir if i in test_indices else train_val_dir\n",
        "    dst_path = os.path.join(dst_dir, file_name)\n",
        "    shutil.copy(src_path, dst_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dy5IinNPpPgO",
        "outputId": "e06a6648-32e7-4c03-ffc9-3ef8486a889d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1886/1886 [00:39<00:00, 48.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1879/1879 [00:49<00:00, 37.81it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #ÔºàGroupShuffleSplit„Åågroup„Åî„Å®„Å´ÂàÜÂâ≤„Åô„Çã„ÅÆ„ÅßÔºâÁ∑èÊï∞„Åå50„Å´„Å™„Çã„Çà„ÅÜ„Å´random_state„Å®test_size„ÇíË™øÁØÄ\n",
        "# # ÁµêÊûú„ÅÆÊ†ºÁ¥çÁî®„É™„Çπ„Éà\n",
        "# # Grav„Éï„Ç©„É´„ÉÄ„ÅÆ„Éë„Çπ\n",
        "# src_dir = '/content/GO_extended_dataset/treatable'\n",
        "# train_val_dir = '/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO/train_val/grav'\n",
        "# test_dir = '/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO/test/handai/grav'\n",
        "\n",
        "# # „Éï„Ç°„Ç§„É´„É™„Çπ„Éà„ÇíÂèñÂæó„Åó„ÄÅID„ÇíÊäΩÂá∫„Åó„Å¶„É™„Çπ„Éà„Å´Ê†ºÁ¥ç\n",
        "# file_list = os.listdir(src_dir)\n",
        "# ids = [int(file_name.split('.')[0].split('-', 1)[0]) for file_name in file_list]\n",
        "\n",
        "# results = []\n",
        "\n",
        "# for random_state in range(10):\n",
        "#     for test_size in range(1, 51):\n",
        "#         splitter = GroupShuffleSplit(n_splits=1, test_size=test_size, random_state=random_state)\n",
        "#         train_val_indices, test_indices = next(splitter.split(file_list, groups=ids))\n",
        "#         test_set_size = len(test_indices)\n",
        "#         print(f\"random_state: {random_state}, test_size: {test_size}, test_set_size: {test_set_size}\")\n",
        "#         if test_set_size == 50:\n",
        "#             print(\"Coooool!!\")\n",
        "#             results.append((random_state, test_size))\n",
        "\n",
        "# # ÁµêÊûú„ÅÆË°®Á§∫\n",
        "# for result in results:\n",
        "#     print(f\"random_state: {result[0]}, test_size: {result[1]}\")\n"
      ],
      "metadata": {
        "id": "MMk9fpa9zkZ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**„Éï„Ç°„Ç§„É´Êï∞„ÅÆÁ¢∫Ë™ç**"
      ],
      "metadata": {
        "id": "jQkGRfUO9omP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dir = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO\"\n",
        "print(len(os.listdir(f\"{dir}/train_val/grav\")))\n",
        "print(len(os.listdir(f\"{dir}/train_val/cont\")))\n",
        "print(len(os.listdir(f\"{dir}/test/olympia/grav\")))\n",
        "print(len(os.listdir(f\"{dir}/test/olympia/cont\")))\n",
        "print(len(os.listdir(f\"{dir}/test/handai/grav\")))\n",
        "print(len(os.listdir(f\"{dir}/test/handai/cont\")))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aGGR7_-P96mS",
        "outputId": "d2b42e18-d6a6-4d7a-e411-3812422d9fa2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2342\n",
            "1958\n",
            "50\n",
            "50\n",
            "50\n",
            "50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Êó¢Â≠ò„ÅÆYOLOv5„É¢„Éá„É´„ÇíÁî®„ÅÑ„Å¶„Éê„Ç¶„É≥„Éá„Ç£„É≥„Ç∞„Éú„ÉÉ„ÇØ„Çπ„ÇíË®≠ÂÆö**"
      ],
      "metadata": {
        "id": "R6FT8pBYNvF7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dst_dir = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO/train_val/labels\"\n",
        "if os.path.exists(dst_dir):\n",
        "    shutil.rmtree(dst_dir)\n",
        "os.makedirs(f\"{dst_dir}/grav\")\n",
        "os.makedirs(f\"{dst_dir}/cont\")"
      ],
      "metadata": {
        "id": "-wggPJzAOBYf"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup YOLOv5\n",
        "%cd /content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training\n",
        "!git clone https://github.com/ultralytics/yolov5\n",
        "%cd yolov5\n",
        "%pip install -qr requirements.txt\n",
        "\n",
        "import torch\n",
        "import utils\n",
        "display = utils.notebook_init()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1gF6whZ7P5ax",
        "outputId": "d03c760f-549b-4ac6-ca9e-70dab52aafe2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv5 üöÄ v7.0-72-g064365d Python-3.10.11 torch-2.0.1+cu118 CPU\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete ‚úÖ (2 CPUs, 12.7 GB RAM, 23.4/107.7 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from models.common import DetectMultiBackend\n",
        "#from utils.datasets import IMG_FORMATS, VID_FORMATS, LoadImages, LoadStreams\n",
        "from utils.general import (LOGGER, check_file, check_img_size, check_imshow, check_requirements, colorstr,\n",
        "                           increment_path, non_max_suppression, print_args, strip_optimizer, xyxy2xywh)\n",
        "#from utils.plots import Annotator, colors, save_one_box\n",
        "from utils.torch_utils import select_device, time_sync\n",
        "from utils.augmentations import letterbox #padding\n",
        "\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torchvision import models, transforms\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "#„Çµ„Éù„Éº„Éà„Éë„ÉÉ„ÉÅ„ÅÆ„Ç§„É≥„Éù„Éº„Éà\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "\n",
        "def interference(img, weight):\n",
        "    device = 'cpu'\n",
        "    device = select_device(device)\n",
        "    model = DetectMultiBackend(weight, device=device, dnn=False)\n",
        "    #stride, names, pt, jit, onnx, engine = model.stride, model.names, model.pt, model.jit, model.onnx, model.engine\n",
        "    #imgsz = check_img_size([640], s=stride)  # check image size\n",
        "\n",
        "    #class_names = {0:\"cont\", 1:\"grav\"}\n",
        "\n",
        "    # transform = transforms.Compose([\n",
        "    #             transforms.Resize(size=(480,640)),\n",
        "    #             transforms.ToTensor(),\n",
        "    #             # transforms.Normalize(\n",
        "    #             #     mean=[0.5, 0.5, 0.5],\n",
        "    #             #     std=[0.5, 0.5, 0.5]\n",
        "    #             #    )\n",
        "    #             ])\n",
        "\n",
        "    img_cv2 = cv2.imread(img) #CV2„ÅßÈñã„Åè\n",
        "    img_cv2 = letterbox(img_cv2, (640,640), stride=32, auto=False)[0] #resize, ‰∏ä‰∏ãpadding (color 114)\n",
        "\n",
        "    #cv2_imshow(img_cv2)\n",
        "\n",
        "    img_cv2 = img_cv2.transpose((2, 0, 1))[::-1]  # HWC to CHW, BGR to RGB\n",
        "    img_cv2 = np.ascontiguousarray(img_cv2)\n",
        "    img_tensor = torch.from_numpy(img_cv2).float()\n",
        "\n",
        "    #img_tensor = transform(img_np)\n",
        "    img_tensor /= 255\n",
        "    #print(img_tensor.shape)\n",
        "\n",
        "    #print(img_tensor)\n",
        "    img_tensor = torch.unsqueeze(img_tensor, 0)  # „Éê„ÉÉ„ÉÅÂØæÂøú\n",
        "\n",
        "\n",
        "    pred = model(img_tensor, visualize=False, augment=False)\n",
        "\n",
        "    pred = non_max_suppression(pred, conf_thres=0.25, iou_thres=0.45, classes=None,  max_det=1000)\n",
        "\n",
        "    print(f\"pred: {pred}\")\n",
        "\n",
        "    return pred"
      ],
      "metadata": {
        "id": "Yo05tVYVaD1N"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def interference_thres(img, weight):\n",
        "    device = 'cpu'\n",
        "    device = select_device(device)\n",
        "    model = DetectMultiBackend(weight, device=device, dnn=False)\n",
        "    #stride, names, pt, jit, onnx, engine = model.stride, model.names, model.pt, model.jit, model.onnx, model.engine\n",
        "    #imgsz = check_img_size([640], s=stride)  # check image size\n",
        "\n",
        "    #class_names = {0:\"cont\", 1:\"grav\"}\n",
        "\n",
        "    # transform = transforms.Compose([\n",
        "    #             transforms.Resize(size=(480,640)),\n",
        "    #             transforms.ToTensor(),\n",
        "    #             # transforms.Normalize(\n",
        "    #             #     mean=[0.5, 0.5, 0.5],\n",
        "    #             #     std=[0.5, 0.5, 0.5]\n",
        "    #             #    )\n",
        "    #             ])\n",
        "\n",
        "    img_cv2 = cv2.imread(img) #CV2„ÅßÈñã„Åè\n",
        "    img_cv2 = letterbox(img_cv2, (640,640), stride=32, auto=False)[0] #resize, ‰∏ä‰∏ãpadding (color 114)\n",
        "\n",
        "    #cv2_imshow(img_cv2)\n",
        "\n",
        "    img_cv2 = img_cv2.transpose((2, 0, 1))[::-1]  # HWC to CHW, BGR to RGB\n",
        "    img_cv2 = np.ascontiguousarray(img_cv2)\n",
        "    img_tensor = torch.from_numpy(img_cv2).float()\n",
        "\n",
        "    #img_tensor = transform(img_np)\n",
        "    img_tensor /= 255\n",
        "    #print(img_tensor.shape)\n",
        "\n",
        "    #print(img_tensor)\n",
        "    img_tensor = torch.unsqueeze(img_tensor, 0)  # „Éê„ÉÉ„ÉÅÂØæÂøú\n",
        "\n",
        "\n",
        "    pred = model(img_tensor, visualize=False, augment=False)\n",
        "\n",
        "    pred = non_max_suppression(pred, conf_thres=0.15, iou_thres=0.25, classes=None,  max_det=1000)\n",
        "\n",
        "    #print(f\"pred: {pred}\")\n",
        "\n",
        "    return pred"
      ],
      "metadata": {
        "id": "P-HTdamj-mfN"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "YOLOv5_model_path = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training/yolov5n_130epch.pt\"\n",
        "parent_dir = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO/train_val\"\n",
        "\n",
        "for class_name in [\"grav\", \"cont\"]:\n",
        "    if class_name == \"cont\":\n",
        "        class_num = 0\n",
        "    else:\n",
        "        class_num = 1\n",
        "    for image_path in glob.glob(f\"{parent_dir}/{class_name}/*\"):\n",
        "        name = os.path.splitext(os.path.basename(image_path))[0]\n",
        "        print(f\"image_name: {name}\")\n",
        "\n",
        "        #YOLOv5„Å´„Çà„Çä„Éê„Ç¶„É≥„Éá„Ç£„É≥„Ç∞„Éú„ÉÉ„ÇØ„Çπ„ÇíÊäú„ÅçÂá∫„Åô\n",
        "        try:\n",
        "            pred = interference(image_path, YOLOv5_model_path)[0].tolist()[0]\n",
        "        except: #ÈÄöÂ∏∏„ÅÆÈñæÂÄ§Ë®≠ÂÆö„ÅßÊ§úÂá∫„Åï„Çå„Å™„ÅÑÂ†¥Âêà\n",
        "            pred = interference_thres(image_path, YOLOv5_model_path)[0].tolist()[0]\n",
        "        pred = [max(num, 0) for num in pred] #0„Çà„ÇäÂ∞è„Åï„ÅÑÂ∫ßÊ®ô„ÅØ0„Å´‰øÆÊ≠£„Åô„Çã\n",
        "        pred = [min(num, 640) for num in pred] #640„Çà„ÇäÂ∞è„Åï„ÅÑÂ∫ßÊ®ô„ÅØ640„Å´‰øÆÊ≠£„Åô„Çã\n",
        "        xcenter = (pred[0]+pred[2])/2\n",
        "        ycenter = (pred[1]+pred[3])/2\n",
        "        xwidth = pred[2]-pred[0]\n",
        "        ywidth = pred[3]-pred[1]\n",
        "        \n",
        "        # „Éï„Ç°„Ç§„É´Âêç„Å®‰ΩúÊàê„Åô„ÇãÂÜÖÂÆπ„ÇíÊåáÂÆö\n",
        "        txt_name = f\"{parent_dir}/labels/{class_name}/{name}.txt\"\n",
        "        content = f\"{class_num} {round(xcenter)} {round(ycenter)} {round(xwidth)} {round(ywidth)}\"\n",
        "        with open(txt_name, \"w\") as file:\n",
        "            # „ÉÜ„Ç≠„Çπ„Éà„Çí„Éï„Ç°„Ç§„É´„Å´Êõ∏„ÅçËæº„ÇÄ\n",
        "            file.write(content)\n",
        "            print(f\"text file successfully createdüôÜ {content}\")\n",
        "            print(\"\")\n",
        "            print(\"\")\n",
        "        "
      ],
      "metadata": {
        "id": "wlGbrrAWRtHT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = interference(image_path, YOLOv5_model_path)[0].tolist()[0]"
      ],
      "metadata": {
        "id": "UH2bvRVvIRnX",
        "outputId": "c2b84361-2973-457b-9697-a26fc9f5c0f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv5 üöÄ v7.0-72-g064365d Python-3.10.11 torch-2.0.1+cu118 CPU\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 1761871 parameters, 0 gradients, 4.1 GFLOPs\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-c99fedc93d31>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minterference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYOLOv5_model_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-13-0e323a5b696c>\u001b[0m in \u001b[0;36minterference\u001b[0;34m(img, weight)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;31m#             ])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0mimg_cv2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#CV2„ÅßÈñã„Åè\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0mimg_cv2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mletterbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_cv2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m640\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m640\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauto\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#resize, ‰∏ä‰∏ãpadding (color 114)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training/yolov5/utils/general.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(path, flags)\u001b[0m\n\u001b[1;32m   1116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1117\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIMREAD_COLOR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1118\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.7.0) /io/opencv/modules/imgcodecs/src/loadsave.cpp:798: error: (-215:Assertion failed) !buf.empty() in function 'imdecode_'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "interference_thres(image_path, YOLOv5_model_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KfWGEPR361WW",
        "outputId": "f21deca8-f079-487d-a550-5e13c613591a"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv5 üöÄ v7.0-72-g064365d Python-3.10.11 torch-2.0.1+cu118 CPU\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 1761871 parameters, 0 gradients, 4.1 GFLOPs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([[  8.11356, 186.25688, 635.81311, 470.85193,   0.88355,   0.00000]])]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**YOLOv5„Éà„É¨„Éº„Éã„É≥„Ç∞Áî®„Å´„Éï„Ç©„É´„ÉÄ„Çí‰ΩúÊàê**\n",
        "\n",
        "„Éê„Ç¶„É≥„Éá„Ç£„É≥„Ç∞„Éú„ÉÉ„ÇØ„ÇπÊ±∫ÂÆö„Å´„ÅØ‰ª•Ââç„Å´‰ΩúÊàê„Åó„ÅüYOLOv5„É¢„Éá„É´„ÇíÁî®„ÅÑ„Çã\n"
      ],
      "metadata": {
        "id": "hPB-WI5z1agI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup YOLOv5\n",
        "%cd /content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training\n",
        "!git clone https://github.com/ultralytics/yolov5\n",
        "%cd yolov5\n",
        "%pip install -qr requirements.txt\n",
        "\n",
        "import torch\n",
        "import utils\n",
        "display = utils.notebook_init()"
      ],
      "metadata": {
        "id": "yCB5xW-2-H25",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57f2fad5-e9fe-4715-97c5-e682914ac231"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv5 üöÄ v7.0-72-g064365d Python-3.10.11 torch-2.0.1+cu118 CPU\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete ‚úÖ (2 CPUs, 12.7 GB RAM, 30.8/107.7 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from models.common import DetectMultiBackend\n",
        "#from utils.datasets import IMG_FORMATS, VID_FORMATS, LoadImages, LoadStreams\n",
        "from utils.general import (LOGGER, check_file, check_img_size, check_imshow, check_requirements, colorstr,\n",
        "                           increment_path, non_max_suppression, print_args, strip_optimizer, xyxy2xywh)\n",
        "#from utils.plots import Annotator, colors, save_one_box\n",
        "from utils.torch_utils import select_device, time_sync\n",
        "from utils.augmentations import letterbox #padding\n",
        "\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torchvision import models, transforms\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "#„Çµ„Éù„Éº„Éà„Éë„ÉÉ„ÉÅ„ÅÆ„Ç§„É≥„Éù„Éº„Éà\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "\n",
        "def interference(img, weight):\n",
        "    device = 'cpu'\n",
        "    device = select_device(device)\n",
        "    model = DetectMultiBackend(weight, device=device, dnn=False)\n",
        "    #stride, names, pt, jit, onnx, engine = model.stride, model.names, model.pt, model.jit, model.onnx, model.engine\n",
        "    #imgsz = check_img_size([640], s=stride)  # check image size\n",
        "\n",
        "    #class_names = {0:\"cont\", 1:\"grav\"}\n",
        "\n",
        "    # transform = transforms.Compose([\n",
        "    #             transforms.Resize(size=(480,640)),\n",
        "    #             transforms.ToTensor(),\n",
        "    #             # transforms.Normalize(\n",
        "    #             #     mean=[0.5, 0.5, 0.5],\n",
        "    #             #     std=[0.5, 0.5, 0.5]\n",
        "    #             #    )\n",
        "    #             ])\n",
        "\n",
        "    img_cv2 = cv2.imread(img) #CV2„ÅßÈñã„Åè\n",
        "    img_cv2 = letterbox(img_cv2, (640,640), stride=32, auto=False)[0] #resize, ‰∏ä‰∏ãpadding (color 114)\n",
        "\n",
        "    #cv2_imshow(img_cv2)\n",
        "\n",
        "    img_cv2 = img_cv2.transpose((2, 0, 1))[::-1]  # HWC to CHW, BGR to RGB\n",
        "    img_cv2 = np.ascontiguousarray(img_cv2)\n",
        "    img_tensor = torch.from_numpy(img_cv2).float()\n",
        "\n",
        "    #img_tensor = transform(img_np)\n",
        "    img_tensor /= 255\n",
        "    #print(img_tensor.shape)\n",
        "\n",
        "    #print(img_tensor)\n",
        "    img_tensor = torch.unsqueeze(img_tensor, 0)  # „Éê„ÉÉ„ÉÅÂØæÂøú\n",
        "\n",
        "\n",
        "    pred = model(img_tensor, visualize=False, augment=False)\n",
        "\n",
        "    pred = non_max_suppression(pred, conf_thres=0.25, iou_thres=0.45, classes=None,  max_det=1000)\n",
        "\n",
        "    #print(f\"pred: {pred}\")\n",
        "\n",
        "    return pred"
      ],
      "metadata": {
        "id": "fGY-seX8674J"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# image_path = image_list\n",
        "# img = image_path[102]\n",
        "\n",
        "YOLOv5_model_path = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training/yolov5n_130epch.pt\"\n",
        "\n",
        "parent_dir = \"/content/drive/MyDrive/Deep_learning/Olympia_dataset/for_validation/treated_640px\"\n",
        "img = f\"{parent_dir}/970.JPG\"\n",
        "\n",
        "class_names = {0:\"cont\", 1:\"grav\"}\n",
        "pred = interference(img, YOLOv5_model_path)\n",
        "\n",
        "# output result\n",
        "x1, y1, x2, y2, prob, class_num = torch.round(pred[0][0])\n",
        "\n",
        "# probability\n",
        "prob = pred[0][0][4].item()\n",
        "\n",
        "\n",
        "# class\n",
        "class_name = class_names[pred[0][0][5].item()]\n",
        "\n",
        "print(\"Ë®∫Êñ≠„ÅØ %s„ÄÅÁ¢∫Áéá„ÅØ%.1fÔºÖ„Åß„Åô„ÄÇ\" %(class_name, prob*100))\n",
        "\n",
        "img_cv2 = cv2.imread(img) \n",
        "\n",
        "# Ê®™ÂπÖ„Åå640px„Å´„Å™„Çã„Çà„ÅÜ„Å´„É™„Çµ„Ç§„Ç∫\n",
        "height, width, _ = img_cv2.shape\n",
        "resize_width = 640\n",
        "resize_height = int((height / width) * resize_width)\n",
        "resize_size = (resize_width, resize_height)\n",
        "img_cv2 = cv2.resize(img_cv2, resize_size)\n",
        "\n",
        "# calculate coordinates of the bounding box (640*640„Å´padding„Åï„Çå„Å¶„ÅÑ„ÇãÂàÜ„ÅÆÂ∫ßÊ®ô„ÇíË∂≥„Åô)\n",
        "img_height, img_width, _ = img_cv2.shape[:3]\n",
        "print(f\"img_height: {img_height}, img_width: {img_width}\")\n",
        "padding_x = (img_height - min(img_width, img_height))/2\n",
        "padding_y = (img_width - min(img_width, img_height))/2\n",
        "x1 = x1 - padding_x\n",
        "y1 = y1 - padding_y\n",
        "x2 = x2 - padding_x\n",
        "y2 = y2 - padding_y\n",
        "print(f\"x1: {x1}, y1: {y1}, x2: {x2}, y2: {y2}\")\n",
        "\n",
        "\n",
        "# draw bounding box\n",
        "cv2.rectangle(img_cv2, (int(x1), int(y1)), (int(x2), int(y2)), (255, 0, 0), 2)\n",
        "\n",
        "# show image\n",
        "cv2_imshow(img_cv2)"
      ],
      "metadata": {
        "id": "66_9Bbl069J1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**YOLOv5Áî®„Éà„É¨„Éº„Éã„É≥„Ç∞Áî®„Éï„Ç©„É´„ÉÄ‰ΩúÊàê**\n",
        "\n",
        "https://github.com/ykitaguchi77/GravCont_classification_colab/blob/master/Extend_dataset_YOLOv5%EF%BC%A0.ipynb\n",
        "\n",
        "https://book.st-hakky.com/docs/object-detection-yolov5-tutorial/"
      ],
      "metadata": {
        "id": "9XI1oisiBK1O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "\n",
        "---------------super_extend_for_YOLO_training --------train------labels\n",
        "                                              |           |--images\n",
        "                                              |            \n",
        "                                              |------valid ----labels\n",
        "                                              |           |--images\n",
        "                                              |\n",
        "                                              |--dataset.yaml\n",
        "                                              |--yolov5                                    \n",
        "\"\"\""
      ],
      "metadata": {
        "id": "nt3WfWu_Bb_p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dst_path = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_for_YOLO_training\"\n",
        "orig_grav_path = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO/train_val/grav\"\n",
        "orig_cont_path = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO/train_val/grav\""
      ],
      "metadata": {
        "id": "ZbyOJj3g_8Fj"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if os.path.exists(dst_path):\n",
        "    shutil.rmtree(dst_path)\n",
        "os.makedirs(dst_path)\n",
        "os.makedirs(f\"{dst_path}/train/images\")\n",
        "os.makedirs(f\"{dst_path}/train/labels\")\n",
        "os.makedirs(f\"{dst_path}/valid/images\")\n",
        "os.makedirs(f\"{dst_path}/valid/labels\")"
      ],
      "metadata": {
        "id": "DtXJAAtsCjP3"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd $dst_path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uVip7xMUEDgf",
        "outputId": "4e56f642-ee1d-4f6a-f593-d751435a9c33"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_for_YOLO_training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile dataset.yaml\n",
        "# path\n",
        "train: /content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_for_YOLO_training/train/images\n",
        "val: /content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_for_YOLO_training/valid/images\n",
        "\n",
        "# num of classes\n",
        "nc: 2\n",
        "\n",
        "#class names\n",
        "names: ['cont', 'grav'] # classÂêç„ÇíÂÆöÁæ©"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMwlnFiqCpxI",
        "outputId": "1deead05-a8b2-4839-b279-dedeaa5812d0"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing dataset.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# split dataset\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import glob\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "dataset_dir = dst_path = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_for_YOLO_training/train_val\"\n",
        "\n",
        "\n",
        "# def split_dataset(dataset_dir):\n",
        "#     img_list = glob.glob(f\"{dataset_dir}/images/*\")\n",
        "#     img_train, img_test = train_test_split(img_list, test_size=0.3, random_state=0)\n",
        "\n",
        "#     # img_train, img_test„Å´ÂêçÂâç„Åå‰∏ÄËá¥„Åô„Çãtxt„Éï„Ç°„Ç§„É´„ÇíÊäú„ÅçÂá∫„Åô\n",
        "#     label_train = [f\"{dataset_dir}/labels/{os.path.basename(i).split('.')[0]}.txt\" for i in img_train]\n",
        "#     label_test = [f\"{dataset_dir}/labels/{os.path.basename(i).split('.')[0]}.txt\" for i in img_test]\n",
        "\n",
        "#     print(f\"train: {len(label_train)},test: {len(label_test)}\")\n",
        "\n",
        "#     return img_train, img_test, label_train, label_test\n",
        "\n",
        "def make_path_list(dir, class_name):\n",
        "    image_list =  [file for file in glob.glob(f\"{dir}/{class_name}/images/*\") if os.path.isfile(file) == True ]\n",
        "    label_list =  [f\"{dir}/{class_name}/labels/{os.path.basename(i).split('.')[0]}.txt\" for i in image_list]\n",
        "\n",
        "    id_list = [os.path.basename(i).split(\"-\")[0].split(\".\")[0] for i in image_list]\n",
        "    \n",
        "    index = {}\n",
        "    id_idx = []\n",
        "    for item in id_list:\n",
        "        if item in index:\n",
        "            id_idx.append(index[item])\n",
        "        else:\n",
        "            index[item] = len(index) + 1\n",
        "            id_idx.append(index[item])\n",
        "    id_idx = [int(i) for i in id_idx]\n",
        "\n",
        "    return image_list, label_list, id_idx\n",
        "\n",
        "grav_image_list, grav_label_list, grav_id_idx = make_path_list(dataset_dir, \"grav\")\n",
        "cont_image_list, cont_label_list, cont_id_idx = make_path_list(dataset_dir, \"cont\")\n",
        "\n",
        "print(f\"grav: {len(grav_image_list)}\")\n",
        "print(f\"cont: {len(cont_image_list)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lb7vg1IfHSCT",
        "outputId": "866d78d4-0ae3-44b7-f007-679509292cf4"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "grav: 0\n",
            "cont: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f8hUG0YRLnUq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
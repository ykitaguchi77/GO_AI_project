{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled37.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "gpuClass": "premium",
      "gpuType": "V100",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykitaguchi77/GO_AI_project/blob/main/Train_Super_extend_dataset_iFish_YOLOv5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Train GO super-extend dataset iFish YOLOv5**\n",
        "\n",
        "Train YOLOv5 using iFish augmentation\n",
        "\n",
        "```\n",
        "iFish: https://github.com/Gil-Mor/iFish.git\n",
        "\n",
        "yolov5_iFish: https://github.com/ykitaguchi77/yolov5-iFish.git\n",
        "â€» FishAugment(distortion_range=(0, 0.3), p=0.5)\n",
        "\n",
        "```\n",
        "\n",
        "Output as CoreML"
      ],
      "metadata": {
        "id": "LXR--60tO5mS"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5xvbecME5IS",
        "outputId": "43479fe3-bf65-448c-af67-df9b2d964120",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import shutil\n",
        "import copy\n",
        "import pandas as pd\n",
        "import csv\n",
        "from random import randint\n",
        "from time import sleep\n",
        "import numpy as np\n",
        "import sys\n",
        "import torch\n",
        "\n",
        "\n",
        "import glob\n",
        "import random\n",
        "from PIL import Image\n",
        "%matplotlib inline\n",
        "\n",
        "# #ã‚µãƒãƒ¼ãƒˆãƒ‘ãƒƒãƒã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n",
        "# from google.colab.patches import cv2_imshow\n",
        "# import cv2\n",
        "\n",
        "plt.ion()   # interactive mode\n",
        "!nvidia-smi\n",
        "print(torch.cuda.is_available())\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Sep  9 12:33:34 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P0    23W / 300W |      0MiB / 16384MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0ZI4pHmFDXZ"
      },
      "source": [
        "#Google colabã‚’ãƒã‚¦ãƒ³ãƒˆ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkrhEditFGkP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d84c53a-bf2f-4b41-b54b-d15cfcb0cbf8"
      },
      "source": [
        "'''\n",
        "ãƒ»dlibã‚’ç”¨ã„ã¦ç›®ã‚’åˆ‡ã‚ŠæŠœã\n",
        "ãƒ»æ¨ªå¹…ã‚’2å€ã€ç¸¦å¹…ã‚’ä¸Šã«1å€è¿½åŠ /ä¸‹ã«0.5å€è¿½åŠ ã—ãŸä¸¡çœ¼ã®ç”»åƒãŒå«ã¾ã‚Œã‚‹ã‚ˆã†ã«åˆ‡ã‚Šå–ã‚‹ï¼ˆç›®ã®å…¨å¹…ã€çœ‰æ¯›ãŒå«ã¾ã‚Œã‚‹ã‚ˆã†ã«ï¼‰\n",
        "'''\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mt7fAuwXxNka",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2dc3e90f-9652-48e4-a3fb-3e10a8afc21c"
      },
      "source": [
        "#æ®‹ã‚Šæ™‚é–“ç¢ºèª\n",
        "!cat /proc/uptime | awk '{printf(\"æ®‹ã‚Šæ™‚é–“ : %.2f\", 12-$1/60/60)}'\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "æ®‹ã‚Šæ™‚é–“ : 11.87"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"train_images: {len(os.listdir('/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_for_YOLO_training/train/images'))}\")\n",
        "print(f\"val_images: {len(os.listdir('/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_for_YOLO_training/valid/images'))}\")\n",
        "print(f\"train_labels: {len(os.listdir('/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_for_YOLO_training/train/labels'))}\")\n",
        "print(f\"val_labels: {len(os.listdir('/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_for_YOLO_training/valid/labels'))}\")\n",
        "\n",
        "def check_basename(image_dir, label_dir):\n",
        "    # ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ™ãƒ¼ã‚¹ãƒãƒ¼ãƒ ä¸€è¦§ã‚’å–å¾—\n",
        "    image_files = [os.path.splitext(file)[0] for file in os.listdir(image_dir) if os.path.isfile(os.path.join(image_dir, file))]\n",
        "    image_files = set(image_files)  # é‡è¤‡ã‚’å‰Šé™¤\n",
        "\n",
        "    # ãƒ©ãƒ™ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ™ãƒ¼ã‚¹ãƒãƒ¼ãƒ ä¸€è¦§ã‚’å–å¾—\n",
        "    label_files = [os.path.splitext(file)[0] for file in os.listdir(label_dir) if os.path.isfile(os.path.join(label_dir, file))]\n",
        "    label_files = set(label_files)  # é‡è¤‡ã‚’å‰Šé™¤\n",
        "\n",
        "    # ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ™ãƒ¼ã‚¹ãƒãƒ¼ãƒ ãŒå®Œå…¨ã«ä¸€è‡´ã™ã‚‹ã‹ç¢ºèª\n",
        "    match = image_files == label_files\n",
        "\n",
        "    if match:\n",
        "        print(\"ã™ã¹ã¦ã®ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ™ãƒ¼ã‚¹ãƒãƒ¼ãƒ ãŒä¸€è‡´ã—ã¦ã„ã¾ã™ã€‚\")\n",
        "    else:\n",
        "        print(\"ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ™ãƒ¼ã‚¹ãƒãƒ¼ãƒ ãŒä¸€è‡´ã—ã¦ã„ã¾ã›ã‚“ã€‚\")\n",
        "\n",
        "check_basename('/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_for_YOLO_training/train/images', '/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_for_YOLO_training/train/labels')\n",
        "check_basename('/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_for_YOLO_training/valid/images', '/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_for_YOLO_training/valid/labels')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8WcREJmtMLv",
        "outputId": "de7bf91f-f32c-4baf-e4ac-8ed64d245062"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_images: 3498\n",
            "val_images: 795\n",
            "train_labels: 3498\n",
            "val_labels: 795\n",
            "ã™ã¹ã¦ã®ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ™ãƒ¼ã‚¹ãƒãƒ¼ãƒ ãŒä¸€è‡´ã—ã¦ã„ã¾ã™ã€‚\n",
            "ã™ã¹ã¦ã®ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ™ãƒ¼ã‚¹ãƒãƒ¼ãƒ ãŒä¸€è‡´ã—ã¦ã„ã¾ã™ã€‚\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "directory = '/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_for_YOLO_training/train/labels'\n",
        "\n",
        "# ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—\n",
        "files = os.listdir(directory)\n",
        "\n",
        "# ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚“ã§è¡¨ç¤º\n",
        "for file in files:\n",
        "    if file.endswith('.txt'):\n",
        "        file_path = os.path.join(directory, file)\n",
        "        with open(file_path, 'r') as f:\n",
        "            content = f.read().strip()\n",
        "            if content:\n",
        "                print(f\"ãƒ•ã‚¡ã‚¤ãƒ«å: {file}\\nå†…å®¹: {content}\\n\")\n",
        "            else:\n",
        "                print(f\"ãƒ•ã‚¡ã‚¤ãƒ«å: {file}\\nã‚¨ãƒ©ãƒ¼: ãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ãŒç©ºæ¬„ã§ã™ã€‚\\n\")\n",
        "                sys.exit(1)  # ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’ä¸­æ­¢\n"
      ],
      "metadata": {
        "id": "E-NkFCNSwQLy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Albumentationã«ã‚ˆã‚‹ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µ**\n",
        "\n",
        "(YOLOv5-iFish https://github.com/ykitaguchi77/yolov5-iFish.git ã«çµ„ã¿è¾¼ã¿æ¸ˆã¿)"
      ],
      "metadata": {
        "id": "ORyTzZcA7sPv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "from albumentations import DualTransform\n",
        "from math import sqrt\n",
        "import albumentations as A\n",
        "\n",
        "\n",
        "class FishEyeEffect(DualTransform):\n",
        "    def __init__(self, always_apply=False, p=0.5):\n",
        "        super(FishEyeEffect, self).__init__(always_apply, p)\n",
        "        self.image_shape = None  # Initialize the instance variable to store image shape\n",
        "\n",
        "\n",
        "    def get_fish_xn_yn(self, source_x, source_y, radius, distortion):\n",
        "        if 1 - distortion*(radius**2) == 0:\n",
        "            return source_x, source_y\n",
        "        return source_x / (1 - (distortion*(radius**2))), source_y / (1 - (distortion*(radius**2)))\n",
        "\n",
        "    def get_original_xn_yn(self, dest_x, dest_y, radius, distortion):\n",
        "        return dest_x * (1 - distortion * (radius**2)), dest_y * (1 - distortion * (radius**2))\n",
        "\n",
        "\n",
        "    def apply(self, img, distortion=0, **params):\n",
        "        self.image_shape = img.shape  # set image shape here\n",
        "        # your fish-eye effect implementation here\n",
        "        dstimg = np.zeros_like(img)\n",
        "        w, h = float(img.shape[0]), float(img.shape[1])\n",
        "        for x in range(len(dstimg)):\n",
        "            for y in range(len(dstimg[x])):\n",
        "                xnd, ynd = float((2*x - w)/w), float((2*y - h)/h)\n",
        "                rd = sqrt(xnd**2 + ynd**2)\n",
        "                xdu, ydu = self.get_fish_xn_yn(xnd, ynd, rd, distortion)\n",
        "                xu, yu = int(((xdu + 1)*w)/2), int(((ydu + 1)*h)/2)\n",
        "                if 0 <= xu < img.shape[0] and 0 <= yu < img.shape[1]:\n",
        "                    dstimg[x][y] = img[xu][yu]\n",
        "        return dstimg\n",
        "\n",
        "    def apply_to_bbox(self, bbox, distortion=0, **params):\n",
        "        img_h, img_w = self.image_shape[:2]  # Use the stored image shape\n",
        "\n",
        "        # YOLOå½¢å¼ã‹ã‚‰4ã¤ã®è§’ã®åº§æ¨™ã‚’å–å¾—\n",
        "        x_min, y_min, x_max, y_max = bbox\n",
        "\n",
        "        # 4ã¤ã®è§’ã®åº§æ¨™ã‚’æ­£è¦åŒ–\n",
        "        corners = [(x_min, y_min),\n",
        "                  (x_max, y_min),\n",
        "                  (x_min, y_max),\n",
        "                  (x_max, y_max)]\n",
        "\n",
        "        # æ­£è¦åŒ–ã•ã‚ŒãŸåº§æ¨™ã‚’é­šçœ¼å¤‰æ›ç”¨ã«å¤‰æ›\n",
        "        corners = [(2*x - 1, 2*y - 1) for x, y in corners]\n",
        "\n",
        "        print(\"Transformed corners:\", corners)\n",
        "\n",
        "        # å„è§’ã‚’FishEyeã§é€†å¤‰æ›\n",
        "        distorted_corners = [self.get_original_xn_yn(x, y, sqrt(x**2 + y**2), distortion) for x, y in corners]\n",
        "\n",
        "        print(\"Distorted corners:\", distorted_corners)\n",
        "\n",
        "        # é€†å¤‰æ›ã•ã‚ŒãŸç‚¹ã‚’å«ã‚€æœ€å°ã®é•·æ–¹å½¢ã‚’æ±‚ã‚ã‚‹\n",
        "        x_min_new = min(x for x, y in distorted_corners)\n",
        "        x_max_new = max(x for x, y in distorted_corners)\n",
        "        y_min_new = min(y for x, y in distorted_corners)\n",
        "        y_max_new = max(y for x, y in distorted_corners)\n",
        "\n",
        "        # é­šçœ¼é€†å¤‰æ›å¾Œã®åº§æ¨™ã‚’ç”»åƒåº§æ¨™ç³»ã«æˆ»ã™\n",
        "        x_min_new = (x_min_new + 1) / 2\n",
        "        x_max_new = (x_max_new + 1) / 2\n",
        "        y_min_new = (y_min_new + 1)  / 2\n",
        "        y_max_new = (y_max_new + 1)  / 2\n",
        "\n",
        "        print(x_min_new, y_min_new, x_max_new, y_max_new)\n",
        "\n",
        "        return x_min_new, y_min_new, x_max_new, y_max_new\n",
        "\n",
        "\n",
        "    def get_params(self):\n",
        "        # Random distortion coefficient between 0 and 0.3\n",
        "        return {'distortion': random.uniform(0, 0.3)}\n",
        "\n",
        "\n",
        "# å¤‰æ›ã™ã‚‹é–¢æ•°ã‚’å®šç¾©\n",
        "transform = A.Compose([\n",
        "    #A.RandomCrop(width=400, height=400),\n",
        "    FishEyeEffect(p=1),\n",
        "    #A.HorizontalFlip(p=1),\n",
        "    #A.VerticalFlip(p=1),\n",
        "    A.RandomBrightnessContrast(p=1),\n",
        "], bbox_params=A.BboxParams(format='yolo',min_area=1024,\n",
        "min_visibility=0.1, label_fields=['class_labels']))\n",
        "\n",
        "\n",
        "\n",
        "# ç”»åƒèª­ã¿è¾¼ã¿\n",
        "image = cv2.imread(\"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_for_YOLO_training/train/images/1043.jpg\")\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# yoloã®ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿\n",
        "f = open('/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_for_YOLO_training/train/labels/1043.txt', 'r')\n",
        "anno_lists = f.readlines()\n",
        "f.close()\n",
        "\n",
        "# ç©ºã®é…åˆ—ã‚’ç”¨æ„\n",
        "bboxes = []\n",
        "class_labels = []\n",
        "\n",
        "# ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã«ä¸ãˆã‚‹å½¢ã«å¤‰æ›\n",
        "for anno_list in anno_lists:\n",
        "    # ã‚¹ãƒšãƒ¼ã‚¹ã§åŒºåˆ‡ã‚‹\n",
        "    anno_list = anno_list.split()\n",
        "\n",
        "    # 0ç•ªç›®ã®è¦ç´ ã‹ã‚‰ã‚¯ãƒ©ã‚¹ãƒ©ãƒ™ãƒ«ã‚’å–ã‚Šå‡ºã—\n",
        "    class_labels.append(anno_list[0])\n",
        "\n",
        "    # BBoxã®å€¤ã‚’floatã«å¤‰æ›\n",
        "    anno_list = [float(i) for i in anno_list[1:]]\n",
        "\n",
        "    # BBoxã®é…åˆ—ã«è¿½åŠ \n",
        "    bboxes.append(anno_list)\n",
        "\n",
        "\n",
        "# å¤‰æ›ã‚’å®Ÿè¡Œã—ã€å¤‰æ›å¾Œã®image, bboxes, class_labelsã‚’å–å¾—\n",
        "transformed = transform(image=image, bboxes=bboxes, class_labels=class_labels)\n",
        "transformed_image = transformed['image']\n",
        "transformed_bboxes = transformed['bboxes']\n",
        "transformed_class_labels = transformed['class_labels']\n",
        "\n",
        "\n",
        "\n",
        "# é–¢æ•°ï¼šYOLOå½¢å¼ã®ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã‚’matplotlibã®rectangleã«å¤‰æ›\n",
        "def yolo_to_rect(bbox, img_shape):\n",
        "    cx, cy, w, h = bbox\n",
        "    img_h, img_w = img_shape[:2]\n",
        "    tlx = int((cx - w/2) * img_w)\n",
        "    tly = int((cy - h/2) * img_h)\n",
        "    rect_w = int(w * img_w)\n",
        "    rect_h = int(h * img_h)\n",
        "    return tlx, tly, rect_w, rect_h\n",
        "\n",
        "# å…ƒã®ç”»åƒã¨ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã‚’è¡¨ç¤º\n",
        "plt.figure(figsize=(20,10))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(image)\n",
        "plt.axis('off')\n",
        "for bbox in bboxes:\n",
        "    tlx, tly, rect_w, rect_h = yolo_to_rect(bbox, image.shape)\n",
        "    rect = plt.Rectangle((tlx, tly), rect_w, rect_h, linewidth=2, edgecolor='r', facecolor='none')\n",
        "    plt.gca().add_patch(rect)\n",
        "plt.title('Before Augmentation')\n",
        "\n",
        "# å¤‰æ›å¾Œã®ç”»åƒã¨ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã‚’è¡¨ç¤º\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(transformed_image)\n",
        "plt.axis('off')\n",
        "for bbox in transformed_bboxes:\n",
        "    tlx, tly, rect_w, rect_h = yolo_to_rect(bbox, transformed_image.shape)\n",
        "    rect = plt.Rectangle((tlx, tly), rect_w, rect_h, linewidth=2, edgecolor='r', facecolor='none')\n",
        "    plt.gca().add_patch(rect)\n",
        "plt.title('After Augmentation')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# # To save the transformed annotations:\n",
        "# with open('result.txt', 'w') as f:\n",
        "#     for i, transformed_bbox in enumerate(transformed_bboxes):\n",
        "#         f.write(\"{} {} {} {} {}\\n\".format(\n",
        "#             transformed_class_labels[i],\n",
        "#             transformed_bbox[0], transformed_bbox[1],\n",
        "#             transformed_bbox[2], transformed_bbox[3]\n",
        "#         ))\n",
        "\n"
      ],
      "metadata": {
        "id": "TfgxSSHW70zo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Setup YOLOv5**"
      ],
      "metadata": {
        "id": "cdEoEk_996YE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_for_YOLO_training\n",
        "!git clone https://github.com/ykitaguchi77/yolov5-iFish.git #iFish augmentationã‚’å®Ÿè£…ã—ãŸãƒãƒ¼ã‚¸ãƒ§ãƒ³\n",
        "%cd yolov5-iFish\n",
        "%pip install -qr requirements.txt\n",
        "\n",
        "import torch\n",
        "import utils\n",
        "display = utils.notebook_init()"
      ],
      "metadata": {
        "id": "ZjV_xXLpd5__",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fb11c27-ac86-4186-da29-8ca374af3832"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv5 ğŸš€ 88fa533 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla V100-SXM2-16GB, 16151MiB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete âœ… (8 CPUs, 51.0 GB RAM, 29.3/166.8 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Train YOLOv5**"
      ],
      "metadata": {
        "id": "shiv0uvTdH7-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train\n",
        "!python train.py --img 640 --batch 16 --epochs 300 --data /content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_for_YOLO_training/dataset.yaml --weights yolov5n.pt\n"
      ],
      "metadata": {
        "id": "spn1bRX60hYN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f2d4924-e03c-43e2-b0ae-a12837bcff8c"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5n.pt, cfg=, data=/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_for_YOLO_training/dataset.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=300, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "remote: Enumerating objects: 15943, done.\u001b[K\n",
            "remote: Counting objects: 100% (63/63), done.\u001b[K\n",
            "remote: Compressing objects: 100% (51/51), done.\u001b[K\n",
            "remote: Total 15943 (delta 28), reused 34 (delta 12), pack-reused 15880\u001b[K\n",
            "Receiving objects: 100% (15943/15943), 14.67 MiB | 14.27 MiB/s, done.\n",
            "Resolving deltas: 100% (10923/10923), done.\n",
            "From https://github.com/ultralytics/yolov5\n",
            " * [new branch]      add/weights_dir   -> ultralytics/add/weights_dir\n",
            " * [new branch]      benchmarks        -> ultralytics/benchmarks\n",
            " * [new branch]      exp/scaleFill     -> ultralytics/exp/scaleFill\n",
            " * [new branch]      exp12             -> ultralytics/exp12\n",
            " * [new branch]      exp13             -> ultralytics/exp13\n",
            " * [new branch]      exp13-nosoft      -> ultralytics/exp13-nosoft\n",
            " * [new branch]      exp13-soft        -> ultralytics/exp13-soft\n",
            " * [new branch]      fix/rgb_albumentations -> ultralytics/fix/rgb_albumentations\n",
            " * [new branch]      ghost             -> ultralytics/ghost\n",
            " * [new branch]      master            -> ultralytics/master\n",
            " * [new branch]      study_activations -> ultralytics/study_activations\n",
            " * [new branch]      ultralytics/HUB   -> ultralytics/ultralytics/HUB\n",
            " * [new branch]      update/cls-album  -> ultralytics/update/cls-album\n",
            " * [new branch]      update/textlogger -> ultralytics/update/textlogger\n",
            " * [new branch]      update/threaded   -> ultralytics/update/threaded\n",
            " * [new tag]         v1.0              -> v1.0\n",
            " * [new tag]         v2.0              -> v2.0\n",
            " * [new tag]         v3.0              -> v3.0\n",
            " * [new tag]         v3.1              -> v3.1\n",
            " * [new tag]         v4.0              -> v4.0\n",
            " * [new tag]         v5.0              -> v5.0\n",
            " * [new tag]         v6.0              -> v6.0\n",
            " * [new tag]         v6.1              -> v6.1\n",
            " * [new tag]         v6.2              -> v6.2\n",
            " * [new tag]         v7.0              -> v7.0\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mâš ï¸ YOLOv5 is out of date by 2699 commits. Use 'git pull ultralytics master' or 'git clone https://github.com/ultralytics/yolov5' to update.\n",
            "YOLOv5 ğŸš€ 88fa533 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla V100-SXM2-16GB, 16151MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 ğŸš€ runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5n.pt to yolov5n.pt...\n",
            "100% 3.87M/3.87M [00:00<00:00, 17.8MB/s]\n",
            "\n",
            "Overriding model.yaml nc=80 with nc=2\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      1760  models.common.Conv                      [3, 16, 6, 2, 2]              \n",
            "  1                -1  1      4672  models.common.Conv                      [16, 32, 3, 2]                \n",
            "  2                -1  1      4800  models.common.C3                        [32, 32, 1]                   \n",
            "  3                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  4                -1  2     29184  models.common.C3                        [64, 64, 2]                   \n",
            "  5                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  6                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
            "  7                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  8                -1  1    296448  models.common.C3                        [256, 256, 1]                 \n",
            "  9                -1  1    164608  models.common.SPPF                      [256, 256, 5]                 \n",
            " 10                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 14                -1  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     22912  models.common.C3                        [128, 64, 1, False]           \n",
            " 18                -1  1     36992  models.common.Conv                      [64, 64, 3, 2]                \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1     74496  models.common.C3                        [128, 128, 1, False]          \n",
            " 21                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 24      [17, 20, 23]  1      9471  models.yolo.Detect                      [2, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [64, 128, 256]]\n",
            "Model summary: 214 layers, 1766623 parameters, 1766623 gradients, 4.2 GFLOPs\n",
            "\n",
            "Transferred 343/349 items from yolov5n.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mClass utils.augmentations.FishEyeEffect is not serializable because the `get_transform_init_args_names` method is not implemented\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_for_YOLO_training/train/labels.cache... 3498 images, 0 backgrounds, 0 corrupt: 100% 3498/3498 [00:00<?, ?it/s]\n",
            "Transformed corners: [(-1.0, -0.5883068591356277), (-0.5097596049308777, -0.5883068591356277), (-1.0, -0.23480252921581268), (-0.5097596049308777, -0.23480252921581268)]\n",
            "Distorted corners: [(-0.6878244730435252, -0.4046518553728546), (-0.4381239607009473, -0.5056331037979873), (-0.7553040298764334, -0.1773472965418823), (-0.4725223129330012, -0.21765050253956256)]\n",
            "0.1223479850617833 0.24718344810100634 0.28093801964952636 0.41132635172905885\n",
            "Transformed corners: [(-0.508134663105011, -0.6369931250810623), (0.772454559803009, -0.6369931250810623), (-0.508134663105011, -0.2665011137723923), (0.772454559803009, -0.2665011137723923)]\n",
            "Distorted corners: [(-0.42989240576790794, -0.5389093224331448), (0.5928762076153883, -0.4889065168719375), (-0.4693384072176955, -0.24615366228976904), (0.6528411064862757, -0.22523380797876633)]\n",
            "0.26533079639115226 0.2305453387834276 0.8264205532431379 0.3873830960106168\n",
            "Transformed corners: [(-1.0, 0.1608770787715912), (-0.5138378143310547, 0.1608770787715912), (-1.0, 0.5638109743595123), (-0.5138378143310547, 0.5638109743595123)]\n",
            "Distorted corners: [(-0.7620875884140415, 0.1226024249921377), (-0.47929081863667305, 0.1500607869521922), (-0.6943694776780396, 0.39149313177516115), (-0.44449469262545743, 0.4877239057873771)]\n",
            "0.11895620579297927 0.5613012124960689 0.2777526536872713 0.7438619528936885\n",
            "Transformed corners: [(-0.5081346035003662, 0.17423102259635925), (0.7610363960266113, 0.17423102259635925), (-0.5081346035003662, 0.5237572491168976), (0.7610363960266113, 0.5237572491168976)]\n",
            "Distorted corners: [(-0.4741305530494944, 0.16257159133216015), (0.6534586430091257, 0.1496022636898014), (-0.4453812981546174, 0.4590745875652751), (0.6104007028827713, 0.42008738960458586)]\n",
            "0.2629347234752528 0.5748011318449007 0.8267293215045628 0.7295372937826375\n",
            "Transformed corners: [(-1.0, 0.1264786273241043), (-0.896806612610817, 0.1264786273241043), (-1.0, 0.48344044387340546), (-0.896806612610817, 0.48344044387340546)]\n",
            "Distorted corners: [(-0.8679776593254682, 0.10978062289947427), (-0.8012182888341126, 0.1129975938331791), (-0.8396866106438299, 0.4059384677642085), (-0.7758466892987249, 0.4182347259464929)]\n",
            "0.06601117033726589 0.5548903114497371 0.11207665535063754 0.7091173629732465\n",
            "Transformed corners: [(-0.75341796875, 0.12606534361839294), (0.71352219581604, 0.12606534361839294), (-0.75341796875, 0.533529669046402), (0.71352219581604, 0.533529669046402)]\n",
            "Distorted corners: [(-0.6962891748231124, 0.11650629228750119), (0.664844820788275, 0.11746500848474184), (-0.6699769241603841, 0.47444125497705836), (0.6399258838257275, 0.47849870265253985)]\n",
            "0.15185541258844382 0.5582531461437505 0.8324224103941376 0.7392493513262699\n",
            "Transformed corners: [(-1.0, -0.619087427854538), (-0.13895416259765625, -0.619087427854538), (-1.0, -0.13674500584602356), (-0.13895416259765625, -0.13674500584602356)]\n",
            "Distorted corners: [(-0.678621877033529, -0.420126272338506), (-0.1259575356865488, -0.5611830932540696), (-0.7633232740063931, -0.10438064556641007), (-0.13772714737376476, -0.13553749827066552)]\n",
            "0.11833836299680345 0.21940845337296522 0.4370212321567256 0.447809677216795\n",
            "Transformed corners: [(-0.05527496337890625, -0.5374280959367752), (0.9999969005584717, -0.5374280959367752), (-0.05527496337890625, -0.04587368667125702), (0.9999969005584717, -0.04587368667125702)]\n",
            "Distorted corners: [(-0.05152653895950559, -0.5009828687428269), (0.7005626743782066, -0.3765032311252048), (-0.055208701475032686, -0.04581869472498109), (0.7671778447517947, -0.03519338515111355)]\n",
            "0.4723956492624837 0.24950856562858653 0.8835889223758974 0.4824033074244432\n",
            "Transformed corners: [(-1.0, 0.7893490046262741), (-0.14927178621292114, 0.7893490046262741), (-1.0, 0.9999969750642776), (-0.14927178621292114, 0.9999969750642776)]\n",
            "Distorted corners: [(-0.6229079859443094, 0.4916917986788978), (-0.12689048822544455, 0.6709967309859026), (-0.5353368082605781, 0.5353351889011433), (-0.11381858211182488, 0.7624899567797746)]\n",
            "0.1885460070278453 0.7458458993394489 0.44309070894408753 0.8812449783898872\n",
            "Transformed corners: [(-0.12170988321304321, 0.6682827025651932), (0.9999969601631165, 0.6682827025651932), (-0.12170988321304321, 0.9999969452619553), (0.9999969601631165, 0.9999969452619553)]\n",
            "Distorted corners: [(-0.10866238620103676, 0.5966417122469926), (0.6639070797316319, 0.44367896620690606), (-0.09301404144468771, 0.7642251792185489), (0.535336607270144, 0.5353365992929826)]\n",
            "0.44566880689948163 0.721839483103453 0.831953539865816 0.8821125896092745\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_for_YOLO_training/valid/labels.cache... 795 images, 0 backgrounds, 0 corrupt: 100% 795/795 [00:00<?, ?it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m1.64 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset âœ…\n",
            "Plotting labels to runs/train/exp/labels.jpg... \n",
            "Transformed corners: [(-1.0, -0.3846864402294159), (-0.5404531061649323, -0.3846864402294159), (-1.0, 0.38646242022514343), (-0.5404531061649323, 0.38646242022514343)]\n",
            "Distorted corners: [(-0.8024067897834802, -0.30867501157772026), (-0.49951579941956165, -0.3555478773738804), (-0.802171061006798, 0.31000896967125835), (-0.4993883990699912, 0.35709823319629797)]\n",
            "0.09879660510825988 0.3222260613130598 0.2503058004650044 0.678549116598149\n",
            "Transformed corners: [(-0.425065279006958, -0.42327234148979187), (0.9999969005584717, -0.42327234148979187), (-0.425065279006958, 0.4529995620250702), (0.9999969005584717, 0.4529995620250702)]\n",
            "Distorted corners: [(-0.39873828098559005, -0.3970563914998631), (0.7970393431463908, -0.3373657546784888), (-0.3968324467023937, 0.42291133487423405), (0.7925557297573441, 0.3590285112484144)]\n",
            "0.300630859507205 0.3014718042500685 0.8985196715731953 0.7114556674371171\n",
            "Transformed corners: [(-1.0, -0.7734581828117371), (-0.4923087954521179, -0.7734581828117371), (-1.0, -0.18081873655319214), (-0.4923087954521179, -0.18081873655319214)]\n",
            "Distorted corners: [(-0.553625030934596, -0.4282058103857644), (-0.37672729508864977, -0.591870004693402), (-0.7115764292376635, -0.12866635089578624), (-0.45448815772721063, -0.16692769907381227)]\n",
            "0.14421178538116824 0.204064997653299 0.3116363524556751 0.43566682455210687\n",
            "Transformed corners: [(-0.4915592670440674, -0.8035670816898346), (0.9999969005584717, -0.8035670816898346), (-0.4915592670440674, -0.30200764536857605), (0.9999969005584717, -0.30200764536857605)]\n",
            "Distorted corners: [(-0.3697361746092116, -0.6044191183954469), (0.5403636064970986, -0.43421975216299996), (-0.44586425801538127, -0.27393322381441554), (0.6952337362159668, -0.20996655443444023)]\n",
            "0.27706787099230934 0.19779044080227653 0.8476168681079834 0.3950167227827799\n",
            "Transformed corners: [(-1.0, 0.5504436790943146), (-0.4986632466316223, 0.5504436790943146), (-1.0, 0.9999968707561493), (-0.4986632466316223, 0.9999968707561493)]\n",
            "Distorted corners: [(-0.6360858038900759, 0.35012941011291804), (-0.4218330290449498, 0.46563552866475993), (-0.44141774255950217, 0.4414163612557457), (-0.32475922156636217, 0.6512575520839896)]\n",
            "0.18195709805496207 0.675064705056459 0.3376203892168189 0.8256287760419948\n",
            "Transformed corners: [(-0.144902765750885, 0.6577365398406982), (0.9999969601631165, 0.6577365398406982), (-0.144902765750885, 0.9999969005584717), (0.9999969601631165, 0.9999969005584717)]\n",
            "Distorted corners: [(-0.12654491709499927, 0.5744073653334286), (0.5998813040509843, 0.39456505265502023), (-0.10358308816010145, 0.7148432714421377), (0.44141808207108874, 0.4414180557604408)]\n",
            "0.43672754145250037 0.6972825263275101 0.7999406520254921 0.8574216357210689\n",
            "Transformed corners: [(-1.0, -0.9812595248222351), (0.8567768335342407, -0.9812595248222351), (-1.0, -0.1743142008781433), (0.8567768335342407, -0.1743142008781433)]\n",
            "Distorted corners: [(-0.43263546190532554, -0.4245276677704679), (0.43653045832326676, -0.49995477624874696), (-0.7021687204867896, -0.1223979793932831), (0.6674603101428592, -0.13579710144646484)]\n",
            "0.1489156397566052 0.2500226118756265 0.8337301550714296 0.43880101030335844\n",
            "Transformed corners: [(-1.0, 0.6280399858951569), (0.8567768335342407, 0.6280399858951569), (-1.0, 0.9999969899654388), (0.8567768335342407, 0.9999969899654388)]\n",
            "Distorted corners: [(-0.5969409963293872, 0.37490281491494926), (0.5773036338392654, 0.4231787693862116), (-0.42190490803003766, 0.42190363808168296), (0.4273367683519292, 0.49877105137251465)]\n",
            "0.20152950183530638 0.6874514074574747 0.7886518169196327 0.7493855256862574\n",
            "Transformed corners: [(-1.0, -0.5497641861438751), (0.890001654624939, -0.5497641861438751), (-1.0, 0.047090083360672), (0.890001654624939, 0.047090083360672)]\n",
            "Distorted corners: [(-0.6990615023883779, -0.3843189779250612), (0.6649247075447375, -0.41073158548714855), (-0.7683947133029071, 0.036183771103333554), (0.7266313799791283, 0.03844614454128957)]\n",
            "0.11580264334854645 0.29463420725642575 0.8633156899895642 0.5192230722706448\n",
            "Transformed corners: [(-0.8240085244178772, -0.35514217615127563), (0.9999969601631165, -0.35514217615127563), (-0.8240085244178772, 0.3679106831550598), (0.9999969601631165, 0.3679106831550598)]\n",
            "Distorted corners: [(-0.7605109847971625, -0.3277751602371097), (0.8922140176521602, -0.3168637910358999), (-0.7597828553422005, 0.33923463298626333), (0.8913303772285596, 0.3279309648596588)]\n",
            "0.11974450760141875 0.33611241988144513 0.9461070088260801 0.6696173164931316\n",
            "Transformed corners: [(-1.0, -0.7823831737041473), (-0.4607774019241333, -0.7823831737041473), (-1.0, -0.14035561680793762), (-0.4607774019241333, -0.14035561680793762)]\n",
            "Distorted corners: [(-0.5948358377681102, -0.46538955058597936), (-0.36530396380945085, -0.6202727681055009), (-0.743725718188226, -0.10438608191223485), (-0.4339090560822267, -0.1321713542171461)]\n",
            "0.12813714090588701 0.18986361594724954 0.3173480180952746 0.44780695904388257\n",
            "Transformed corners: [(-0.17597752809524536, -0.7411027550697327), (0.9999969601631165, -0.7411027550697327), (-0.17597752809524536, -0.13005036115646362), (0.9999969601631165, -0.13005036115646362)]\n",
            "Distorted corners: [(-0.15031681580604173, -0.6330365446824169), (0.6106412655079853, -0.45254929990328946), (-0.17385987482294948, -0.12848537967361662), (0.7444253213739496, -0.09681307619465845)]\n",
            "0.41307006258852524 0.18348172765879156 0.8722126606869748 0.4515934619026708\n",
            "Transformed corners: [(-1.0, -0.5625253617763519), (0.6028053760528564, -0.5625253617763519), (-1.0, -0.05022206902503967), (0.6028053760528564, -0.05022206902503967)]\n",
            "Distorted corners: [(-0.8614301414925091, -0.4845763019881277), (0.5596700069956578, -0.5222723380837937), (-0.8944730350288526, -0.044922286506255765), (0.5795884408597078, -0.04828777552312183)]\n",
            "0.05276348248557372 0.23886383095810315 0.7897942204298539 0.47753885674687213\n",
            "Transformed corners: [(-0.9370567798614502, 0.7266371995210648), (0.5950222015380859, 0.7266371995210648), (-0.9370567798614502, 0.9999970644712448), (0.5950222015380859, 0.9999970644712448)]\n",
            "Distorted corners: [(-0.7983670043480158, 0.6190907282216546), (0.5397766521860063, 0.6591716979592236), (-0.7518115640517433, 0.8023092871687438), (0.5102143874716325, 0.8574686598311226)]\n",
            "0.10081649782599211 0.8095453641108272 0.7698883260930032 0.9287343299155613\n",
            "Transformed corners: [(-0.9358909726142883, -0.6925350725650787), (0.9999969601631165, -0.6925350725650787), (-0.9358909726142883, 0.02868834137916565), (0.9999969601631165, 0.02868834137916565)]\n",
            "Distorted corners: [(-0.8430183571956145, -0.6238117433095167), (0.891677477954903, -0.6175198040596218), (-0.8758223597643527, 0.02684702767699566), (0.9267284655269789, 0.026586383403097182)]\n",
            "0.06208882011782363 0.18809412834524164 0.9633642327634895 0.5134235138384978\n",
            "Transformed corners: [(-0.9237259030342102, 0.632193848490715), (0.9999969601631165, 0.632193848490715), (-0.9237259030342102, 0.9999968558549881), (0.9999969601631165, 0.9999968558549881)]\n",
            "Distorted corners: [(-0.8389959717981087, 0.5742050650923557), (0.8975294703652739, 0.567414334851079), (-0.798399037486729, 0.8643218995828128), (0.8535804907275146, 0.8535804016918606)]\n",
            "0.08050201410094565 0.7837071674255395 0.9487647351826369 0.9321609497914064\n",
            "Transformed corners: [(-0.7781641483306885, -0.6355747580528259), (0.9999969005584717, -0.6355747580528259), (-0.7781641483306885, 0.025361716747283936), (0.9999969005584717, 0.025361716747283936)]\n",
            "Distorted corners: [(-0.5426772724015766, -0.4432380711027384), (0.5791332195792792, -0.3680835967680402), (-0.6367586923349442, 0.020753068136090704), (0.7000346110598938, 0.017754134546898018)]\n",
            "0.1816206538325279 0.2783809644486308 0.8500173055299469 0.5103765340680454\n",
            "Transformed corners: [(-0.640015184879303, 0.8667518645524979), (0.9999969601631165, 0.8667518645524979), (-0.640015184879303, 0.9999969452619553), (0.9999969601631165, 0.9999969452619553)]\n",
            "Distorted corners: [(-0.41729048305209887, 0.5651230045637555), (0.47502157362522535, 0.41172708622550835), (-0.36956846661219117, 0.5774352646758386), (0.40045791873044095, 0.4004579127631348)]\n",
            "0.29135475847395054 0.7002289563815673 0.7375107868126127 0.7887176323379192\n",
            "Transformed corners: [(-1.0, -0.9741959571838379), (0.44532036781311035, -0.9741959571838379), (-1.0, -0.3058931827545166), (0.44532036781311035, -0.3058931827545166)]\n",
            "Distorted corners: [(-0.48244724493895663, -0.46999815557401237), (0.3096436889360047, -0.677385657005345), (-0.7096132767602417, -0.21706586375305198), (0.41080534978130406, -0.2821846136395965)]\n",
            "0.14519336161987917 0.16130717149732748 0.705402674890652 0.391467068123474\n",
            "Transformed corners: [(0.6084694117307663, -0.6872976124286652), (0.9999969750642776, -0.6872976124286652), (0.6084694117307663, -0.1838831603527069), (0.9999969750642776, -0.1838831603527069)]\n",
            "Distorted corners: [(0.4723259348446102, -0.533516526958102), (0.6090245406854368, -0.41858237890835587), (0.5431861760531295, -0.16415416911170405), (0.725480726476742, -0.13340409229832534)]\n",
            "0.7361629674223051 0.23324173652094898 0.862740363238371 0.43329795385083736\n",
            "Transformed corners: [(-1.0, 0.6641280651092529), (0.4473222494125366, 0.6641280651092529), (-1.0, 0.9999969005584717), (0.4473222494125366, 0.9999969005584717)]\n",
            "Distorted corners: [(-0.6173393433260902, 0.40999238359897305), (0.37116363085089127, 0.5510572843618966), (-0.4689216905052832, 0.46892023710992214), (0.30477311253855904, 0.6813257518765751)]\n",
            "0.1913303283369549 0.7049961917994865 0.6855818154254456 0.8406628759382875\n",
            "Transformed corners: [(0.5276221036911011, 0.6090114116668701), (0.9999970197677612, 0.6090114116668701), (0.5276221036911011, 0.9999969005584717), (0.9999970197677612, 0.9999969005584717)]\n",
            "Distorted corners: [(0.4366548862871608, 0.5040118805649378), (0.6359722862371491, 0.3873155341125343), (0.34851513460351813, 0.6605372518761571), (0.46892187574427324, 0.46892181984426295)]\n",
            "0.674257567301759 0.6936577670562671 0.8179861431185745 0.8302686259380785\n",
            "Transformed corners: [(-1.0, -1.0), (0.26671433448791504, -1.0), (-1.0, -0.7570872008800507), (0.26671433448791504, -0.7570872008800507)]\n",
            "Distorted corners: [(-0.7689823888133305, -0.7689823888133305), (0.23371491623958973, -0.8762742980736923), (-0.8182837382730571, -0.6195121449348128), (0.24686429285009684, -0.7007414761938165)]\n",
            "0.09085813086347144 0.06186285096315386 0.6234321464250484 0.19024392753259362\n",
            "Transformed corners: [(0.38094645738601685, -1.0), (0.9999968409538269, -1.0), (0.38094645738601685, -0.714559018611908), (0.9999968409538269, -0.714559018611908)]\n",
            "Distorted corners: [(0.3305581106362778, -0.867728533045052), (0.7689806893543002, -0.7689831186074783), (0.35209325548200443, -0.6604377235149158), (0.8255111450067281, -0.589878297081977)]\n",
            "0.6652790553181389 0.06613573347747398 0.912755572503364 0.20506085145901148\n",
            "Transformed corners: [(-1.0, -0.2807857394218445), (0.30832552909851074, -0.2807857394218445), (-1.0, 0.10293823480606079), (0.30832552909851074, 0.10293823480606079)]\n",
            "Distorted corners: [(-0.8753844072341878, -0.24579545806360445), (0.3021320125126223, -0.27514543081919707), (-0.883267230738765, 0.09092196959428607), (0.3045624882404613, 0.10168189776331486)]\n",
            "0.058366384630617496 0.36242728459040147 0.6522812441202306 0.5508409488816575\n",
            "Transformed corners: [(0.32813864946365356, -0.21447715163230896), (0.999997079372406, -0.21447715163230896), (0.32813864946365356, 0.1994546353816986), (0.999997079372406, 0.1994546353816986)]\n",
            "Distorted corners: [(0.32231390478400546, -0.21066999679115164), (0.879175844498014, -0.18856368163615564), (0.3225495962948239, 0.19605740508365252), (0.8798941104591758, 0.17549947154473827)]\n",
            "0.6611569523920027 0.3946650016044242 0.9399470552295879 0.5980287025418263\n",
            "Transformed corners: [(-0.7103551626205444, -0.28416135907173157), (0.6470714807510376, -0.28416135907173157), (-0.7103551626205444, 0.08799651265144348), (0.6470714807510376, 0.08799651265144348)]\n",
            "Distorted corners: [(-0.655661722158449, -0.26228249735320286), (0.6045619747448738, -0.26549331487643024), (-0.6624830108242779, 0.08206626447016538), (0.6107755726602393, 0.08306056132223257)]\n",
            "0.16875849458786107 0.3672533425617849 0.8053877863301196 0.5415302806611163\n",
            "Transformed corners: [(0.6577485054731369, -0.2817326486110687), (0.9999968558549881, -0.2817326486110687), (0.6577485054731369, 0.10098215937614441), (0.9999968558549881, 0.10098215937614441)]\n",
            "Distorted corners: [(0.6134511561550651, -0.2627588167498274), (0.8580223830232052, -0.24173367858244824), (0.619436059115218, 0.09510016415758842), (0.8671214293805135, 0.08756406969430611)]\n",
            "0.8067255780775325 0.3686205916250863 0.9335607146902567 0.5475500820787942\n",
            "Transformed corners: [(-0.6323100328445435, 0.6646092683076859), (0.5558902025222778, 0.6646092683076859), (-0.6323100328445435, 0.9899539202451706), (0.5558902025222778, 0.9899539202451706)]\n",
            "Distorted corners: [(-0.5623197477834999, 0.5910437866185748), (0.5009981901838455, 0.5989816677659765), (-0.5175484587994442, 0.8102815060524582), (0.4616378770340319, 0.822105199965605)]\n",
            "0.21884012610825004 0.7955218933092874 0.7504990950919228 0.9110525999828025\n",
            "Transformed corners: [(0.6814467906951904, 0.6452861577272415), (0.9999969005584717, 0.6452861577272415), (0.6814467906951904, 0.9687377661466599), (0.9999969005584717, 0.9687377661466599)]\n",
            "Distorted corners: [(0.6025000911824896, 0.5705287253210706), (0.8136923786203214, 0.5250660559833861), (0.5557057078066686, 0.7899855327903008), (0.7450234245973258, 0.7217345650454313)]\n",
            "0.7778528539033343 0.7625330279916931 0.9068461893101607 0.8949927663951505\n",
            "Transformed corners: [(-0.6858320236206055, -0.208082914352417), (0.36434102058410645, -0.208082914352417), (-0.6858320236206055, 0.07922053337097168), (0.36434102058410645, 0.07922053337097168)]\n",
            "Distorted corners: [(-0.5854614874928613, -0.17763027733159287), (0.3460669275120736, -0.19764619070960632), (-0.5926957464343647, 0.06846235162855388), (0.3499100511854224, 0.07608273381441581)]\n",
            "0.20365212678281763 0.40117690464519684 0.6749550255927113 0.5380413669072079\n",
            "Transformed corners: [(0.43924030661582947, -0.29818466305732727), (0.9999968111515045, -0.29818466305732727), (0.43924030661582947, 0.11310377717018127), (0.9999968111515045, 0.11310377717018127)]\n",
            "Distorted corners: [(0.4039688351151109, -0.2742401122349987), (0.6897559545137871, -0.20567530275585852), (0.41349503214264555, 0.10647440426577941), (0.711443778938032, 0.08046723523994091)]\n",
            "0.7019844175575555 0.36287994388250067 0.855721889469016 0.5532372021328897\n",
            "Transformed corners: [(-0.7183532118797302, 0.5807254761457443), (0.3934401869773865, 0.5807254761457443), (-0.7183532118797302, 0.8554045706987381), (0.3934401869773865, 0.8554045706987381)]\n",
            "Distorted corners: [(-0.5437164967780989, 0.43954703098428094), (0.33828504468234805, 0.49931539824484744), (-0.4629805924085268, 0.5513105646938616), (0.29406619971075904, 0.6393489522590359)]\n",
            "0.22814175161095057 0.7197735154921405 0.669142522341174 0.8196744761295179\n",
            "Transformed corners: [(0.4415495991706848, 0.5175408124923706), (0.999997079372406, 0.5175408124923706), (0.4415495991706848, 0.8895286321640015), (0.999997079372406, 0.8895286321640015)]\n",
            "Distorted corners: [(0.3833264366852185, 0.44929737421227955), (0.6387757471106124, 0.33059348470050115), (0.3174798833229885, 0.6395826128758814), (0.48965011961000654, 0.43555907324147697)]\n",
            "0.6587399416614943 0.6652967423502506 0.8193878735553062 0.8197913064379407\n",
            "Image sizes 640 train, 640 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/exp\u001b[0m\n",
            "Starting training for 300 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "  0% 0/219 [00:00<?, ?it/s]Transformed corners: [(-1.0, -1.0), (0.37523388862609863, -1.0), (-1.0, -0.3312392830848694), (0.37523388862609863, -0.3312392830848694)]\n",
            "Distorted corners: [(-0.9882978049562814, -0.9882978049562814), (0.37272922688108456, -0.993325065190181), (-0.9935069232020793, -0.32908852098131114), (0.3746838645767685, -0.3307537470570691)]\n",
            "0.0032465383989603303 0.0033374674049094777 0.6873419322883842 0.33545573950934443\n",
            "Transformed corners: [(0.4184165596961975, -1.0), (0.999997079372406, -1.0), (0.4184165596961975, -0.2691771984100342), (0.999997079372406, -0.2691771984100342)]\n",
            "Distorted corners: [(0.41553975199186965, -0.9931245366903818), (0.9882949526840452, -0.9882978391339853), (0.41781056069961864, -0.2687873450250323), (0.9937220851025403, -0.26748810809922896)]\n",
            "0.7077698759959348 0.0034377316548090953 0.9968610425512702 0.3662559459503855\n",
            "Transformed corners: [(-1.0, -0.9651074409484863), (0.9999969005584717, -0.9651074409484863), (-1.0, 0.06489849090576172), (0.9999969005584717, 0.06489849090576172)]\n",
            "Distorted corners: [(-0.7711793971515233, -0.744270974497103), (0.7711777413165624, -0.7442716832650247), (-0.8810290456151588, 0.057177455504567314), (0.8810270493076355, 0.05717750316554947)]\n",
            "0.05948547719242059 0.12786415836748766 0.9405135246538178 0.5285887515827747\n",
            "Transformed corners: [(-1.0, 0.03527209162712097), (0.235396146774292, 0.03527209162712097), (-1.0, 0.623039036989212), (0.235396146774292, 0.623039036989212)]\n",
            "Distorted corners: [(-0.9055009547561936, 0.031938912644605987), (0.23413742828882278, 0.03508348346865867), (-0.8689815409827215, 0.5414094224552763), (0.22554089900409144, 0.5969544805333099)]\n",
            "0.047249522621903184 0.515969456322303 0.6170687141444113 0.7984772402666549\n",
            "Transformed corners: [(0.30552443861961365, -0.0908539891242981), (0.9999970495700836, -0.0908539891242981), (0.30552443861961365, 0.5617960095405579), (0.9999970495700836, 0.5617960095405579)]\n",
            "Distorted corners: [(0.3025947226204472, -0.08998277768626008), (0.9048371959907024, -0.08220831131366074), (0.2937317138145856, 0.5401116370333781), (0.87582811672942, 0.4920381927462139)]\n",
            "0.6468658569072928 0.45500861115686997 0.9524185979953512 0.770055818516689\n",
            "Transformed corners: [(-1.0, -0.8575639128684998), (0.9021050930023193, -0.8575639128684998), (-1.0, 0.02197808027267456), (0.9021050930023193, 0.02197808027267456)]\n",
            "Distorted corners: [(-0.866275703588272, -0.7428867819920713), (0.7944154259654579, -0.7551913922431236), (-0.9229067264005414, 0.020283718117022398), (0.8455025600663367, 0.02059906687151584)]\n",
            "0.038546636799729306 0.1224043038784382 0.9227512800331683 0.510299533435758\n",
            "Transformed corners: [(-1.0, -0.3061855435371399), (0.5307857990264893, -0.3061855435371399), (-1.0, 0.4661152958869934), (0.5307857990264893, 0.4661152958869934)]\n",
            "Distorted corners: [(-0.9522151686337971, -0.2915545189724485), (0.5220785311630873, -0.3011627272742162), (-0.9468189700048045, 0.4413268043552078), (0.5192143055620918, 0.45595366362421536)]\n",
            "0.023892415683101464 0.3494186363628919 0.7610392655815437 0.7279768318121077\n",
            "Transformed corners: [(0.6176324188709259, -0.12584245204925537), (0.9999968707561493, -0.12584245204925537), (0.6176324188709259, 0.5370384454727173), (0.9999968707561493, 0.5370384454727173)]\n",
            "Distorted corners: [(0.6069116112630302, -0.12365809016003941), (0.9556164047027672, -0.12025748790129431), (0.599556544528241, 0.5213212661910638), (0.9437079564182078, 0.5068090398241405)]\n",
            "0.7997782722641205 0.4381709549199803 0.9778082023513837 0.7606606330955319\n",
            "Transformed corners: [(-1.0, 0.3183472752571106), (-0.23889201879501343, 0.3183472752571106), (-1.0, 0.9999968409538269), (-0.23889201879501343, 0.9999968409538269)]\n",
            "Distorted corners: [(-0.9539960388440867, 0.30370203957209163), (-0.23731125091520008, 0.31624074549571096), (-0.9164588456064123, 0.9164559504706034), (-0.22834391504275353, 0.9558427060291097)]\n",
            "0.02300198057795666 0.6518510197860459 0.38582804247862323 0.9779213530145549\n",
            "Transformed corners: [(-0.09073781967163086, 0.198271244764328), (0.9999969005584717, 0.198271244764328), (-0.09073781967163086, 0.9999969303607941), (0.9999969005584717, 0.9999969303607941)]\n",
            "Distorted corners: [(-0.09055761602976964, 0.197877481716988), (0.9565845162232431, 0.18966379060569394), (-0.08691645395488745, 0.9578826939777909), (0.9164562565572063, 0.9164562838698157)]\n",
            "0.4547211919851152 0.594831895302847 0.9782922581116216 0.9789413469888955\n",
            "Transformed corners: [(-1.0, -0.3019818067550659), (0.12914586067199707, -0.3019818067550659), (-1.0, 0.29580605030059814), (0.12914586067199707, 0.29580605030059814)]\n",
            "Distorted corners: [(-0.9642734085530966, -0.29119302612072995), (0.1286897419692604, -0.30091526424855053), (-0.9643942809843039, 0.28527366319045216), (0.1287053521434202, 0.2947970741918477)]\n",
            "0.017802859507848046 0.34954236787572474 0.5643526760717101 0.6473985370959239\n",
            "Transformed corners: [(0.14290738105773926, -0.3172266483306885), (0.9999969005584717, -0.3172266483306885), (0.14290738105773926, 0.23022043704986572), (0.9999969005584717, 0.23022043704986572)]\n",
            "Distorted corners: [(0.14234097439386745, -0.3159693354736316), (0.9639615587756913, -0.3057952422045114), (0.14256383693260963, 0.22966699552677672), (0.9655210432917691, 0.22228336552176756)]\n",
            "0.5711704871969338 0.3420153322631842 0.9827605216458846 0.6148334977633884\n",
            "Transformed corners: [(-1.0, -0.08360688388347626), (-0.5172625184059143, -0.08360688388347626), (-1.0, 0.1157631129026413), (-0.5172625184059143, 0.1157631129026413)]\n",
            "Distorted corners: [(-0.7678808928834372, -0.0642001286476456), (-0.4845270069505763, -0.07831573285720975), (-0.7664031101068396, 0.0887212097642335), (-0.48376260530989657, 0.10826584781195918)]\n",
            "0.1160595535582814 0.46084213357139514 0.2581186973450517 0.5541329239059796\n",
            "Transformed corners: [(-0.2502918839454651, -0.1762935370206833), (0.9192963242530823, -0.1762935370206833), (-0.2502918839454651, 0.18704454600811005), (0.9192963242530823, 0.18704454600811005)]\n",
            "Distorted corners: [(-0.24488446605910816, -0.17248481254145695), (0.7336283093695284, -0.1406879654635197), (-0.24465909787866907, 0.1828351329979214), (0.7328005552425652, 0.14909920071876867)]\n",
            "0.3775577669704459 0.4137575937292715 0.8668141546847642 0.5914175664989607\n",
            "Transformed corners: [(-1.0, 0.7315143123269081), (-0.5022456645965576, 0.7315143123269081), (-1.0, 0.9488574489951134), (-0.5022456645965576, 0.9488574489951134)]\n",
            "Distorted corners: [(-0.6461443872369306, 0.4726638670935147), (-0.4110913186391059, 0.5987491868136049), (-0.5619589463453637, 0.5332189322692436), (-0.36880954592916676, 0.6967659645136015)]\n",
            "0.1769278063815347 0.7363319335467573 0.31559522703541665 0.8483829822568008\n",
            "Transformed corners: [(-0.2411346435546875, 0.6234730929136276), (0.874596357345581, 0.6234730929136276), (-0.2411346435546875, 0.9485095292329788), (0.874596357345581, 0.9485095292329788)]\n",
            "Distorted corners: [(-0.21629637831508008, 0.5592517524075092), (0.6420215289140542, 0.45767758462206426), (-0.18789593732677504, 0.7390936633217097), (0.5390130110618838, 0.58456563771251)]\n",
            "0.39185181084245996 0.7288387923110321 0.821010764457027 0.8695468316608548\n",
            "Transformed corners: [(-1.0, -0.0911012589931488), (-0.5029755234718323, -0.0911012589931488), (-1.0, 0.3849678933620453), (-0.5029755234718323, 0.3849678933620453)]\n",
            "Distorted corners: [(-0.8596208307805464, -0.0783125399408443), (-0.48467883453466615, -0.08778727785530682), (-0.840143319577991, 0.32342820386013477), (-0.4748821231416324, 0.3634657394046484)]\n",
            "0.0701895846097268 0.4561063610723466 0.26255893842918376 0.6817328697023242\n",
            "Transformed corners: [(-0.3876262307167053, -0.04195031523704529), (0.9999969601631165, -0.04195031523704529), (-0.3876262307167053, 0.438513845205307), (0.9999969601631165, 0.438513845205307)]\n",
            "Distorted corners: [(-0.379422532627358, -0.04106248130402854), (0.86052953003754, -0.03609959479274096), (-0.36914000062949914, 0.4176007407853551), (0.8340026855522561, 0.36572283629083924)]\n",
            "0.31028873368632104 0.4794687593479857 0.93026476501877 0.7088003703926775\n",
            "Transformed corners: [(-0.9616443514823914, 0.11497938632965088), (0.8122829794883728, 0.11497938632965088), (-0.9616443514823914, 0.647530198097229), (0.8122829794883728, 0.647530198097229)]\n",
            "Distorted corners: [(-0.9277403310370208, 0.11092563874728593), (0.7917344417584335, 0.11207072233222445), (-0.9130624309769494, 0.6148172095996215), (0.7793362943819648, 0.6212659846736793)]\n",
            "0.0361298344814896 0.555462819373643 0.8958672208792168 0.8106329923368396\n",
            "Transformed corners: [(0.8186454549431801, -0.07626298069953918), (0.9999969229102135, -0.07626298069953918), (0.8186454549431801, 0.5105216801166534), (0.9999969229102135, 0.5105216801166534)]\n",
            "Distorted corners: [(0.797844496979633, -0.07432521503294055), (0.9621911912169138, -0.0733797940412569), (0.7900035915084691, 0.4926601111626362), (0.9526133192619074, 0.4863312487360093)]\n",
            "0.8950017957542346 0.46283739248352973 0.9810955956084568 0.7463300555813182\n",
            "Transformed corners: [(-0.5573294162750244, -0.39483216404914856), (0.9999969005584717, -0.39483216404914856), (-0.5573294162750244, 0.30782344937324524), (0.9999969005584717, 0.30782344937324524)]\n",
            "Distorted corners: [(-0.5474338346767956, -0.38782177883914637), (0.9560039055453935, -0.377462260788132), (-0.5487306765400158, 0.3030742047645828), (0.9583307840590062, 0.2949976019174281)]\n",
            "0.22563466172999208 0.3060891105804268 0.9791653920295031 0.6515371023822913\n",
            "  0% 0/219 [00:07<?, ?it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_for_YOLO_training/yolov5-iFish/train.py\", line 647, in <module>\n",
            "    main(opt)\n",
            "  File \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_for_YOLO_training/yolov5-iFish/train.py\", line 536, in main\n",
            "    train(opt.hyp, opt, device, callbacks)\n",
            "  File \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_for_YOLO_training/yolov5-iFish/train.py\", line 291, in train\n",
            "    for i, (imgs, targets, paths, _) in pbar:  # batch -------------------------------------------------------------\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tqdm/std.py\", line 1182, in __iter__\n",
            "    for obj in iterable:\n",
            "  File \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_for_YOLO_training/yolov5-iFish/utils/dataloaders.py\", line 172, in __iter__\n",
            "    yield next(self.iterator)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 633, in __next__\n",
            "    data = self._next_data()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1328, in _next_data\n",
            "    idx, data = self._get_data()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1284, in _get_data\n",
            "    success, data = self._try_get_data()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1132, in _try_get_data\n",
            "    data = self._data_queue.get(timeout=timeout)\n",
            "  File \"/usr/lib/python3.10/queue.py\", line 180, in get\n",
            "    self.not_empty.wait(remaining)\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 324, in wait\n",
            "    gotit = waiter.acquire(True, timeout)\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# é€”ä¸­ã‹ã‚‰\n",
        "!python train.py --img 640 --batch 16 --epochs 300 --data /content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_for_YOLO_training/dataset.yaml --resume /content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_for_YOLO_training/yolov5/runs/train/exp/weights/best.pt\n"
      ],
      "metadata": {
        "id": "5126RlFFfXWQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48d5e42b-65df-4597-bea2-2a3fb686ba85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING âš ï¸ 'ultralytics.yolo.v8' is deprecated since '8.0.136' and will be removed in '8.1.0'. Please use 'ultralytics.models.yolo' instead.\n",
            "WARNING âš ï¸ 'ultralytics.yolo.utils' is deprecated since '8.0.136' and will be removed in '8.1.0'. Please use 'ultralytics.utils' instead.\n",
            "Note this warning may be related to loading older models. You can update your model to current structure with:\n",
            "    import torch\n",
            "    ckpt = torch.load(\"model.pt\")  # applies to both official and custom models\n",
            "    torch.save(ckpt, \"updated-model.pt\")\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorboard/compat/__init__.py\", line 42, in tf\n",
            "    from tensorboard.compat import notf  # noqa: F401\n",
            "ImportError: cannot import name 'notf' from 'tensorboard.compat' (/usr/local/lib/python3.10/dist-packages/tensorboard/compat/__init__.py)\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_for_YOLO_training/yolov5/train.py\", line 56, in <module>\n",
            "    from utils.loggers import Loggers\n",
            "  File \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_for_YOLO_training/yolov5/utils/loggers/__init__.py\", line 23, in <module>\n",
            "    from torch.utils.tensorboard import SummaryWriter\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/tensorboard/__init__.py\", line 12, in <module>\n",
            "    from .writer import FileWriter, SummaryWriter  # noqa: F401\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/tensorboard/writer.py\", line 16, in <module>\n",
            "    from ._embedding import (\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/tensorboard/_embedding.py\", line 9, in <module>\n",
            "    _HAS_GFILE_JOIN = hasattr(tf.io.gfile, \"join\")\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorboard/lazy.py\", line 65, in __getattr__\n",
            "    return getattr(load_once(self), attr_name)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorboard/lazy.py\", line 97, in wrapper\n",
            "    cache[arg] = f(arg)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorboard/lazy.py\", line 50, in load_once\n",
            "    module = load_fn()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorboard/compat/__init__.py\", line 45, in tf\n",
            "    import tensorflow\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/__init__.py\", line 52, in <module>\n",
            "    from ._api.v2 import compat\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/_api/v2/compat/__init__.py\", line 37, in <module>\n",
            "    from . import v1\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/_api/v2/compat/v1/__init__.py\", line 31, in <module>\n",
            "    from . import compat\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py\", line 37, in <module>\n",
            "    from . import v1\n",
            "  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\n",
            "  File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 879, in exec_module\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 1012, in get_code\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 672, in _compile_bytecode\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_t1_bMiSeo09"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# best.pyã‚’renameã—ã¦gdriveã«ç§»å‹•ã—ã¦ãŠã\n",
        "orig_pt = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_for_YOLO_training/yolov5/runs/train/exp/weights/best.pt\"\n",
        "dst_pt = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_for_YOLO_training/yolo5n_100epoch.pt\"\n",
        "shutil.copy(orig_pt, dst_pt)"
      ],
      "metadata": {
        "id": "2_mRrhFn-ONj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fCJ9m4Swo0Ov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KrBGgvJ_AvBA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jRe67Lg1AvD6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GKOIspiWAvGg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oxDheZVGAvJN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l7xRpeWqObKr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0UeNKxikObNU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Show examples**"
      ],
      "metadata": {
        "id": "MjJoQlzAOTS5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import glob\n",
        "\n",
        "val_images_dir = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_for_YOLO_training/valid/images\"\n",
        "val_labels_dir = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_for_YOLO_training/valid/labels\"\n",
        "\n",
        "for sample_num in range(21):\n",
        "    sample_image_path = glob.glob(f\"{val_images_dir}/*\")[sample_num]\n",
        "    sample_label_path = glob.glob(f\"{val_labels_dir}/*\")[sample_num]\n",
        "\n",
        "    # ç”»åƒã®èª­ã¿è¾¼ã¿\n",
        "    image = cv2.imread(sample_image_path)\n",
        "    height, width = image.shape[:2]\n",
        "    image = cv2.resize(image, (640, int(height * 640 / width)))\n",
        "\n",
        "    # ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã®æƒ…å ±\n",
        "    with open(sample_label_path, \"r\", encoding=\"utf-8\") as file:\n",
        "        content = file.read()\n",
        "    content_list = content.split()\n",
        "\n",
        "    # ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã®åº§æ¨™ã‚’è¨ˆç®—\n",
        "    x = float(content_list[1]) * image.shape[1]\n",
        "    y = float(content_list[2]) * image.shape[0]\n",
        "    box_width = float(content_list[3]) * image.shape[1]\n",
        "    box_height = float(content_list[4]) * image.shape[0]\n",
        "\n",
        "    # ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã®åº§æ¨™ã‚’è¨ˆç®—\n",
        "    left = int(x - (box_width / 2))\n",
        "    top = int(y - (box_height / 2))\n",
        "    right = int(x + (box_width / 2))\n",
        "    bottom = int(y + (box_height / 2))\n",
        "\n",
        "    # ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã‚’ç”»åƒã«é‡ã­ã‚‹\n",
        "    cv2.rectangle(image, (left, top), (right, bottom), (0, 255, 0), 2)\n",
        "\n",
        "    # ç”»åƒã®è¡¨ç¤º\n",
        "    cv2_imshow(image)\n"
      ],
      "metadata": {
        "id": "iRp4OAwxOXIa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Interference Olympia dataset**"
      ],
      "metadata": {
        "id": "uzZr3wMsrxJf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_for_YOLO_training/yolov5\n",
        "\n",
        "import torch\n",
        "import utils\n",
        "%pip install -qr requirements.txt\n",
        "display = utils.notebook_init()"
      ],
      "metadata": {
        "id": "cpKHAnmE_wFQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "effd129b-8479-432c-93d0-713b01ec8cd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv5 ğŸš€ v7.0-176-g76ea9ed Python-3.10.12 torch-2.0.1+cu118 CPU\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete âœ… (4 CPUs, 25.5 GB RAM, 23.9/225.8 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# YOLOv5\n",
        "weight = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_for_YOLO_training/yolov5/runs/train/exp/weights/best.pt\"\n",
        "\n",
        "# æ¨ªå¹…ã‚’640pxã«ãƒªã‚µã‚¤ã‚ºã—ãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ\n",
        "dataset_olympia_grav = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO/test/olympia/grav\"\n",
        "dataset_olympia_cont = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO/test/olympia/cont\"\n",
        "dataset_handai_grav = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO/test/handai/grav\"\n",
        "dataset_handai_cont = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO/test/handai/cont\""
      ],
      "metadata": {
        "id": "CrVmlh1Csdxz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from models.common import DetectMultiBackend\n",
        "#from utils.datasets import IMG_FORMATS, VID_FORMATS, LoadImages, LoadStreams\n",
        "from utils.general import (LOGGER, check_file, check_img_size, check_imshow, check_requirements, colorstr,\n",
        "                           increment_path, non_max_suppression, print_args, strip_optimizer, xyxy2xywh)\n",
        "#from utils.plots import Annotator, colors, save_one_box\n",
        "from utils.torch_utils import select_device, time_sync\n",
        "from utils.augmentations import letterbox #padding\n",
        "\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torchvision import models, transforms\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "#ã‚µãƒãƒ¼ãƒˆãƒ‘ãƒƒãƒã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "\n",
        "def interference(img, weight):\n",
        "    device = 'cpu'\n",
        "    device = select_device(device)\n",
        "    model = DetectMultiBackend(weight, device=device, dnn=False)\n",
        "    #stride, names, pt, jit, onnx, engine = model.stride, model.names, model.pt, model.jit, model.onnx, model.engine\n",
        "    #imgsz = check_img_size([640], s=stride)  # check image size\n",
        "\n",
        "    #class_names = {0:\"cont\", 1:\"grav\"}\n",
        "\n",
        "    # transform = transforms.Compose([\n",
        "    #             transforms.Resize(size=(480,640)),\n",
        "    #             transforms.ToTensor(),\n",
        "    #             # transforms.Normalize(\n",
        "    #             #     mean=[0.5, 0.5, 0.5],\n",
        "    #             #     std=[0.5, 0.5, 0.5]\n",
        "    #             #    )\n",
        "    #             ])\n",
        "\n",
        "    img_cv2 = cv2.imread(img) #CV2ã§é–‹ã\n",
        "    img_cv2 = letterbox(img_cv2, (640,640), stride=32, auto=False)[0] #resize, ä¸Šä¸‹padding (color 114)\n",
        "\n",
        "    #cv2_imshow(img_cv2)\n",
        "\n",
        "    img_cv2 = img_cv2.transpose((2, 0, 1))[::-1]  # HWC to CHW, BGR to RGB\n",
        "    img_cv2 = np.ascontiguousarray(img_cv2)\n",
        "    img_tensor = torch.from_numpy(img_cv2).float()\n",
        "\n",
        "    #img_tensor = transform(img_np)\n",
        "    img_tensor /= 255\n",
        "    #print(img_tensor.shape)\n",
        "\n",
        "    #print(img_tensor)\n",
        "    img_tensor = torch.unsqueeze(img_tensor, 0)  # ãƒãƒƒãƒå¯¾å¿œ\n",
        "\n",
        "\n",
        "    pred = model(img_tensor, visualize=False, augment=False)\n",
        "\n",
        "    pred = non_max_suppression(pred, conf_thres=0.25, iou_thres=0.45, classes=None,  max_det=1000)\n",
        "\n",
        "    print(f\"pred: {pred}\")\n",
        "\n",
        "    return pred"
      ],
      "metadata": {
        "id": "VPTVErBetQT9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import glob\n",
        "\n",
        "\n",
        "image_path = glob.glob(f\"{dataset_olympia_grav}/*\")\n",
        "start_index = 1\n",
        "end_index = 5\n",
        "\n",
        "class_names = {0: \"cont\", 1: \"grav\"}\n",
        "\n",
        "for i in range(start_index, end_index + 1):\n",
        "    img = image_path[i]\n",
        "\n",
        "    pred = interference(img, weight)\n",
        "\n",
        "    # output result\n",
        "    x1, y1, x2, y2, prob, class_num = torch.round(pred[0][0])\n",
        "\n",
        "    # probability\n",
        "    prob = pred[0][0][4].item()\n",
        "\n",
        "    # class\n",
        "    class_name = class_names[pred[0][0][5].item()]\n",
        "\n",
        "    print(\"è¨ºæ–­ã¯ %sã€ç¢ºç‡ã¯%.1fï¼…ã§ã™ã€‚\" % (class_name, prob * 100))\n",
        "\n",
        "    img_cv2 = cv2.imread(img)\n",
        "    img_cv2 = cv2.resize(img_cv2, (640, int(img_cv2.shape[0] * 640 / img_cv2.shape[1])))  # æ¨ªå¹…ã‚’640pxã«ãƒªã‚µã‚¤ã‚º\n",
        "\n",
        "    # calculate coordinates of the bounding box (640*640ã«paddingã•ã‚Œã¦ã„ã‚‹åˆ†ã®åº§æ¨™ã‚’è¶³ã™)\n",
        "    img_height, img_width, _ = img_cv2.shape[:3]\n",
        "    print(f\"img_height: {img_height}, img_width: {img_width}\")\n",
        "    padding_x = (img_height - min(img_width, img_height)) / 2\n",
        "    padding_y = (img_width - min(img_width, img_height)) / 2\n",
        "    x1 = x1 - padding_x\n",
        "    y1 = y1 - padding_y\n",
        "    x2 = x2 - padding_x\n",
        "    y2 = y2 - padding_y\n",
        "    print(f\"x1: {x1}, y1: {y1}, x2: {x2}, y2: {y2}\")\n",
        "\n",
        "    # draw bounding box\n",
        "    cv2.rectangle(img_cv2, (int(x1), int(y1)), (int(x2), int(y2)), (255, 0, 0), 2)\n",
        "\n",
        "    # show image\n",
        "    cv2_imshow(img_cv2)\n"
      ],
      "metadata": {
        "id": "_NeSLz6rtalH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Testsetã®æ­£è§£ç‡ã‚’ç¢ºèª\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import glob\n",
        "\n",
        "class_names = {0: \"cont\", 1: \"grav\"}\n",
        "\n",
        "\n",
        "\n",
        "def interference_testset(image_path, answer):\n",
        "    pred_list = []\n",
        "    correct_list = [] #æ­£è§£ãªã‚‰1ã€ä¸æ­£è§£ãªã‚‰0\n",
        "\n",
        "    for img in image_path:\n",
        "        pred = interference(img, weight)\n",
        "\n",
        "        # output result\n",
        "        x1, y1, x2, y2, prob, class_num = torch.round(pred[0][0])\n",
        "\n",
        "        # probability\n",
        "        prob = pred[0][0][4].item()\n",
        "\n",
        "        # class\n",
        "        class_name = class_names[pred[0][0][5].item()]\n",
        "\n",
        "        if class_name == answer:\n",
        "            correct_list.append(1)\n",
        "        else:\n",
        "            correct_list.append(0)\n",
        "\n",
        "        print(\"è¨ºæ–­ã¯ %sã€ç¢ºç‡ã¯%.1fï¼…ã§ã™ã€‚\" % (class_name, prob * 100))\n",
        "\n",
        "    total_count = len(correct_list)\n",
        "    one_count = correct_list.count(1)\n",
        "    percentage = (one_count / total_count) * 100\n",
        "    print(\"\")\n",
        "    print(f\"image_path: {image_path}\")\n",
        "    print(f\"The percentage of corrects in the list is: {percentage:.2f}%\")\n",
        "    print(\"\")\n",
        "    print(\"\")\n",
        "    print(\"\")\n",
        "    print(\"\")\n",
        "    print(\"\")\n",
        "    print(\"\")\n",
        "    print(\"\")\n",
        "    print(\"\")\n",
        "\n",
        "interference_testset(glob.glob(f\"{dataset_olympia_grav}/*\"), \"grav\")\n",
        "interference_testset(glob.glob(f\"{dataset_olympia_cont}/*\"), \"cont\")\n",
        "interference_testset(glob.glob(f\"{dataset_handai_grav}/*\"), \"grav\")\n",
        "interference_testset(glob.glob(f\"{dataset_handai_cont}/*\"), \"cont\")\n"
      ],
      "metadata": {
        "id": "4iGCwXZrAcRX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Export coreML including non-max supression**"
      ],
      "metadata": {
        "id": "g7JhasvF89PY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# clone Yolov5 repo\n",
        "import os\n",
        "%cd /content\n",
        "!git clone https://github.com/hietalajulius/yolov5.git\n",
        "%cd yolov5\n",
        "!pip install -r requirements.txt -r requirements-export.txt"
      ],
      "metadata": {
        "id": "E7CfdEw-ylvG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weight_path = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training/yolo5n_100epoch.pt\""
      ],
      "metadata": {
        "id": "9uFOe6N9Aiwo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python export-nms.py --include coreml --weights $weight_path\n"
      ],
      "metadata": {
        "id": "tBf-4p1BArEe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Interference and crop Extended dataset**"
      ],
      "metadata": {
        "id": "mMbAS9qBSXsu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup YOLOv5\n",
        "%cd /content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training\n",
        "!git clone https://github.com/ultralytics/yolov5\n",
        "%cd yolov5\n",
        "%pip install -qr requirements.txt\n",
        "\n",
        "import torch\n",
        "import utils\n",
        "display = utils.notebook_init()"
      ],
      "metadata": {
        "id": "argQTM34hQEI",
        "outputId": "0f8f99ad-cf66-430e-f771-1741a546d52f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv5 ğŸš€ v7.0-72-g064365d Python-3.8.10 torch-1.13.1+cu116 CUDA:0 (NVIDIA A100-SXM4-40GB, 40536MiB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete âœ… (12 CPUs, 83.5 GB RAM, 24.9/166.8 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ãƒ‘ã‚¹ã‚’æŒ‡å®šã™ã‚‹\n",
        "weight = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training/yolo5n_100epoch.pt\"\n",
        "input_folder = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training/train/images\"\n",
        "output_folder = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_cropped_using_YOLO/train\""
      ],
      "metadata": {
        "id": "SK0LQ6a7hpmA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from models.common import DetectMultiBackend\n",
        "#from utils.datasets import IMG_FORMATS, VID_FORMATS, LoadImages, LoadStreams\n",
        "from utils.general import (LOGGER, check_file, check_img_size, check_imshow, check_requirements, colorstr,\n",
        "                           increment_path, non_max_suppression, print_args, strip_optimizer, xyxy2xywh)\n",
        "#from utils.plots import Annotator, colors, save_one_box\n",
        "from utils.torch_utils import select_device, time_sync\n",
        "from utils.augmentations import letterbox #padding\n",
        "\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torchvision import models, transforms\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "#ã‚µãƒãƒ¼ãƒˆãƒ‘ãƒƒãƒã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "\n",
        "def interference(img, weight):\n",
        "    #stride, names, pt, jit, onnx, engine = model.stride, model.names, model.pt, model.jit, model.onnx, model.engine\n",
        "    #imgsz = check_img_size([640], s=stride)  # check image size\n",
        "\n",
        "    #class_names = {0:\"cont\", 1:\"grav\"}\n",
        "\n",
        "    # transform = transforms.Compose([\n",
        "    #             transforms.Resize(size=(480,640)),\n",
        "    #             transforms.ToTensor(),\n",
        "    #             # transforms.Normalize(\n",
        "    #             #     mean=[0.5, 0.5, 0.5],\n",
        "    #             #     std=[0.5, 0.5, 0.5]\n",
        "    #             #    )\n",
        "    #             ])\n",
        "\n",
        "    img_cv2 = cv2.imread(img) #CV2ã§é–‹ã\n",
        "    img_cv2 = letterbox(img_cv2, (640,640), stride=32, auto=False)[0] #resize, ä¸Šä¸‹padding (color 114)\n",
        "\n",
        "    #cv2_imshow(img_cv2)\n",
        "\n",
        "    img_cv2 = img_cv2.transpose((2, 0, 1))[::-1]  # HWC to CHW, BGR to RGB\n",
        "    img_cv2 = np.ascontiguousarray(img_cv2)\n",
        "    img_tensor = torch.from_numpy(img_cv2).float()\n",
        "\n",
        "    #img_tensor = transform(img_np)\n",
        "    img_tensor /= 255\n",
        "    #print(img_tensor.shape)\n",
        "\n",
        "    #print(img_tensor)\n",
        "    img_tensor = torch.unsqueeze(img_tensor, 0)  # ãƒãƒƒãƒå¯¾å¿œ\n",
        "\n",
        "\n",
        "    pred = model(img_tensor, visualize=False, augment=False)\n",
        "\n",
        "    pred = non_max_suppression(pred, conf_thres=0.25, iou_thres=0.45, classes=None,  max_det=1000)\n",
        "\n",
        "    print(f\"pred: {pred}\")\n",
        "\n",
        "    return pred"
      ],
      "metadata": {
        "id": "6qZSIfF5hjGC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import os\n",
        "\n",
        "# image_path = glob.glob(f\"{dataset_grav}/*\")\n",
        "# img = image_path[100]\n",
        "\n",
        "class_names = {0:\"cont\", 1:\"grav\"}\n",
        "\n",
        "device = 'cpu' # device = None or 'cpu' or 0 or '0' or '0,1,2,3'\n",
        "device = select_device(device)\n",
        "model = DetectMultiBackend(weight, device=device, dnn=False)\n",
        "\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "for img in tqdm(glob.glob(f\"{input_folder}/*\")):\n",
        "\n",
        "    pred = interference(img, weight)\n",
        "\n",
        "    # output result\n",
        "    x1, y1, x2, y2, prob, class_num = torch.round(pred[0][0])\n",
        "\n",
        "    # probability\n",
        "    prob = pred[0][0][4].item()\n",
        "\n",
        "    # class\n",
        "    class_name = class_names[pred[0][0][5].item()]\n",
        "\n",
        "    print(\"è¨ºæ–­ã¯ %sã€ç¢ºç‡ã¯%.1fï¼…ã§ã™ã€‚\" %(class_name, prob*100))\n",
        "\n",
        "    img_cv2 = cv2.imread(img)\n",
        "\n",
        "    # calculate coordinates of the bounding box (640*640ã«paddingã•ã‚Œã¦ã„ã‚‹åˆ†ã®åº§æ¨™ã‚’è¶³ã™)\n",
        "    img_height, img_width, _ = img_cv2.shape[:3]\n",
        "    print(f\"img_height: {img_height}, img_width: {img_width}\")\n",
        "    padding_x = (img_height - min(img_width, img_height))/2\n",
        "    padding_y = (img_width - min(img_width, img_height))/2\n",
        "    x1 = x1 - padding_x\n",
        "    y1 = y1 - padding_y\n",
        "    x2 = x2 - padding_x\n",
        "    y2 = y2 - padding_y\n",
        "    print(f\"x1: {x1}, y1: {y1}, x2: {x2}, y2: {y2}\")\n",
        "\n",
        "    # draw bounding box\n",
        "    #cv2.rectangle(img_cv2, (int(x1), int(y1)), (int(x2), int(y2)), (255, 0, 0), 2)\n",
        "\n",
        "    # show image\n",
        "    #cv2_imshow(img_cv2)\n",
        "\n",
        "    # ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã§ç”»åƒã‚’åˆ‡ã‚ŠæŠœãã€\n",
        "\n",
        "    if x1 < 0: #è² ã®å ´åˆã®ã‚¨ãƒ©ãƒ¼å›é¿\n",
        "        x1 = 0\n",
        "\n",
        "    cropped_image = img_cv2[int(y1):int(y2), int(x1):int(x2)]\n",
        "\n",
        "    # åˆ‡ã‚ŠæŠœã„ãŸç”»åƒã‚’ä¿å­˜ã™ã‚‹\n",
        "    save_path = f\"{output_folder}/{os.path.basename(img)}\"\n",
        "    print(save_path)\n",
        "    #cv2_imshow(cropped_image)\n",
        "    cv2.imwrite(save_path, cropped_image)"
      ],
      "metadata": {
        "id": "iJqs6HmydRUO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#rewrite csv file (bootcampç”¨csvã®image_pathã‚’æ”¹å¤‰)\n",
        "import pandas as pd\n",
        "\n",
        "csv_1_orig = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training/train_list.csv\"\n",
        "csv_2_orig = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training/valid_list.csv\"\n",
        "csv_1 = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_cropped_using_YOLO/train_list.csv\"\n",
        "csv_2 = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_cropped_using_YOLO/valid_list.csv\"\n",
        "\n",
        "def rewrite_csv(df):\n",
        "    path_list = []\n",
        "    for path in df[\"image_path\"]:\n",
        "        path = path.replace(\"periocular_for_YOLO_training\", \"periocular_cropped_using_YOLO\")\n",
        "        path = path.replace(\"images/\", \"\")\n",
        "        path_list.append(path)\n",
        "    df[\"image_path\"] = path_list\n",
        "    return(df)\n",
        "\n",
        "df = pd.read_csv(csv_1_orig)\n",
        "df = rewrite_csv(df)\n",
        "print(df)\n",
        "df.to_csv(csv_1, index=False)\n",
        "\n",
        "df = pd.read_csv(csv_2_orig)\n",
        "df = rewrite_csv(df)\n",
        "df.to_csv(csv_2,  index=False)"
      ],
      "metadata": {
        "id": "z9kG4PiPlCyP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **To do Next**"
      ],
      "metadata": {
        "id": "pStgcOTIFO62"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ãƒ»å¤–éƒ¨ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼ˆTreatedï¼‰ã‚’æ´—ã„å‡ºã—\n",
        "\n",
        "ãƒ»å†…éƒ¨ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ã•ã‚‰ã«æ°´å¢—ã—\n",
        "\n",
        "ãƒ»å†…éƒ¨ãŠã‚ˆã³å¤–éƒ¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚ˆã‚Šã€testç”¨å„100æšï¼ˆgrav50æšã€cont50æšï¼‰ã‚’æŠœãå‡ºã—ã¦ãŠãã€åˆä½“ã™ã‚‹\n",
        "\n",
        "ãƒ»æ—¢å­˜ã®YOLOv5ã‚’ç”¨ã„ã¦bounding boxã‚’æŠœãå‡ºã—ã€æ–°ãŸã«ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹"
      ],
      "metadata": {
        "id": "UjetedHEGU6w"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Hp2FOqU89Qgh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO14I3Fuf+d0VhG6A8wm/am",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykitaguchi77/GO_AI_project/blob/main/make_super_extend_dataset_iFish_for_YOLO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Create extended dataset for YOLOv5 implementation**\n",
        "\n",
        "#Olympia\n",
        "・Olympia dataset\n",
        "\n",
        "Treated 640px: 561枚。テストに50枚を残す（test_olympia）、残りの511枚をtrain/valに回す\n",
        "\n",
        "Control 640px: 169枚。テストに50枚を残す(test_control)、残りの119枚をtrain/valに回す\n",
        "\n",
        "#Handai\n",
        "・GO_extended_dataset\n",
        "\n",
        "control: 1886枚。テストに50枚を残す(test_handai)、残りの1836枚をtrain/valに回す\n",
        "\n",
        "treatable: 1879枚。テストに50枚を残す(test_handai)、残りの1829枚をtrain/valに回す\n",
        "\n",
        "\n",
        "#合計：\n",
        "treatable: 1829 + 119\n",
        "\n",
        "control: 1836 + 511\n",
        "\n",
        "testset: Olympia treated 50, control 50, Handai treated 50, control 50\n",
        "\n",
        "##既存のYOLOでbounding boxを作成 --> classは既知のもので。Glaucomaのrepositoryを参考にしてYOLO datasetを作成。"
      ],
      "metadata": {
        "id": "BW6BkO088P6u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ds7rvBFs8LcO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d06eeee-d4b2-4314-e4ef-4ae719a66539"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "import glob\n",
        "import random\n",
        "from PIL import Image\n",
        "import time\n",
        "%matplotlib inline\n",
        "\n",
        "#サポートパッチのインポート\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "\n",
        "\n",
        "# Google Driveをマウント\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ファイル数確認用\n",
        "import os\n",
        "\n",
        "def countfile(name, path):\n",
        "    print(f\"path: {path}\")\n",
        "    print(f\"number: {len(os.listdir(path))}\")\n",
        "    print(\"\")\n",
        "\n",
        "if not os.path.exists(\"/content/GO_extended_dataset\"):\n",
        "    !unzip /content/drive/MyDrive/Deep_learning/GO_extended_dataset/GO_extended_dataset.zip -d /content/\n",
        "\n",
        "\n",
        "olympia_cont_dir = \"/content/drive/MyDrive/Deep_learning/Olympia_dataset/control_640px\"\n",
        "olympia_grav_dir = \"/content/drive/MyDrive/Deep_learning/Olympia_dataset/treated_640px\"\n",
        "handai_cont_dir = \"/content/GO_extended_dataset/Control_photo_1886mai\"\n",
        "handai_grav_dir = \"/content/GO_extended_dataset/treatable\"\n",
        "\n",
        "\n",
        "countfile(\"control_640px_olympia\", olympia_cont_dir)\n",
        "countfile(\"treated_640px_olympia\", olympia_grav_dir)\n",
        "\n",
        "countfile(\"control_handai\", handai_cont_dir)\n",
        "countfile(\"treated_handai\", handai_grav_dir)\n"
      ],
      "metadata": {
        "id": "JFEWXrZrz_CY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Handai dataset, Olympia dataset --> super_extend_datase_for_YOLO**"
      ],
      "metadata": {
        "id": "6pYCYtrN79vn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dst_dir = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO\"\n",
        "\n",
        "if os.path.exists(dst_dir):\n",
        "    shutil.rmtree(dst_dir)\n",
        "os.makedirs(dst_dir)\n",
        "os.makedirs(f\"{dst_dir}/train_val\")\n",
        "os.makedirs(f\"{dst_dir}/train_val/grav\")\n",
        "os.makedirs(f\"{dst_dir}/train_val/cont\")\n",
        "os.makedirs(f\"{dst_dir}/test\")\n",
        "os.makedirs(f\"{dst_dir}/test/handai/grav\")\n",
        "os.makedirs(f\"{dst_dir}/test/handai/cont\")\n",
        "os.makedirs(f\"{dst_dir}/test/olympia/grav\")\n",
        "os.makedirs(f\"{dst_dir}/test/olympia/cont\")"
      ],
      "metadata": {
        "id": "FlAqRIZbCDRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "\n",
        "random_state = 1\n",
        "\n",
        "# Olympia Control images\n",
        "src_cont = olympia_cont_dir\n",
        "test_cont = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO/test/olympia/cont\"\n",
        "trainval_cont = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO/train_val/cont\"\n",
        "\n",
        "cont_images = os.listdir(src_cont)\n",
        "random.Random(random_state).shuffle(cont_images)\n",
        "\n",
        "test_cont_images = cont_images[:50]\n",
        "trainval_cont_images = cont_images[50:]\n",
        "\n",
        "for image in tqdm(test_cont_images, desc=\"Copying test cont images\"):\n",
        "    src_path = os.path.join(src_cont, image)\n",
        "    dst_path = os.path.join(test_cont, image)\n",
        "    shutil.copy(src_path, dst_path)\n",
        "\n",
        "for image in tqdm(trainval_cont_images, desc=\"Copying trainval cont images\"):\n",
        "    src_path = os.path.join(src_cont, image)\n",
        "    dst_path = os.path.join(trainval_cont, image)\n",
        "    shutil.copy(src_path, dst_path)\n",
        "\n",
        "\n",
        "# Olympia Grav images\n",
        "src_grav = olympia_grav_dir\n",
        "test_grav = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO/test/olympia/grav\"\n",
        "trainval_grav = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO/train_val/grav\"\n",
        "\n",
        "grav_images = os.listdir(src_grav)\n",
        "random.Random(random_state).shuffle(grav_images)\n",
        "\n",
        "test_grav_images = grav_images[:50]\n",
        "trainval_grav_images = grav_images[50:]\n",
        "\n",
        "for image in tqdm(test_grav_images, desc=\"Copying test grav images\"):\n",
        "    src_path = os.path.join(src_grav, image)\n",
        "    dst_path = os.path.join(test_grav, image)\n",
        "    shutil.copy(src_path, dst_path)\n",
        "\n",
        "for image in tqdm(trainval_grav_images, desc=\"Copying trainval grav images\"):\n",
        "    src_path = os.path.join(src_grav, image)\n",
        "    dst_path = os.path.join(trainval_grav, image)\n",
        "    shutil.copy(src_path, dst_path)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sta5Z-LLC01f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfb3c992-8961-4a5f-c6f9-98807749f318"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Copying test cont images: 100%|██████████| 50/50 [00:09<00:00,  5.51it/s]\n",
            "Copying trainval cont images: 100%|██████████| 119/119 [00:03<00:00, 33.30it/s]\n",
            "Copying test grav images: 100%|██████████| 50/50 [00:28<00:00,  1.74it/s]\n",
            "Copying trainval grav images: 100%|██████████| 511/511 [00:16<00:00, 30.59it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from shutil import copyfile\n",
        "from tqdm import tqdm\n",
        "\n",
        "grav_dir = olympia_grav_dir\n",
        "cont_dir = olympia_cont_dir\n",
        "test_grav_dir = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO/test/olympia/grav\"\n",
        "test_cont_dir = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO/test/olympia/cont\"\n",
        "train_val_grav_dir = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO/train_val/grav\"\n",
        "train_val_cont_dir = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO/train_val/cont\"\n",
        "\n",
        "# Check if files in grav_dir are in test_grav_dir\n",
        "for filename in tqdm(os.listdir(grav_dir)):\n",
        "    basename = os.path.basename(filename)\n",
        "    if os.path.exists(os.path.join(test_grav_dir, basename)):\n",
        "        print(\"coooool!!!\")\n",
        "        continue\n",
        "    else:\n",
        "        copyfile(os.path.join(grav_dir, filename), os.path.join(train_val_grav_dir, filename))\n",
        "\n",
        "# Check if files in cont_dir are in test_cont_dir\n",
        "for filename in tqdm(os.listdir(cont_dir)):\n",
        "    basename = os.path.basename(filename)\n",
        "    if os.path.exists(os.path.join(test_cont_dir, basename)):\n",
        "        print(\"hotttttt!!!\")\n",
        "        continue\n",
        "    else:\n",
        "        copyfile(os.path.join(cont_dir, filename), os.path.join(train_val_cont_dir, filename))\n"
      ],
      "metadata": {
        "id": "-Ll-LhlRKSQN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#####################\n",
        "# rename\n",
        "#指定されたフォルダ内にあるファイル名が\"olympia_\"から始まらない場合に、\"olympia_\"を先頭につけたファイル名にリネームする処理を行う。\n",
        "#####################\n",
        "\n",
        "import os\n",
        "\n",
        "# フォルダのパスを指定\n",
        "test_grav_dir = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO/test/olympia/grav\"\n",
        "test_cont_dir = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO/test/olympia/cont\"\n",
        "train_val_grav_dir = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO/train_val/grav\"\n",
        "train_val_cont_dir = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO/train_val/cont\"\n",
        "\n",
        "# ファイル名が \"olympia_\" から始まらない場合、\"olympia_\" を先頭につけたファイル名にリネームする\n",
        "def rename_file(path):\n",
        "    for filename in os.listdir(path):\n",
        "        if not filename.startswith(\"oly_\"):\n",
        "            new_filename = \"oly_\" + filename\n",
        "            os.rename(os.path.join(path, filename), os.path.join(path, new_filename))\n",
        "\n",
        "# リネーム処理を実行\n",
        "rename_file(test_grav_dir)\n",
        "rename_file(test_cont_dir)\n",
        "rename_file(train_val_grav_dir)\n",
        "rename_file(train_val_cont_dir)\n"
      ],
      "metadata": {
        "id": "AleU8QFERy6K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(os.listdir(\"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO/train_val/grav\")))\n",
        "print(len(os.listdir(\"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO/train_val/cont\")))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQ3tV45TLy95",
        "outputId": "53c8f4e2-86c2-4c06-fc32-670649df511b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "511\n",
            "119\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "import os\n",
        "import random\n",
        "import shutil\n",
        "from tqdm import tqdm\n",
        "\n",
        "############################\n",
        "# Handai GO_extended_dataset\n",
        "#\n",
        "# /treatable → /train_val/grav\n",
        "# /control → /train_val/Control_photo_1886mai\n",
        "#\n",
        "############################\n",
        "\n",
        "if not os.path.exists(\"/content/GO_extended_dataset\"):\n",
        "    !unzip /content/drive/MyDrive/Deep_learning/GO_extended_dataset/GO_extended_dataset.zip -d /content/\n",
        "\n",
        "#file_name, class, idxのりストを作成\n",
        "def get_file_info(src_dir, class_id):\n",
        "    file_list = os.listdir(src_dir)\n",
        "    ids_list = [int(file_name.split('.')[0].split('-')[0]) for file_name in file_list]\n",
        "    class_list = [class_id] * len(file_list)\n",
        "    return file_list, ids_list, class_list\n",
        "\n",
        "# Contフォルダの情報\n",
        "cont_dir = '/content/GO_extended_dataset/Control_photo_1886mai'\n",
        "file_list_cont, ids_list_cont, class_list_cont = get_file_info(cont_dir, 0)\n",
        "\n",
        "# Gravフォルダの情報\n",
        "grav_dir = '/content/GO_extended_dataset/treatable'\n",
        "file_list_grav, ids_list_grav, class_list_grav = get_file_info(grav_dir, 1)\n",
        "\n",
        "# 結合\n",
        "file_list = file_list_cont + file_list_grav\n",
        "ids_list = ids_list_cont + ids_list_grav\n",
        "class_list = class_list_cont + class_list_grav\n",
        "\n",
        "print(file_list)\n",
        "print(ids_list)\n",
        "print(class_list)\n",
        "\n",
        "\n",
        "\n",
        "import random\n",
        "\n",
        "# file_listに画像のパスが、ids_listに患者のidが、class_listにgravかcontか(0 or 1)が格納されていると仮定する\n",
        "# 例: file_list = ['/path/to/image1.jpg', '/path/to/image2.jpg', ...]\n",
        "#     ids_list = ['patient1', 'patient1', 'patient2', 'patient3', ...]\n",
        "#     class_list = [0, 1, 0, 1, ...]\n",
        "\n",
        "# ランダムシードを固定する\n",
        "random.seed(1234)\n",
        "\n",
        "# idごとに画像のリストをまとめる\n",
        "id_to_files = {}\n",
        "for i, id in enumerate(ids_list):\n",
        "    if id not in id_to_files:\n",
        "        id_to_files[id] = []\n",
        "    id_to_files[id].append((file_list[i], class_list[i]))\n",
        "\n",
        "# idごとに画像をtestかtrainに振り分ける\n",
        "test_files = []\n",
        "train_files = []\n",
        "for id in id_to_files:\n",
        "    files = id_to_files[id]\n",
        "    random.shuffle(files)  # 同じid内の画像の順番をランダムに並べ替える\n",
        "    for file, cls in files:\n",
        "        if len(test_files) < 50 and cls == 0:\n",
        "            test_files.append((file, cls))\n",
        "        else:\n",
        "            train_files.append((file, cls))\n",
        "\n",
        "# 確認\n",
        "print(len(test_files), len(train_files))  # 50 以上の場合は再実行してください。"
      ],
      "metadata": {
        "id": "DjeQtXC5F_7d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "import numpy as np\n",
        "from sklearn.model_selection import GroupShuffleSplit\n",
        "\n",
        "############################\n",
        "# Handai GO_extended_dataset\n",
        "#\n",
        "# /treatable → /train_val/grav\n",
        "# /control → /train_val/Control_photo_1886mai\n",
        "#\n",
        "############################\n",
        "\n",
        "if not os.path.exists(\"/content/GO_extended_dataset\"):\n",
        "    !unzip /content/drive/MyDrive/Deep_learning/GO_extended_dataset/GO_extended_dataset.zip -d /content/\n",
        "\n",
        "# Contフォルダのパス\n",
        "src_dir = '/content/GO_extended_dataset/Control_photo_1886mai'\n",
        "train_val_dir = '/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO/train_val/cont'\n",
        "test_dir = '/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO/test/handai/cont'\n",
        "\n",
        "# ファイルリストを取得し、IDを抽出してリストに格納\n",
        "file_list = os.listdir(src_dir)\n",
        "ids = [int(file_name.split('.')[0].split('-', 1)[0]) for file_name in file_list]\n",
        "\n",
        "# IDごとにグループを作成して、group-stratifiedに分割\n",
        "splitter = GroupShuffleSplit(n_splits=1, test_size=50, random_state=2)\n",
        "train_val_indices, test_indices = next(splitter.split(file_list, groups=ids))\n",
        "\n",
        "# 学習用とテスト用のフォルダにファイルをコピー\n",
        "for i, file_name in tqdm(enumerate(file_list), total=len(file_list)):\n",
        "    src_path = os.path.join(src_dir, file_name)\n",
        "    dst_dir = test_dir if i in test_indices else train_val_dir\n",
        "    dst_path = os.path.join(dst_dir, file_name)\n",
        "    shutil.copy(src_path, dst_path)\n",
        "\n",
        "# Gravフォルダのパス\n",
        "src_dir = '/content/GO_extended_dataset/treatable'\n",
        "train_val_dir = '/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO/train_val/grav'\n",
        "test_dir = '/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO/test/handai/grav'\n",
        "\n",
        "# ファイルリストを取得し、IDを抽出してリストに格納\n",
        "file_list = os.listdir(src_dir)\n",
        "ids = [int(file_name.split('.')[0].split('-', 1)[0]) for file_name in file_list]\n",
        "\n",
        "# IDごとにグループを作成して、group-stratifiedに分割\n",
        "splitter = GroupShuffleSplit(n_splits=1, test_size=15, random_state=4)\n",
        "train_val_indices, test_indices = next(splitter.split(file_list, groups=ids))\n",
        "print(len(test_indices))\n",
        "\n",
        "# 学習用とテスト用のフォルダにファイルをコピー\n",
        "for i, file_name in tqdm(enumerate(file_list), total=len(file_list)):\n",
        "    src_path = os.path.join(src_dir, file_name)\n",
        "    dst_dir = test_dir if i in test_indices else train_val_dir\n",
        "    dst_path = os.path.join(dst_dir, file_name)\n",
        "    shutil.copy(src_path, dst_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dy5IinNPpPgO",
        "outputId": "4644b4fb-b027-47e9-8e1f-f1434c2c3ea7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1886/1886 [00:44<00:00, 42.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1879/1879 [00:40<00:00, 46.03it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #（GroupShuffleSplitがgroupごとに分割するので）総数が50になるようにrandom_stateとtest_sizeを調節\n",
        "# # 結果の格納用リスト\n",
        "# # Gravフォルダのパス\n",
        "# src_dir = '/content/GO_extended_dataset/treatable'\n",
        "# train_val_dir = '/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO/train_val/grav'\n",
        "# test_dir = '/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO/test/handai/grav'\n",
        "\n",
        "# # ファイルリストを取得し、IDを抽出してリストに格納\n",
        "# file_list = os.listdir(src_dir)\n",
        "# ids = [int(file_name.split('.')[0].split('-', 1)[0]) for file_name in file_list]\n",
        "\n",
        "# results = []\n",
        "\n",
        "# for random_state in range(10):\n",
        "#     for test_size in range(1, 51):\n",
        "#         splitter = GroupShuffleSplit(n_splits=1, test_size=test_size, random_state=random_state)\n",
        "#         train_val_indices, test_indices = next(splitter.split(file_list, groups=ids))\n",
        "#         test_set_size = len(test_indices)\n",
        "#         print(f\"random_state: {random_state}, test_size: {test_size}, test_set_size: {test_set_size}\")\n",
        "#         if test_set_size == 50:\n",
        "#             print(\"Coooool!!\")\n",
        "#             results.append((random_state, test_size))\n",
        "\n",
        "# # 結果の表示\n",
        "# for result in results:\n",
        "#     print(f\"random_state: {result[0]}, test_size: {result[1]}\")\n"
      ],
      "metadata": {
        "id": "MMk9fpa9zkZ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**ファイル数の確認**"
      ],
      "metadata": {
        "id": "jQkGRfUO9omP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dir = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO\"\n",
        "print(len(os.listdir(f\"{dir}/train_val/grav\")))\n",
        "print(len(os.listdir(f\"{dir}/train_val/cont\")))\n",
        "print(len(os.listdir(f\"{dir}/test/olympia/grav\")))\n",
        "print(len(os.listdir(f\"{dir}/test/olympia/cont\")))\n",
        "print(len(os.listdir(f\"{dir}/test/handai/grav\")))\n",
        "print(len(os.listdir(f\"{dir}/test/handai/cont\")))\n",
        "\n",
        "\"\"\"\n",
        "2340\n",
        "1933\n",
        "50\n",
        "50\n",
        "50\n",
        "50\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "aGGR7_-P96mS",
        "outputId": "a49aaf81-dbc7-4264-c516-f90ca626bcc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2340\n",
            "1955\n",
            "50\n",
            "50\n",
            "50\n",
            "50\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n2340\\n1933\\n50\\n50\\n50\\n50\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**既存のYOLOv5モデルを用いてバウンディングボックスを設定**"
      ],
      "metadata": {
        "id": "R6FT8pBYNvF7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dst_dir = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO/train_val/labels\"\n",
        "if os.path.exists(dst_dir):\n",
        "    shutil.rmtree(dst_dir)\n",
        "os.makedirs(f\"{dst_dir}/grav\")\n",
        "os.makedirs(f\"{dst_dir}/cont\")"
      ],
      "metadata": {
        "id": "-wggPJzAOBYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup YOLOv5\n",
        "%cd /content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training\n",
        "!git clone https://github.com/ultralytics/yolov5\n",
        "%cd yolov5\n",
        "%pip install -qr requirements.txt\n",
        "\n",
        "import torch\n",
        "import utils\n",
        "display = utils.notebook_init()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1gF6whZ7P5ax",
        "outputId": "22f59ad2-8768-4d32-cf30-9a7634ac398f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv5 🚀 v7.0-72-g064365d Python-3.10.11 torch-2.0.1+cu118 CPU\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete ✅ (2 CPUs, 12.7 GB RAM, 34.7/225.8 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from models.common import DetectMultiBackend\n",
        "#from utils.datasets import IMG_FORMATS, VID_FORMATS, LoadImages, LoadStreams\n",
        "from utils.general import (LOGGER, check_file, check_img_size, check_imshow, check_requirements, colorstr,\n",
        "                           increment_path, non_max_suppression, print_args, strip_optimizer, xyxy2xywh)\n",
        "#from utils.plots import Annotator, colors, save_one_box\n",
        "from utils.torch_utils import select_device, time_sync\n",
        "from utils.augmentations import letterbox #padding\n",
        "\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torchvision import models, transforms\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "#サポートパッチのインポート\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "\n",
        "def interference(img, weight):\n",
        "    device = 'cpu'\n",
        "    device = select_device(device)\n",
        "    model = DetectMultiBackend(weight, device=device, dnn=False)\n",
        "    #stride, names, pt, jit, onnx, engine = model.stride, model.names, model.pt, model.jit, model.onnx, model.engine\n",
        "    #imgsz = check_img_size([640], s=stride)  # check image size\n",
        "\n",
        "    #class_names = {0:\"cont\", 1:\"grav\"}\n",
        "\n",
        "    # transform = transforms.Compose([\n",
        "    #             transforms.Resize(size=(480,640)),\n",
        "    #             transforms.ToTensor(),\n",
        "    #             # transforms.Normalize(\n",
        "    #             #     mean=[0.5, 0.5, 0.5],\n",
        "    #             #     std=[0.5, 0.5, 0.5]\n",
        "    #             #    )\n",
        "    #             ])\n",
        "\n",
        "    img_cv2 = cv2.imread(img) #CV2で開く\n",
        "    img_cv2 = letterbox(img_cv2, (640,640), stride=32, auto=False)[0] #resize, 上下padding (color 114)\n",
        "\n",
        "    #cv2_imshow(img_cv2)\n",
        "\n",
        "    img_cv2 = img_cv2.transpose((2, 0, 1))[::-1]  # HWC to CHW, BGR to RGB\n",
        "    img_cv2 = np.ascontiguousarray(img_cv2)\n",
        "    img_tensor = torch.from_numpy(img_cv2).float()\n",
        "\n",
        "    #img_tensor = transform(img_np)\n",
        "    img_tensor /= 255\n",
        "    #print(img_tensor.shape)\n",
        "\n",
        "    #print(img_tensor)\n",
        "    img_tensor = torch.unsqueeze(img_tensor, 0)  # バッチ対応\n",
        "\n",
        "\n",
        "    pred = model(img_tensor, visualize=False, augment=False)\n",
        "\n",
        "    pred = non_max_suppression(pred, conf_thres=0.25, iou_thres=0.45, classes=None,  max_det=1000)\n",
        "\n",
        "    print(f\"pred: {pred}\")\n",
        "\n",
        "    return pred"
      ],
      "metadata": {
        "id": "Yo05tVYVaD1N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def interference_thres(img, weight):\n",
        "    device = 'cpu'\n",
        "    device = select_device(device)\n",
        "    model = DetectMultiBackend(weight, device=device, dnn=False)\n",
        "    #stride, names, pt, jit, onnx, engine = model.stride, model.names, model.pt, model.jit, model.onnx, model.engine\n",
        "    #imgsz = check_img_size([640], s=stride)  # check image size\n",
        "\n",
        "    #class_names = {0:\"cont\", 1:\"grav\"}\n",
        "\n",
        "    # transform = transforms.Compose([\n",
        "    #             transforms.Resize(size=(480,640)),\n",
        "    #             transforms.ToTensor(),\n",
        "    #             # transforms.Normalize(\n",
        "    #             #     mean=[0.5, 0.5, 0.5],\n",
        "    #             #     std=[0.5, 0.5, 0.5]\n",
        "    #             #    )\n",
        "    #             ])\n",
        "\n",
        "    img_cv2 = cv2.imread(img) #CV2で開く\n",
        "    img_cv2 = letterbox(img_cv2, (640,640), stride=32, auto=False)[0] #resize, 上下padding (color 114)\n",
        "\n",
        "    #cv2_imshow(img_cv2)\n",
        "\n",
        "    img_cv2 = img_cv2.transpose((2, 0, 1))[::-1]  # HWC to CHW, BGR to RGB\n",
        "    img_cv2 = np.ascontiguousarray(img_cv2)\n",
        "    img_tensor = torch.from_numpy(img_cv2).float()\n",
        "\n",
        "    #img_tensor = transform(img_np)\n",
        "    img_tensor /= 255\n",
        "    #print(img_tensor.shape)\n",
        "\n",
        "    #print(img_tensor)\n",
        "    img_tensor = torch.unsqueeze(img_tensor, 0)  # バッチ対応\n",
        "\n",
        "\n",
        "    pred = model(img_tensor, visualize=False, augment=False)\n",
        "\n",
        "    pred = non_max_suppression(pred, conf_thres=0.15, iou_thres=0.25, classes=None,  max_det=1000)\n",
        "\n",
        "    #print(f\"pred: {pred}\")\n",
        "\n",
        "    return pred"
      ],
      "metadata": {
        "id": "P-HTdamj-mfN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "YOLOv5_model_path = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training/yolov5n_130epch.pt\"\n",
        "parent_dir = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO/train_val\"\n",
        "\n",
        "for class_name in [\"grav\", \"cont\"]:\n",
        "    if class_name == \"cont\":\n",
        "        class_num = 0\n",
        "    else:\n",
        "        class_num = 1\n",
        "    for image_path in glob.glob(f\"{parent_dir}/{class_name}/*\"):\n",
        "        name = os.path.splitext(os.path.basename(image_path))[0]\n",
        "        print(f\"image_name: {name}\")\n",
        "\n",
        "        #YOLOv5によりバウンディングボックスを抜き出す\n",
        "        try:\n",
        "            pred = interference(image_path, YOLOv5_model_path)[0].tolist()[0]\n",
        "        except: #通常の閾値設定で検出されない場合\n",
        "            pred = interference_thres(image_path, YOLOv5_model_path)[0].tolist()[0]\n",
        "        pred = [max(num, 0) for num in pred] #0より小さい座標は0に修正する\n",
        "        pred = [min(num, 640) for num in pred] #640より小さい座標は640に修正する\n",
        "        xcenter = ((pred[0]+pred[2])/2)/640\n",
        "        ycenter = ((pred[1]+pred[3])/2)/640\n",
        "        xwidth = (pred[2]-pred[0])/640\n",
        "        ywidth = (pred[3]-pred[1])/640\n",
        "\n",
        "        # ファイル名と作成する内容を指定\n",
        "        txt_name = f\"{parent_dir}/labels/{class_name}/{name}.txt\"\n",
        "        content = f\"{class_num} {xcenter} {ycenter} {xwidth} {ywidth}\"\n",
        "        with open(txt_name, \"w\") as file:\n",
        "            # テキストをファイルに書き込む\n",
        "            file.write(content)\n",
        "            print(f\"text file successfully created🙆 {content}\")\n",
        "            print(\"\")\n",
        "            print(\"\")\n",
        ""
      ],
      "metadata": {
        "id": "wlGbrrAWRtHT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87cf0f1f-91d4-4809-ab3d-ebf2d4ff255d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fusing layers... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred: [tensor([[ 64.66748, 227.64108, 514.43115, 399.88657,   0.88143,   0.00000]])]\n",
            "text file successfully created🙆 0 0.4524208068847656 0.4902559757232666 0.7027557373046875 0.2691335678100586\n",
            "\n",
            "\n",
            "image_name: 9808-20191114-22-094457_e056ae61aa8b734ef2992b52c8fe38add031cae5e048f4d91553a02c64b6c645\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Model summary: 157 layers, 1761871 parameters, 0 gradients, 4.1 GFLOPs\n",
            "YOLOv5 🚀 v7.0-72-g064365d Python-3.10.11 torch-2.0.1+cu118 CPU\n",
            "\n",
            "Fusing layers... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred: [tensor([[-5.88837e-01,  1.90427e+02,  6.37211e+02,  4.48986e+02,  8.17542e-01,  0.00000e+00]])]\n",
            "text file successfully created🙆 0 0.49782142639160154 0.4995415687561035 0.9956428527832031 0.40399904251098634\n",
            "\n",
            "\n",
            "image_name: 8027\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Model summary: 157 layers, 1761871 parameters, 0 gradients, 4.1 GFLOPs\n",
            "YOLOv5 🚀 v7.0-72-g064365d Python-3.10.11 torch-2.0.1+cu118 CPU\n",
            "\n",
            "Fusing layers... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred: [tensor([[ 27.75302, 228.71809, 604.83643, 465.75330,   0.86981,   0.00000]])]\n",
            "text file successfully created🙆 0 0.4942105054855347 0.5425557732582093 0.9016928195953369 0.3703675031661987\n",
            "\n",
            "\n",
            "image_name: 1033\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Model summary: 157 layers, 1761871 parameters, 0 gradients, 4.1 GFLOPs\n",
            "YOLOv5 🚀 v7.0-72-g064365d Python-3.10.11 torch-2.0.1+cu118 CPU\n",
            "\n",
            "Fusing layers... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred: [tensor([[  8.33530, 164.84067, 638.79395, 450.50369,   0.81064,   0.00000]])]\n",
            "text file successfully created🙆 0 0.5055697202682495 0.4807377815246582 0.9850916385650634 0.4463484764099121\n",
            "\n",
            "\n",
            "image_name: 4163\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Model summary: 157 layers, 1761871 parameters, 0 gradients, 4.1 GFLOPs\n",
            "YOLOv5 🚀 v7.0-72-g064365d Python-3.10.11 torch-2.0.1+cu118 CPU\n",
            "\n",
            "Fusing layers... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred: [tensor([[ 12.76440, 178.12775, 633.55420, 446.41986,   0.86880,   0.00000]])]\n",
            "text file successfully created🙆 0 0.504936408996582 0.48792781829833987 0.9699840545654297 0.419206428527832\n",
            "\n",
            "\n",
            "image_name: 5513\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Model summary: 157 layers, 1761871 parameters, 0 gradients, 4.1 GFLOPs\n",
            "YOLOv5 🚀 v7.0-72-g064365d Python-3.10.11 torch-2.0.1+cu118 CPU\n",
            "\n",
            "Fusing layers... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred: [tensor([[  5.46478, 185.79282, 633.87360, 426.82767,   0.85804,   0.00000]])]\n",
            "text file successfully created🙆 0 0.4994831085205078 0.4786097526550293 0.9818887710571289 0.3766169548034668\n",
            "\n",
            "\n",
            "image_name: 4183\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dir = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO/train_val\"\n",
        "print(len(os.listdir(f\"{dir}/grav\")))\n",
        "print(len(os.listdir(f\"{dir}/cont\")))\n",
        "print(len(os.listdir(f\"{dir}/labels/grav\")))\n",
        "print(len(os.listdir(f\"{dir}/labels/cont\")))\n",
        "\n",
        "\"\"\"\n",
        "2340\n",
        "1933\n",
        "2340\n",
        "1933\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "wzlaSDfE_Zk1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**YOLOv5用トレーニング用フォルダ作成**\n",
        "\n",
        "https://github.com/ykitaguchi77/GravCont_classification_colab/blob/master/Extend_dataset_YOLOv5%EF%BC%A0.ipynb\n",
        "\n",
        "https://book.st-hakky.com/docs/object-detection-yolov5-tutorial/"
      ],
      "metadata": {
        "id": "9XI1oisiBK1O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "\n",
        "---------------super_extend_for_YOLO_training --------train------labels\n",
        "                                              |           |--images\n",
        "                                              |\n",
        "                                              |------valid ----labels\n",
        "                                              |           |--images\n",
        "                                              |\n",
        "                                              |--dataset.yaml\n",
        "                                              |--yolov5\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "nt3WfWu_Bb_p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dst_path = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_for_YOLO_training\"\n",
        "orig_path = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO/train_val\"\n"
      ],
      "metadata": {
        "id": "ZbyOJj3g_8Fj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if os.path.exists(dst_path):\n",
        "    shutil.rmtree(dst_path)\n",
        "os.makedirs(dst_path)\n",
        "os.makedirs(f\"{dst_path}/train/images\")\n",
        "os.makedirs(f\"{dst_path}/train/labels\")\n",
        "os.makedirs(f\"{dst_path}/valid/images\")\n",
        "os.makedirs(f\"{dst_path}/valid/labels\")"
      ],
      "metadata": {
        "id": "DtXJAAtsCjP3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd $dst_path"
      ],
      "metadata": {
        "id": "uVip7xMUEDgf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile dataset.yaml\n",
        "# path\n",
        "train: /content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_for_YOLO_training/train/images\n",
        "val: /content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_for_YOLO_training/valid/images\n",
        "\n",
        "# num of classes\n",
        "nc: 2\n",
        "\n",
        "#class names\n",
        "names: ['cont', 'grav'] # class名を定義"
      ],
      "metadata": {
        "id": "PMwlnFiqCpxI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create dataset_list\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import glob\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "dataset_dir =  \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_for_YOLO_training/train_val\"\n",
        "\n",
        "\n",
        "# def split_dataset(dataset_dir):\n",
        "#     img_list = glob.glob(f\"{dataset_dir}/images/*\")\n",
        "#     img_train, img_test = train_test_split(img_list, test_size=0.3, random_state=0)\n",
        "\n",
        "#     # img_train, img_testに名前が一致するtxtファイルを抜き出す\n",
        "#     label_train = [f\"{dataset_dir}/labels/{os.path.basename(i).split('.')[0]}.txt\" for i in img_train]\n",
        "#     label_test = [f\"{dataset_dir}/labels/{os.path.basename(i).split('.')[0]}.txt\" for i in img_test]\n",
        "\n",
        "#     print(f\"train: {len(label_train)},test: {len(label_test)}\")\n",
        "\n",
        "#     return img_train, img_test, label_train, label_test\n",
        "\n",
        "def make_path_list(dir, class_name):\n",
        "    image_list =  [file for file in glob.glob(f\"{dir}/{class_name}/*\") if os.path.isfile(file) == True ]\n",
        "    label_list =  [f\"{dir}/{class_name}/labels/{os.path.basename(i).split('.')[0]}.txt\" for i in image_list]\n",
        "\n",
        "    id_list = [os.path.basename(i).split(\"-\")[0].split(\".\")[0] for i in image_list]\n",
        "\n",
        "    index = {}\n",
        "    id_idx = []\n",
        "    for item in id_list:\n",
        "        if item in index:\n",
        "            id_idx.append(index[item])\n",
        "        else:\n",
        "            index[item] = len(index) + 1\n",
        "            id_idx.append(index[item])\n",
        "    id_idx = [int(i) for i in id_idx]\n",
        "\n",
        "    print(f\"image_list: {image_list}\")\n",
        "    print(f\"label_list: {label_list}\")\n",
        "\n",
        "    return image_list, label_list, id_idx\n",
        "\n",
        "grav_image_list, grav_label_list, grav_id_idx = make_path_list(orig_path, \"grav\")\n",
        "cont_image_list, cont_label_list, cont_id_idx = make_path_list(orig_path, \"cont\")\n",
        "\n",
        "print(\"image\")\n",
        "print(f\"grav: {len(grav_image_list)}\")\n",
        "print(f\"cont: {len(cont_image_list)}\")\n",
        "print(\"label\")\n",
        "print(f\"grav: {len(grav_label_list)}\")\n",
        "print(f\"cont: {len(cont_label_list)}\")"
      ],
      "metadata": {
        "id": "Lb7vg1IfHSCT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split dataset using GroupShuffleSplit\n",
        "\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import shutil\n",
        "import numpy as np\n",
        "from sklearn.model_selection import GroupShuffleSplit\n",
        "\n",
        "############################\n",
        "# 以下をGroupShuffleSplitで分ける\n",
        "# super_extend_dataset_for_YOLO/train_val/grav\n",
        "# → /super_extend_for_YOLO_training/train/images\n",
        "# → /super_extend_for_YOLO_training/vallid/images\n",
        "#\n",
        "# super_extend_dataset_for_YOLO/train_val/cont\n",
        "# → /super_extend_for_YOLO_training/train/images\n",
        "# → /super_extend_for_YOLO_training/vallid/images\n",
        "#\n",
        "# 以下はbasenameが同じものを移動するのみとする\n",
        "# super_extend_dataset_for_YOLO/train_val/label/grav\n",
        "# → /super_extend_for_YOLO_training/train/labels\n",
        "# → /super_extend_for_YOLO_training/vallid/labels\n",
        "#\n",
        "# super_extend_dataset_for_YOLO/train_val/label/grav\n",
        "# → /super_extend_for_YOLO_training/train/labels\n",
        "# → /super_extend_for_YOLO_training/vallid/labels\n",
        "############################\n",
        "\n",
        "dst_folder = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_for_YOLO_training\"\n",
        "orig_folder = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO/train_val\"\n",
        "\n",
        "for class_name in [\"cont\", \"grav\"]:\n",
        "    # フォルダのパス\n",
        "    src_dir = f\"{orig_folder}/{class_name}\"\n",
        "    train_dir = f\"{dst_folder}/train/images\"\n",
        "    valid_dir = f\"{dst_folder}/valid/images\"\n",
        "\n",
        "    # ファイルリストを取得し、IDを抽出してリストに格納\n",
        "    file_list = os.listdir(src_dir)\n",
        "    ids = [str(file_name.split('.')[0].split('-', 1)[0]) for file_name in file_list]\n",
        "\n",
        "    # IDごとにグループを作成して、group-stratifiedに分割\n",
        "    splitter = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=2)\n",
        "    train_indices, valid_indices = next(splitter.split(file_list, groups=ids))\n",
        "\n",
        "    # 学習用とテスト用のフォルダにファイルをコピー\n",
        "    for i, file_name in tqdm(enumerate(file_list), total=len(file_list)):\n",
        "        src_path = os.path.join(src_dir, file_name)\n",
        "        dst_dir = valid_dir if i in valid_indices else train_dir\n",
        "        dst_path = os.path.join(dst_dir, file_name)\n",
        "        shutil.copy(src_path, dst_path)\n",
        "\n",
        "        label_file_name = file_name.rsplit(\".\", 1)[0] + \".txt\" #同じ名前のラベルファイルも移動\n",
        "        #print(f\"label_file_name: {label_file_name}\")\n",
        "        label_dst_dir = os.path.dirname(dst_path).replace(\"images\", \"labels\")\n",
        "        #print(f\"label_dst_dir: {label_dst_dir}\")\n",
        "\n",
        "        label_src_path = os.path.join(orig_folder, \"labels\", class_name, label_file_name)\n",
        "        label_dst_path = os.path.join(label_dst_dir, label_file_name)\n",
        "        shutil.copy(label_src_path, label_dst_path)"
      ],
      "metadata": {
        "id": "f8hUG0YRLnUq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"train_images: {len(os.listdir('/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_for_YOLO_training/train/images'))}\")\n",
        "print(f\"val_images: {len(os.listdir('/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_for_YOLO_training/valid/images'))}\")\n",
        "print(f\"train_labels: {len(os.listdir('/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_for_YOLO_training/train/labels'))}\")\n",
        "print(f\"val_labels: {len(os.listdir('/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_for_YOLO_training/valid/labels'))}\")\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "train_images: 3480\n",
        "val_images: 792\n",
        "train_labels: 3480\n",
        "val_labels: 792\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "S33XiPEhieCc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dst_dir"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "nkm96dMkicsq",
        "outputId": "086dfd59-20d6-445d-e199-58032f15059c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_for_YOLO_training/train/images'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZMpdg5EhfVfq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
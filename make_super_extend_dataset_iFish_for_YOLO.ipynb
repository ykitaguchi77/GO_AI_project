{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO14I3Fuf+d0VhG6A8wm/am",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykitaguchi77/GO_AI_project/blob/main/make_super_extend_dataset_iFish_for_YOLO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Create extended dataset for YOLOv5 implementation**\n",
        "\n",
        "#Olympia\n",
        "ãƒ»Olympia dataset\n",
        "\n",
        "Treated 640px: 561æžšã€‚ãƒ†ã‚¹ãƒˆã«50æžšã‚’æ®‹ã™ï¼ˆtest_olympiaï¼‰ã€æ®‹ã‚Šã®511æžšã‚’train/valã«å›žã™\n",
        "\n",
        "Control 640px: 169æžšã€‚ãƒ†ã‚¹ãƒˆã«50æžšã‚’æ®‹ã™(test_control)ã€æ®‹ã‚Šã®119æžšã‚’train/valã«å›žã™\n",
        "\n",
        "#Handai\n",
        "ãƒ»GO_extended_dataset\n",
        "\n",
        "control: 1886æžšã€‚ãƒ†ã‚¹ãƒˆã«50æžšã‚’æ®‹ã™(test_handai)ã€æ®‹ã‚Šã®1836æžšã‚’train/valã«å›žã™\n",
        "\n",
        "treatable: 1879æžšã€‚ãƒ†ã‚¹ãƒˆã«50æžšã‚’æ®‹ã™(test_handai)ã€æ®‹ã‚Šã®1829æžšã‚’train/valã«å›žã™\n",
        "\n",
        "\n",
        "#åˆè¨ˆï¼š\n",
        "treatable: 1829 + 119\n",
        "\n",
        "control: 1836 + 511\n",
        "\n",
        "testset: Olympia treated 50, control 50, Handai treated 50, control 50\n",
        "\n",
        "##æ—¢å­˜ã®YOLOã§bounding boxã‚’ä½œæˆ --> classã¯æ—¢çŸ¥ã®ã‚‚ã®ã§ã€‚Glaucomaã®repositoryã‚’å‚è€ƒã«ã—ã¦YOLO datasetã‚’ä½œæˆã€‚"
      ],
      "metadata": {
        "id": "BW6BkO088P6u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ds7rvBFs8LcO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d06eeee-d4b2-4314-e4ef-4ae719a66539"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "import glob\n",
        "import random\n",
        "from PIL import Image\n",
        "import time\n",
        "%matplotlib inline\n",
        "\n",
        "#ã‚µãƒãƒ¼ãƒˆãƒ‘ãƒƒãƒã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "\n",
        "\n",
        "# Google Driveã‚’ãƒžã‚¦ãƒ³ãƒˆ\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ãƒ•ã‚¡ã‚¤ãƒ«æ•°ç¢ºèªç”¨\n",
        "import os\n",
        "\n",
        "def countfile(name, path):\n",
        "    print(f\"path: {path}\")\n",
        "    print(f\"number: {len(os.listdir(path))}\")\n",
        "    print(\"\")\n",
        "\n",
        "if not os.path.exists(\"/content/GO_extended_dataset\"):\n",
        "    !unzip /content/drive/MyDrive/Deep_learning/GO_extended_dataset/GO_extended_dataset.zip -d /content/\n",
        "\n",
        "\n",
        "olympia_cont_dir = \"/content/drive/MyDrive/Deep_learning/Olympia_dataset/control_640px\"\n",
        "olympia_grav_dir = \"/content/drive/MyDrive/Deep_learning/Olympia_dataset/treated_640px\"\n",
        "handai_cont_dir = \"/content/GO_extended_dataset/Control_photo_1886mai\"\n",
        "handai_grav_dir = \"/content/GO_extended_dataset/treatable\"\n",
        "\n",
        "\n",
        "countfile(\"control_640px_olympia\", olympia_cont_dir)\n",
        "countfile(\"treated_640px_olympia\", olympia_grav_dir)\n",
        "\n",
        "countfile(\"control_handai\", handai_cont_dir)\n",
        "countfile(\"treated_handai\", handai_grav_dir)\n"
      ],
      "metadata": {
        "id": "JFEWXrZrz_CY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Handai dataset, Olympia dataset --> super_extend_datase_for_YOLO**"
      ],
      "metadata": {
        "id": "6pYCYtrN79vn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dst_dir = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO\"\n",
        "\n",
        "if os.path.exists(dst_dir):\n",
        "    shutil.rmtree(dst_dir)\n",
        "os.makedirs(dst_dir)\n",
        "os.makedirs(f\"{dst_dir}/train_val\")\n",
        "os.makedirs(f\"{dst_dir}/train_val/grav\")\n",
        "os.makedirs(f\"{dst_dir}/train_val/cont\")\n",
        "os.makedirs(f\"{dst_dir}/test\")\n",
        "os.makedirs(f\"{dst_dir}/test/handai/grav\")\n",
        "os.makedirs(f\"{dst_dir}/test/handai/cont\")\n",
        "os.makedirs(f\"{dst_dir}/test/olympia/grav\")\n",
        "os.makedirs(f\"{dst_dir}/test/olympia/cont\")"
      ],
      "metadata": {
        "id": "FlAqRIZbCDRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "\n",
        "random_state = 1\n",
        "\n",
        "# Olympia Control images\n",
        "src_cont = olympia_cont_dir\n",
        "test_cont = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO/test/olympia/cont\"\n",
        "trainval_cont = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO/train_val/cont\"\n",
        "\n",
        "cont_images = os.listdir(src_cont)\n",
        "random.Random(random_state).shuffle(cont_images)\n",
        "\n",
        "test_cont_images = cont_images[:50]\n",
        "trainval_cont_images = cont_images[50:]\n",
        "\n",
        "for image in tqdm(test_cont_images, desc=\"Copying test cont images\"):\n",
        "    src_path = os.path.join(src_cont, image)\n",
        "    dst_path = os.path.join(test_cont, image)\n",
        "    shutil.copy(src_path, dst_path)\n",
        "\n",
        "for image in tqdm(trainval_cont_images, desc=\"Copying trainval cont images\"):\n",
        "    src_path = os.path.join(src_cont, image)\n",
        "    dst_path = os.path.join(trainval_cont, image)\n",
        "    shutil.copy(src_path, dst_path)\n",
        "\n",
        "\n",
        "# Olympia Grav images\n",
        "src_grav = olympia_grav_dir\n",
        "test_grav = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO/test/olympia/grav\"\n",
        "trainval_grav = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO/train_val/grav\"\n",
        "\n",
        "grav_images = os.listdir(src_grav)\n",
        "random.Random(random_state).shuffle(grav_images)\n",
        "\n",
        "test_grav_images = grav_images[:50]\n",
        "trainval_grav_images = grav_images[50:]\n",
        "\n",
        "for image in tqdm(test_grav_images, desc=\"Copying test grav images\"):\n",
        "    src_path = os.path.join(src_grav, image)\n",
        "    dst_path = os.path.join(test_grav, image)\n",
        "    shutil.copy(src_path, dst_path)\n",
        "\n",
        "for image in tqdm(trainval_grav_images, desc=\"Copying trainval grav images\"):\n",
        "    src_path = os.path.join(src_grav, image)\n",
        "    dst_path = os.path.join(trainval_grav, image)\n",
        "    shutil.copy(src_path, dst_path)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sta5Z-LLC01f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfb3c992-8961-4a5f-c6f9-98807749f318"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Copying test cont images: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:09<00:00,  5.51it/s]\n",
            "Copying trainval cont images: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 119/119 [00:03<00:00, 33.30it/s]\n",
            "Copying test grav images: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:28<00:00,  1.74it/s]\n",
            "Copying trainval grav images: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 511/511 [00:16<00:00, 30.59it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from shutil import copyfile\n",
        "from tqdm import tqdm\n",
        "\n",
        "grav_dir = olympia_grav_dir\n",
        "cont_dir = olympia_cont_dir\n",
        "test_grav_dir = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO/test/olympia/grav\"\n",
        "test_cont_dir = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO/test/olympia/cont\"\n",
        "train_val_grav_dir = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO/train_val/grav\"\n",
        "train_val_cont_dir = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO/train_val/cont\"\n",
        "\n",
        "# Check if files in grav_dir are in test_grav_dir\n",
        "for filename in tqdm(os.listdir(grav_dir)):\n",
        "    basename = os.path.basename(filename)\n",
        "    if os.path.exists(os.path.join(test_grav_dir, basename)):\n",
        "        print(\"coooool!!!\")\n",
        "        continue\n",
        "    else:\n",
        "        copyfile(os.path.join(grav_dir, filename), os.path.join(train_val_grav_dir, filename))\n",
        "\n",
        "# Check if files in cont_dir are in test_cont_dir\n",
        "for filename in tqdm(os.listdir(cont_dir)):\n",
        "    basename = os.path.basename(filename)\n",
        "    if os.path.exists(os.path.join(test_cont_dir, basename)):\n",
        "        print(\"hotttttt!!!\")\n",
        "        continue\n",
        "    else:\n",
        "        copyfile(os.path.join(cont_dir, filename), os.path.join(train_val_cont_dir, filename))\n"
      ],
      "metadata": {
        "id": "-Ll-LhlRKSQN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#####################\n",
        "# rename\n",
        "#æŒ‡å®šã•ã‚ŒãŸãƒ•ã‚©ãƒ«ãƒ€å†…ã«ã‚ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«åãŒ\"olympia_\"ã‹ã‚‰å§‹ã¾ã‚‰ãªã„å ´åˆã«ã€\"olympia_\"ã‚’å…ˆé ­ã«ã¤ã‘ãŸãƒ•ã‚¡ã‚¤ãƒ«åã«ãƒªãƒãƒ¼ãƒ ã™ã‚‹å‡¦ç†ã‚’è¡Œã†ã€‚\n",
        "#####################\n",
        "\n",
        "import os\n",
        "\n",
        "# ãƒ•ã‚©ãƒ«ãƒ€ã®ãƒ‘ã‚¹ã‚’æŒ‡å®š\n",
        "test_grav_dir = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO/test/olympia/grav\"\n",
        "test_cont_dir = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO/test/olympia/cont\"\n",
        "train_val_grav_dir = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO/train_val/grav\"\n",
        "train_val_cont_dir = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO/train_val/cont\"\n",
        "\n",
        "# ãƒ•ã‚¡ã‚¤ãƒ«åãŒ \"olympia_\" ã‹ã‚‰å§‹ã¾ã‚‰ãªã„å ´åˆã€\"olympia_\" ã‚’å…ˆé ­ã«ã¤ã‘ãŸãƒ•ã‚¡ã‚¤ãƒ«åã«ãƒªãƒãƒ¼ãƒ ã™ã‚‹\n",
        "def rename_file(path):\n",
        "    for filename in os.listdir(path):\n",
        "        if not filename.startswith(\"oly_\"):\n",
        "            new_filename = \"oly_\" + filename\n",
        "            os.rename(os.path.join(path, filename), os.path.join(path, new_filename))\n",
        "\n",
        "# ãƒªãƒãƒ¼ãƒ å‡¦ç†ã‚’å®Ÿè¡Œ\n",
        "rename_file(test_grav_dir)\n",
        "rename_file(test_cont_dir)\n",
        "rename_file(train_val_grav_dir)\n",
        "rename_file(train_val_cont_dir)\n"
      ],
      "metadata": {
        "id": "AleU8QFERy6K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(os.listdir(\"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO/train_val/grav\")))\n",
        "print(len(os.listdir(\"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO/train_val/cont\")))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQ3tV45TLy95",
        "outputId": "53c8f4e2-86c2-4c06-fc32-670649df511b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "511\n",
            "119\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "import os\n",
        "import random\n",
        "import shutil\n",
        "from tqdm import tqdm\n",
        "\n",
        "############################\n",
        "# Handai GO_extended_dataset\n",
        "#\n",
        "# /treatable â†’ /train_val/grav\n",
        "# /control â†’ /train_val/Control_photo_1886mai\n",
        "#\n",
        "############################\n",
        "\n",
        "if not os.path.exists(\"/content/GO_extended_dataset\"):\n",
        "    !unzip /content/drive/MyDrive/Deep_learning/GO_extended_dataset/GO_extended_dataset.zip -d /content/\n",
        "\n",
        "#file_name, class, idxã®ã‚Šã‚¹ãƒˆã‚’ä½œæˆ\n",
        "def get_file_info(src_dir, class_id):\n",
        "    file_list = os.listdir(src_dir)\n",
        "    ids_list = [int(file_name.split('.')[0].split('-')[0]) for file_name in file_list]\n",
        "    class_list = [class_id] * len(file_list)\n",
        "    return file_list, ids_list, class_list\n",
        "\n",
        "# Contãƒ•ã‚©ãƒ«ãƒ€ã®æƒ…å ±\n",
        "cont_dir = '/content/GO_extended_dataset/Control_photo_1886mai'\n",
        "file_list_cont, ids_list_cont, class_list_cont = get_file_info(cont_dir, 0)\n",
        "\n",
        "# Gravãƒ•ã‚©ãƒ«ãƒ€ã®æƒ…å ±\n",
        "grav_dir = '/content/GO_extended_dataset/treatable'\n",
        "file_list_grav, ids_list_grav, class_list_grav = get_file_info(grav_dir, 1)\n",
        "\n",
        "# çµåˆ\n",
        "file_list = file_list_cont + file_list_grav\n",
        "ids_list = ids_list_cont + ids_list_grav\n",
        "class_list = class_list_cont + class_list_grav\n",
        "\n",
        "print(file_list)\n",
        "print(ids_list)\n",
        "print(class_list)\n",
        "\n",
        "\n",
        "\n",
        "import random\n",
        "\n",
        "# file_listã«ç”»åƒã®ãƒ‘ã‚¹ãŒã€ids_listã«æ‚£è€…ã®idãŒã€class_listã«gravã‹contã‹(0 or 1)ãŒæ ¼ç´ã•ã‚Œã¦ã„ã‚‹ã¨ä»®å®šã™ã‚‹\n",
        "# ä¾‹: file_list = ['/path/to/image1.jpg', '/path/to/image2.jpg', ...]\n",
        "#     ids_list = ['patient1', 'patient1', 'patient2', 'patient3', ...]\n",
        "#     class_list = [0, 1, 0, 1, ...]\n",
        "\n",
        "# ãƒ©ãƒ³ãƒ€ãƒ ã‚·ãƒ¼ãƒ‰ã‚’å›ºå®šã™ã‚‹\n",
        "random.seed(1234)\n",
        "\n",
        "# idã”ã¨ã«ç”»åƒã®ãƒªã‚¹ãƒˆã‚’ã¾ã¨ã‚ã‚‹\n",
        "id_to_files = {}\n",
        "for i, id in enumerate(ids_list):\n",
        "    if id not in id_to_files:\n",
        "        id_to_files[id] = []\n",
        "    id_to_files[id].append((file_list[i], class_list[i]))\n",
        "\n",
        "# idã”ã¨ã«ç”»åƒã‚’testã‹trainã«æŒ¯ã‚Šåˆ†ã‘ã‚‹\n",
        "test_files = []\n",
        "train_files = []\n",
        "for id in id_to_files:\n",
        "    files = id_to_files[id]\n",
        "    random.shuffle(files)  # åŒã˜idå†…ã®ç”»åƒã®é †ç•ªã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«ä¸¦ã¹æ›¿ãˆã‚‹\n",
        "    for file, cls in files:\n",
        "        if len(test_files) < 50 and cls == 0:\n",
        "            test_files.append((file, cls))\n",
        "        else:\n",
        "            train_files.append((file, cls))\n",
        "\n",
        "# ç¢ºèª\n",
        "print(len(test_files), len(train_files))  # 50 ä»¥ä¸Šã®å ´åˆã¯å†å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚"
      ],
      "metadata": {
        "id": "DjeQtXC5F_7d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "import numpy as np\n",
        "from sklearn.model_selection import GroupShuffleSplit\n",
        "\n",
        "############################\n",
        "# Handai GO_extended_dataset\n",
        "#\n",
        "# /treatable â†’ /train_val/grav\n",
        "# /control â†’ /train_val/Control_photo_1886mai\n",
        "#\n",
        "############################\n",
        "\n",
        "if not os.path.exists(\"/content/GO_extended_dataset\"):\n",
        "    !unzip /content/drive/MyDrive/Deep_learning/GO_extended_dataset/GO_extended_dataset.zip -d /content/\n",
        "\n",
        "# Contãƒ•ã‚©ãƒ«ãƒ€ã®ãƒ‘ã‚¹\n",
        "src_dir = '/content/GO_extended_dataset/Control_photo_1886mai'\n",
        "train_val_dir = '/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO/train_val/cont'\n",
        "test_dir = '/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO/test/handai/cont'\n",
        "\n",
        "# ãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆã‚’å–å¾—ã—ã€IDã‚’æŠ½å‡ºã—ã¦ãƒªã‚¹ãƒˆã«æ ¼ç´\n",
        "file_list = os.listdir(src_dir)\n",
        "ids = [int(file_name.split('.')[0].split('-', 1)[0]) for file_name in file_list]\n",
        "\n",
        "# IDã”ã¨ã«ã‚°ãƒ«ãƒ¼ãƒ—ã‚’ä½œæˆã—ã¦ã€group-stratifiedã«åˆ†å‰²\n",
        "splitter = GroupShuffleSplit(n_splits=1, test_size=50, random_state=2)\n",
        "train_val_indices, test_indices = next(splitter.split(file_list, groups=ids))\n",
        "\n",
        "# å­¦ç¿’ç”¨ã¨ãƒ†ã‚¹ãƒˆç”¨ã®ãƒ•ã‚©ãƒ«ãƒ€ã«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚³ãƒ”ãƒ¼\n",
        "for i, file_name in tqdm(enumerate(file_list), total=len(file_list)):\n",
        "    src_path = os.path.join(src_dir, file_name)\n",
        "    dst_dir = test_dir if i in test_indices else train_val_dir\n",
        "    dst_path = os.path.join(dst_dir, file_name)\n",
        "    shutil.copy(src_path, dst_path)\n",
        "\n",
        "# Gravãƒ•ã‚©ãƒ«ãƒ€ã®ãƒ‘ã‚¹\n",
        "src_dir = '/content/GO_extended_dataset/treatable'\n",
        "train_val_dir = '/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO/train_val/grav'\n",
        "test_dir = '/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO/test/handai/grav'\n",
        "\n",
        "# ãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆã‚’å–å¾—ã—ã€IDã‚’æŠ½å‡ºã—ã¦ãƒªã‚¹ãƒˆã«æ ¼ç´\n",
        "file_list = os.listdir(src_dir)\n",
        "ids = [int(file_name.split('.')[0].split('-', 1)[0]) for file_name in file_list]\n",
        "\n",
        "# IDã”ã¨ã«ã‚°ãƒ«ãƒ¼ãƒ—ã‚’ä½œæˆã—ã¦ã€group-stratifiedã«åˆ†å‰²\n",
        "splitter = GroupShuffleSplit(n_splits=1, test_size=15, random_state=4)\n",
        "train_val_indices, test_indices = next(splitter.split(file_list, groups=ids))\n",
        "print(len(test_indices))\n",
        "\n",
        "# å­¦ç¿’ç”¨ã¨ãƒ†ã‚¹ãƒˆç”¨ã®ãƒ•ã‚©ãƒ«ãƒ€ã«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚³ãƒ”ãƒ¼\n",
        "for i, file_name in tqdm(enumerate(file_list), total=len(file_list)):\n",
        "    src_path = os.path.join(src_dir, file_name)\n",
        "    dst_dir = test_dir if i in test_indices else train_val_dir\n",
        "    dst_path = os.path.join(dst_dir, file_name)\n",
        "    shutil.copy(src_path, dst_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dy5IinNPpPgO",
        "outputId": "4644b4fb-b027-47e9-8e1f-f1434c2c3ea7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1886/1886 [00:44<00:00, 42.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1879/1879 [00:40<00:00, 46.03it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #ï¼ˆGroupShuffleSplitãŒgroupã”ã¨ã«åˆ†å‰²ã™ã‚‹ã®ã§ï¼‰ç·æ•°ãŒ50ã«ãªã‚‹ã‚ˆã†ã«random_stateã¨test_sizeã‚’èª¿ç¯€\n",
        "# # çµæžœã®æ ¼ç´ç”¨ãƒªã‚¹ãƒˆ\n",
        "# # Gravãƒ•ã‚©ãƒ«ãƒ€ã®ãƒ‘ã‚¹\n",
        "# src_dir = '/content/GO_extended_dataset/treatable'\n",
        "# train_val_dir = '/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO/train_val/grav'\n",
        "# test_dir = '/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO/test/handai/grav'\n",
        "\n",
        "# # ãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆã‚’å–å¾—ã—ã€IDã‚’æŠ½å‡ºã—ã¦ãƒªã‚¹ãƒˆã«æ ¼ç´\n",
        "# file_list = os.listdir(src_dir)\n",
        "# ids = [int(file_name.split('.')[0].split('-', 1)[0]) for file_name in file_list]\n",
        "\n",
        "# results = []\n",
        "\n",
        "# for random_state in range(10):\n",
        "#     for test_size in range(1, 51):\n",
        "#         splitter = GroupShuffleSplit(n_splits=1, test_size=test_size, random_state=random_state)\n",
        "#         train_val_indices, test_indices = next(splitter.split(file_list, groups=ids))\n",
        "#         test_set_size = len(test_indices)\n",
        "#         print(f\"random_state: {random_state}, test_size: {test_size}, test_set_size: {test_set_size}\")\n",
        "#         if test_set_size == 50:\n",
        "#             print(\"Coooool!!\")\n",
        "#             results.append((random_state, test_size))\n",
        "\n",
        "# # çµæžœã®è¡¨ç¤º\n",
        "# for result in results:\n",
        "#     print(f\"random_state: {result[0]}, test_size: {result[1]}\")\n"
      ],
      "metadata": {
        "id": "MMk9fpa9zkZ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**ãƒ•ã‚¡ã‚¤ãƒ«æ•°ã®ç¢ºèª**"
      ],
      "metadata": {
        "id": "jQkGRfUO9omP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dir = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO\"\n",
        "print(len(os.listdir(f\"{dir}/train_val/grav\")))\n",
        "print(len(os.listdir(f\"{dir}/train_val/cont\")))\n",
        "print(len(os.listdir(f\"{dir}/test/olympia/grav\")))\n",
        "print(len(os.listdir(f\"{dir}/test/olympia/cont\")))\n",
        "print(len(os.listdir(f\"{dir}/test/handai/grav\")))\n",
        "print(len(os.listdir(f\"{dir}/test/handai/cont\")))\n",
        "\n",
        "\"\"\"\n",
        "2340\n",
        "1933\n",
        "50\n",
        "50\n",
        "50\n",
        "50\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "aGGR7_-P96mS",
        "outputId": "a49aaf81-dbc7-4264-c516-f90ca626bcc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2340\n",
            "1955\n",
            "50\n",
            "50\n",
            "50\n",
            "50\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n2340\\n1933\\n50\\n50\\n50\\n50\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**æ—¢å­˜ã®YOLOv5ãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ã¦ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã‚’è¨­å®š**"
      ],
      "metadata": {
        "id": "R6FT8pBYNvF7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dst_dir = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO/train_val/labels\"\n",
        "if os.path.exists(dst_dir):\n",
        "    shutil.rmtree(dst_dir)\n",
        "os.makedirs(f\"{dst_dir}/grav\")\n",
        "os.makedirs(f\"{dst_dir}/cont\")"
      ],
      "metadata": {
        "id": "-wggPJzAOBYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup YOLOv5\n",
        "%cd /content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training\n",
        "!git clone https://github.com/ultralytics/yolov5\n",
        "%cd yolov5\n",
        "%pip install -qr requirements.txt\n",
        "\n",
        "import torch\n",
        "import utils\n",
        "display = utils.notebook_init()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1gF6whZ7P5ax",
        "outputId": "22f59ad2-8768-4d32-cf30-9a7634ac398f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv5 ðŸš€ v7.0-72-g064365d Python-3.10.11 torch-2.0.1+cu118 CPU\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete âœ… (2 CPUs, 12.7 GB RAM, 34.7/225.8 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from models.common import DetectMultiBackend\n",
        "#from utils.datasets import IMG_FORMATS, VID_FORMATS, LoadImages, LoadStreams\n",
        "from utils.general import (LOGGER, check_file, check_img_size, check_imshow, check_requirements, colorstr,\n",
        "                           increment_path, non_max_suppression, print_args, strip_optimizer, xyxy2xywh)\n",
        "#from utils.plots import Annotator, colors, save_one_box\n",
        "from utils.torch_utils import select_device, time_sync\n",
        "from utils.augmentations import letterbox #padding\n",
        "\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torchvision import models, transforms\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "#ã‚µãƒãƒ¼ãƒˆãƒ‘ãƒƒãƒã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "\n",
        "def interference(img, weight):\n",
        "    device = 'cpu'\n",
        "    device = select_device(device)\n",
        "    model = DetectMultiBackend(weight, device=device, dnn=False)\n",
        "    #stride, names, pt, jit, onnx, engine = model.stride, model.names, model.pt, model.jit, model.onnx, model.engine\n",
        "    #imgsz = check_img_size([640], s=stride)  # check image size\n",
        "\n",
        "    #class_names = {0:\"cont\", 1:\"grav\"}\n",
        "\n",
        "    # transform = transforms.Compose([\n",
        "    #             transforms.Resize(size=(480,640)),\n",
        "    #             transforms.ToTensor(),\n",
        "    #             # transforms.Normalize(\n",
        "    #             #     mean=[0.5, 0.5, 0.5],\n",
        "    #             #     std=[0.5, 0.5, 0.5]\n",
        "    #             #    )\n",
        "    #             ])\n",
        "\n",
        "    img_cv2 = cv2.imread(img) #CV2ã§é–‹ã\n",
        "    img_cv2 = letterbox(img_cv2, (640,640), stride=32, auto=False)[0] #resize, ä¸Šä¸‹padding (color 114)\n",
        "\n",
        "    #cv2_imshow(img_cv2)\n",
        "\n",
        "    img_cv2 = img_cv2.transpose((2, 0, 1))[::-1]  # HWC to CHW, BGR to RGB\n",
        "    img_cv2 = np.ascontiguousarray(img_cv2)\n",
        "    img_tensor = torch.from_numpy(img_cv2).float()\n",
        "\n",
        "    #img_tensor = transform(img_np)\n",
        "    img_tensor /= 255\n",
        "    #print(img_tensor.shape)\n",
        "\n",
        "    #print(img_tensor)\n",
        "    img_tensor = torch.unsqueeze(img_tensor, 0)  # ãƒãƒƒãƒå¯¾å¿œ\n",
        "\n",
        "\n",
        "    pred = model(img_tensor, visualize=False, augment=False)\n",
        "\n",
        "    pred = non_max_suppression(pred, conf_thres=0.25, iou_thres=0.45, classes=None,  max_det=1000)\n",
        "\n",
        "    print(f\"pred: {pred}\")\n",
        "\n",
        "    return pred"
      ],
      "metadata": {
        "id": "Yo05tVYVaD1N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def interference_thres(img, weight):\n",
        "    device = 'cpu'\n",
        "    device = select_device(device)\n",
        "    model = DetectMultiBackend(weight, device=device, dnn=False)\n",
        "    #stride, names, pt, jit, onnx, engine = model.stride, model.names, model.pt, model.jit, model.onnx, model.engine\n",
        "    #imgsz = check_img_size([640], s=stride)  # check image size\n",
        "\n",
        "    #class_names = {0:\"cont\", 1:\"grav\"}\n",
        "\n",
        "    # transform = transforms.Compose([\n",
        "    #             transforms.Resize(size=(480,640)),\n",
        "    #             transforms.ToTensor(),\n",
        "    #             # transforms.Normalize(\n",
        "    #             #     mean=[0.5, 0.5, 0.5],\n",
        "    #             #     std=[0.5, 0.5, 0.5]\n",
        "    #             #    )\n",
        "    #             ])\n",
        "\n",
        "    img_cv2 = cv2.imread(img) #CV2ã§é–‹ã\n",
        "    img_cv2 = letterbox(img_cv2, (640,640), stride=32, auto=False)[0] #resize, ä¸Šä¸‹padding (color 114)\n",
        "\n",
        "    #cv2_imshow(img_cv2)\n",
        "\n",
        "    img_cv2 = img_cv2.transpose((2, 0, 1))[::-1]  # HWC to CHW, BGR to RGB\n",
        "    img_cv2 = np.ascontiguousarray(img_cv2)\n",
        "    img_tensor = torch.from_numpy(img_cv2).float()\n",
        "\n",
        "    #img_tensor = transform(img_np)\n",
        "    img_tensor /= 255\n",
        "    #print(img_tensor.shape)\n",
        "\n",
        "    #print(img_tensor)\n",
        "    img_tensor = torch.unsqueeze(img_tensor, 0)  # ãƒãƒƒãƒå¯¾å¿œ\n",
        "\n",
        "\n",
        "    pred = model(img_tensor, visualize=False, augment=False)\n",
        "\n",
        "    pred = non_max_suppression(pred, conf_thres=0.15, iou_thres=0.25, classes=None,  max_det=1000)\n",
        "\n",
        "    #print(f\"pred: {pred}\")\n",
        "\n",
        "    return pred"
      ],
      "metadata": {
        "id": "P-HTdamj-mfN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "YOLOv5_model_path = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training/yolov5n_130epch.pt\"\n",
        "parent_dir = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO/train_val\"\n",
        "\n",
        "for class_name in [\"grav\", \"cont\"]:\n",
        "    if class_name == \"cont\":\n",
        "        class_num = 0\n",
        "    else:\n",
        "        class_num = 1\n",
        "    for image_path in glob.glob(f\"{parent_dir}/{class_name}/*\"):\n",
        "        name = os.path.splitext(os.path.basename(image_path))[0]\n",
        "        print(f\"image_name: {name}\")\n",
        "\n",
        "        #YOLOv5ã«ã‚ˆã‚Šãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã‚’æŠœãå‡ºã™\n",
        "        try:\n",
        "            pred = interference(image_path, YOLOv5_model_path)[0].tolist()[0]\n",
        "        except: #é€šå¸¸ã®é–¾å€¤è¨­å®šã§æ¤œå‡ºã•ã‚Œãªã„å ´åˆ\n",
        "            pred = interference_thres(image_path, YOLOv5_model_path)[0].tolist()[0]\n",
        "        pred = [max(num, 0) for num in pred] #0ã‚ˆã‚Šå°ã•ã„åº§æ¨™ã¯0ã«ä¿®æ­£ã™ã‚‹\n",
        "        pred = [min(num, 640) for num in pred] #640ã‚ˆã‚Šå°ã•ã„åº§æ¨™ã¯640ã«ä¿®æ­£ã™ã‚‹\n",
        "        xcenter = ((pred[0]+pred[2])/2)/640\n",
        "        ycenter = ((pred[1]+pred[3])/2)/640\n",
        "        xwidth = (pred[2]-pred[0])/640\n",
        "        ywidth = (pred[3]-pred[1])/640\n",
        "\n",
        "        # ãƒ•ã‚¡ã‚¤ãƒ«åã¨ä½œæˆã™ã‚‹å†…å®¹ã‚’æŒ‡å®š\n",
        "        txt_name = f\"{parent_dir}/labels/{class_name}/{name}.txt\"\n",
        "        content = f\"{class_num} {xcenter} {ycenter} {xwidth} {ywidth}\"\n",
        "        with open(txt_name, \"w\") as file:\n",
        "            # ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãè¾¼ã‚€\n",
        "            file.write(content)\n",
        "            print(f\"text file successfully createdðŸ™† {content}\")\n",
        "            print(\"\")\n",
        "            print(\"\")\n",
        ""
      ],
      "metadata": {
        "id": "wlGbrrAWRtHT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87cf0f1f-91d4-4809-ab3d-ebf2d4ff255d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fusing layers... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred: [tensor([[ 64.66748, 227.64108, 514.43115, 399.88657,   0.88143,   0.00000]])]\n",
            "text file successfully createdðŸ™† 0 0.4524208068847656 0.4902559757232666 0.7027557373046875 0.2691335678100586\n",
            "\n",
            "\n",
            "image_name: 9808-20191114-22-094457_e056ae61aa8b734ef2992b52c8fe38add031cae5e048f4d91553a02c64b6c645\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Model summary: 157 layers, 1761871 parameters, 0 gradients, 4.1 GFLOPs\n",
            "YOLOv5 ðŸš€ v7.0-72-g064365d Python-3.10.11 torch-2.0.1+cu118 CPU\n",
            "\n",
            "Fusing layers... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred: [tensor([[-5.88837e-01,  1.90427e+02,  6.37211e+02,  4.48986e+02,  8.17542e-01,  0.00000e+00]])]\n",
            "text file successfully createdðŸ™† 0 0.49782142639160154 0.4995415687561035 0.9956428527832031 0.40399904251098634\n",
            "\n",
            "\n",
            "image_name: 8027\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Model summary: 157 layers, 1761871 parameters, 0 gradients, 4.1 GFLOPs\n",
            "YOLOv5 ðŸš€ v7.0-72-g064365d Python-3.10.11 torch-2.0.1+cu118 CPU\n",
            "\n",
            "Fusing layers... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred: [tensor([[ 27.75302, 228.71809, 604.83643, 465.75330,   0.86981,   0.00000]])]\n",
            "text file successfully createdðŸ™† 0 0.4942105054855347 0.5425557732582093 0.9016928195953369 0.3703675031661987\n",
            "\n",
            "\n",
            "image_name: 1033\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Model summary: 157 layers, 1761871 parameters, 0 gradients, 4.1 GFLOPs\n",
            "YOLOv5 ðŸš€ v7.0-72-g064365d Python-3.10.11 torch-2.0.1+cu118 CPU\n",
            "\n",
            "Fusing layers... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred: [tensor([[  8.33530, 164.84067, 638.79395, 450.50369,   0.81064,   0.00000]])]\n",
            "text file successfully createdðŸ™† 0 0.5055697202682495 0.4807377815246582 0.9850916385650634 0.4463484764099121\n",
            "\n",
            "\n",
            "image_name: 4163\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Model summary: 157 layers, 1761871 parameters, 0 gradients, 4.1 GFLOPs\n",
            "YOLOv5 ðŸš€ v7.0-72-g064365d Python-3.10.11 torch-2.0.1+cu118 CPU\n",
            "\n",
            "Fusing layers... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred: [tensor([[ 12.76440, 178.12775, 633.55420, 446.41986,   0.86880,   0.00000]])]\n",
            "text file successfully createdðŸ™† 0 0.504936408996582 0.48792781829833987 0.9699840545654297 0.419206428527832\n",
            "\n",
            "\n",
            "image_name: 5513\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Model summary: 157 layers, 1761871 parameters, 0 gradients, 4.1 GFLOPs\n",
            "YOLOv5 ðŸš€ v7.0-72-g064365d Python-3.10.11 torch-2.0.1+cu118 CPU\n",
            "\n",
            "Fusing layers... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred: [tensor([[  5.46478, 185.79282, 633.87360, 426.82767,   0.85804,   0.00000]])]\n",
            "text file successfully createdðŸ™† 0 0.4994831085205078 0.4786097526550293 0.9818887710571289 0.3766169548034668\n",
            "\n",
            "\n",
            "image_name: 4183\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dir = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO/train_val\"\n",
        "print(len(os.listdir(f\"{dir}/grav\")))\n",
        "print(len(os.listdir(f\"{dir}/cont\")))\n",
        "print(len(os.listdir(f\"{dir}/labels/grav\")))\n",
        "print(len(os.listdir(f\"{dir}/labels/cont\")))\n",
        "\n",
        "\"\"\"\n",
        "2340\n",
        "1933\n",
        "2340\n",
        "1933\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "wzlaSDfE_Zk1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**YOLOv5ç”¨ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ç”¨ãƒ•ã‚©ãƒ«ãƒ€ä½œæˆ**\n",
        "\n",
        "https://github.com/ykitaguchi77/GravCont_classification_colab/blob/master/Extend_dataset_YOLOv5%EF%BC%A0.ipynb\n",
        "\n",
        "https://book.st-hakky.com/docs/object-detection-yolov5-tutorial/"
      ],
      "metadata": {
        "id": "9XI1oisiBK1O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "\n",
        "---------------super_extend_for_YOLO_training --------train------labels\n",
        "                                              |           |--images\n",
        "                                              |\n",
        "                                              |------valid ----labels\n",
        "                                              |           |--images\n",
        "                                              |\n",
        "                                              |--dataset.yaml\n",
        "                                              |--yolov5\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "nt3WfWu_Bb_p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dst_path = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_for_YOLO_training\"\n",
        "orig_path = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO/train_val\"\n"
      ],
      "metadata": {
        "id": "ZbyOJj3g_8Fj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if os.path.exists(dst_path):\n",
        "    shutil.rmtree(dst_path)\n",
        "os.makedirs(dst_path)\n",
        "os.makedirs(f\"{dst_path}/train/images\")\n",
        "os.makedirs(f\"{dst_path}/train/labels\")\n",
        "os.makedirs(f\"{dst_path}/valid/images\")\n",
        "os.makedirs(f\"{dst_path}/valid/labels\")"
      ],
      "metadata": {
        "id": "DtXJAAtsCjP3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd $dst_path"
      ],
      "metadata": {
        "id": "uVip7xMUEDgf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile dataset.yaml\n",
        "# path\n",
        "train: /content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_for_YOLO_training/train/images\n",
        "val: /content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_for_YOLO_training/valid/images\n",
        "\n",
        "# num of classes\n",
        "nc: 2\n",
        "\n",
        "#class names\n",
        "names: ['cont', 'grav'] # classåã‚’å®šç¾©"
      ],
      "metadata": {
        "id": "PMwlnFiqCpxI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create dataset_list\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import glob\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "dataset_dir =  \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_for_YOLO_training/train_val\"\n",
        "\n",
        "\n",
        "# def split_dataset(dataset_dir):\n",
        "#     img_list = glob.glob(f\"{dataset_dir}/images/*\")\n",
        "#     img_train, img_test = train_test_split(img_list, test_size=0.3, random_state=0)\n",
        "\n",
        "#     # img_train, img_testã«åå‰ãŒä¸€è‡´ã™ã‚‹txtãƒ•ã‚¡ã‚¤ãƒ«ã‚’æŠœãå‡ºã™\n",
        "#     label_train = [f\"{dataset_dir}/labels/{os.path.basename(i).split('.')[0]}.txt\" for i in img_train]\n",
        "#     label_test = [f\"{dataset_dir}/labels/{os.path.basename(i).split('.')[0]}.txt\" for i in img_test]\n",
        "\n",
        "#     print(f\"train: {len(label_train)},test: {len(label_test)}\")\n",
        "\n",
        "#     return img_train, img_test, label_train, label_test\n",
        "\n",
        "def make_path_list(dir, class_name):\n",
        "    image_list =  [file for file in glob.glob(f\"{dir}/{class_name}/*\") if os.path.isfile(file) == True ]\n",
        "    label_list =  [f\"{dir}/{class_name}/labels/{os.path.basename(i).split('.')[0]}.txt\" for i in image_list]\n",
        "\n",
        "    id_list = [os.path.basename(i).split(\"-\")[0].split(\".\")[0] for i in image_list]\n",
        "\n",
        "    index = {}\n",
        "    id_idx = []\n",
        "    for item in id_list:\n",
        "        if item in index:\n",
        "            id_idx.append(index[item])\n",
        "        else:\n",
        "            index[item] = len(index) + 1\n",
        "            id_idx.append(index[item])\n",
        "    id_idx = [int(i) for i in id_idx]\n",
        "\n",
        "    print(f\"image_list: {image_list}\")\n",
        "    print(f\"label_list: {label_list}\")\n",
        "\n",
        "    return image_list, label_list, id_idx\n",
        "\n",
        "grav_image_list, grav_label_list, grav_id_idx = make_path_list(orig_path, \"grav\")\n",
        "cont_image_list, cont_label_list, cont_id_idx = make_path_list(orig_path, \"cont\")\n",
        "\n",
        "print(\"image\")\n",
        "print(f\"grav: {len(grav_image_list)}\")\n",
        "print(f\"cont: {len(cont_image_list)}\")\n",
        "print(\"label\")\n",
        "print(f\"grav: {len(grav_label_list)}\")\n",
        "print(f\"cont: {len(cont_label_list)}\")"
      ],
      "metadata": {
        "id": "Lb7vg1IfHSCT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split dataset using GroupShuffleSplit\n",
        "\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import shutil\n",
        "import numpy as np\n",
        "from sklearn.model_selection import GroupShuffleSplit\n",
        "\n",
        "############################\n",
        "# ä»¥ä¸‹ã‚’GroupShuffleSplitã§åˆ†ã‘ã‚‹\n",
        "# super_extend_dataset_for_YOLO/train_val/grav\n",
        "# â†’ /super_extend_for_YOLO_training/train/images\n",
        "# â†’ /super_extend_for_YOLO_training/vallid/images\n",
        "#\n",
        "# super_extend_dataset_for_YOLO/train_val/cont\n",
        "# â†’ /super_extend_for_YOLO_training/train/images\n",
        "# â†’ /super_extend_for_YOLO_training/vallid/images\n",
        "#\n",
        "# ä»¥ä¸‹ã¯basenameãŒåŒã˜ã‚‚ã®ã‚’ç§»å‹•ã™ã‚‹ã®ã¿ã¨ã™ã‚‹\n",
        "# super_extend_dataset_for_YOLO/train_val/label/grav\n",
        "# â†’ /super_extend_for_YOLO_training/train/labels\n",
        "# â†’ /super_extend_for_YOLO_training/vallid/labels\n",
        "#\n",
        "# super_extend_dataset_for_YOLO/train_val/label/grav\n",
        "# â†’ /super_extend_for_YOLO_training/train/labels\n",
        "# â†’ /super_extend_for_YOLO_training/vallid/labels\n",
        "############################\n",
        "\n",
        "dst_folder = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_for_YOLO_training\"\n",
        "orig_folder = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_dataset_for_YOLO/train_val\"\n",
        "\n",
        "for class_name in [\"cont\", \"grav\"]:\n",
        "    # ãƒ•ã‚©ãƒ«ãƒ€ã®ãƒ‘ã‚¹\n",
        "    src_dir = f\"{orig_folder}/{class_name}\"\n",
        "    train_dir = f\"{dst_folder}/train/images\"\n",
        "    valid_dir = f\"{dst_folder}/valid/images\"\n",
        "\n",
        "    # ãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆã‚’å–å¾—ã—ã€IDã‚’æŠ½å‡ºã—ã¦ãƒªã‚¹ãƒˆã«æ ¼ç´\n",
        "    file_list = os.listdir(src_dir)\n",
        "    ids = [str(file_name.split('.')[0].split('-', 1)[0]) for file_name in file_list]\n",
        "\n",
        "    # IDã”ã¨ã«ã‚°ãƒ«ãƒ¼ãƒ—ã‚’ä½œæˆã—ã¦ã€group-stratifiedã«åˆ†å‰²\n",
        "    splitter = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=2)\n",
        "    train_indices, valid_indices = next(splitter.split(file_list, groups=ids))\n",
        "\n",
        "    # å­¦ç¿’ç”¨ã¨ãƒ†ã‚¹ãƒˆç”¨ã®ãƒ•ã‚©ãƒ«ãƒ€ã«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚³ãƒ”ãƒ¼\n",
        "    for i, file_name in tqdm(enumerate(file_list), total=len(file_list)):\n",
        "        src_path = os.path.join(src_dir, file_name)\n",
        "        dst_dir = valid_dir if i in valid_indices else train_dir\n",
        "        dst_path = os.path.join(dst_dir, file_name)\n",
        "        shutil.copy(src_path, dst_path)\n",
        "\n",
        "        label_file_name = file_name.rsplit(\".\", 1)[0] + \".txt\" #åŒã˜åå‰ã®ãƒ©ãƒ™ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚‚ç§»å‹•\n",
        "        #print(f\"label_file_name: {label_file_name}\")\n",
        "        label_dst_dir = os.path.dirname(dst_path).replace(\"images\", \"labels\")\n",
        "        #print(f\"label_dst_dir: {label_dst_dir}\")\n",
        "\n",
        "        label_src_path = os.path.join(orig_folder, \"labels\", class_name, label_file_name)\n",
        "        label_dst_path = os.path.join(label_dst_dir, label_file_name)\n",
        "        shutil.copy(label_src_path, label_dst_path)"
      ],
      "metadata": {
        "id": "f8hUG0YRLnUq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"train_images: {len(os.listdir('/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_for_YOLO_training/train/images'))}\")\n",
        "print(f\"val_images: {len(os.listdir('/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_for_YOLO_training/valid/images'))}\")\n",
        "print(f\"train_labels: {len(os.listdir('/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_for_YOLO_training/train/labels'))}\")\n",
        "print(f\"val_labels: {len(os.listdir('/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_for_YOLO_training/valid/labels'))}\")\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "train_images: 3480\n",
        "val_images: 792\n",
        "train_labels: 3480\n",
        "val_labels: 792\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "S33XiPEhieCc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dst_dir"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "nkm96dMkicsq",
        "outputId": "086dfd59-20d6-445d-e199-58032f15059c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/Deep_learning/GO_extended_dataset/super_extend_for_YOLO_training/train/images'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZMpdg5EhfVfq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
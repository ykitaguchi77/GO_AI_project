{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNXaE93Sd3qsT/kbptJ/KrZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykitaguchi77/GO_AI_project/blob/main/iFish_YOLOv5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**iFish**\n",
        "\n",
        "https://github.com/Gil-Mor/iFish"
      ],
      "metadata": {
        "id": "qqGs8pruoTpg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-bOK6jei_jEU",
        "outputId": "f7c7716c-8256-49f4-a5da-16ec74be497c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "YOLOv5_model_path = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training/yolov5n_130epch.pt\"\n",
        "\n",
        "# Setup YOLOv5\n",
        "%cd /content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training\n",
        "!git clone https://github.com/ultralytics/yolov5\n",
        "%cd yolov5\n",
        "%pip install -qr requirements.txt\n",
        "\n",
        "import torch\n",
        "import utils\n",
        "display = utils.notebook_init()\n",
        "\n",
        "from models.common import DetectMultiBackend\n",
        "#from utils.datasets import IMG_FORMATS, VID_FORMATS, LoadImages, LoadStreams\n",
        "from utils.general import (LOGGER, check_file, check_img_size, check_imshow, check_requirements, colorstr,\n",
        "                           increment_path, non_max_suppression, print_args, strip_optimizer, xyxy2xywh)\n",
        "#from utils.plots import Annotator, colors, save_one_box\n",
        "from utils.torch_utils import select_device, time_sync\n",
        "from utils.augmentations import letterbox #padding\n",
        "\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torchvision import models, transforms\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "#„Çµ„Éù„Éº„Éà„Éë„ÉÉ„ÉÅ„ÅÆ„Ç§„É≥„Éù„Éº„Éà\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "\n",
        "def interference(img_cv2, weight):\n",
        "    device = 'cpu'\n",
        "    device = select_device(device)\n",
        "    model = DetectMultiBackend(weight, device=device, dnn=False)\n",
        "    #stride, names, pt, jit, onnx, engine = model.stride, model.names, model.pt, model.jit, model.onnx, model.engine\n",
        "    #_cv2sz = check_img_size([640], s=stride)  # check image size\n",
        "\n",
        "    #class_names = {0:\"cont\", 1:\"grav\"}\n",
        "\n",
        "    # transform = transforms.Compose([\n",
        "    #             transforms.Resize(size=(480,640)),\n",
        "    #             transforms.ToTensor(),\n",
        "    #             # transforms.Normalize(\n",
        "    #             #     mean=[0.5, 0.5, 0.5],\n",
        "    #             #     std=[0.5, 0.5, 0.5]\n",
        "    #             #    )\n",
        "    #             ])\n",
        "\n",
        "    img_cv2 = letterbox(img_cv2, (640,640), stride=32, auto=False)[0] #resize, ‰∏ä‰∏ãpadding (color 114)\n",
        "\n",
        "    #cv2_imshow(img_cv2)\n",
        "\n",
        "    img_cv2 = img_cv2.transpose((2, 0, 1))[::-1]  # HWC to CHW, BGR to RGB\n",
        "    img_cv2 = np.ascontiguousarray(img_cv2)\n",
        "    img_tensor = torch.from_numpy(img_cv2).float()\n",
        "\n",
        "    #img_tensor = transform(img_np)\n",
        "    img_tensor /= 255\n",
        "    #print(img_tensor.shape)\n",
        "\n",
        "    #print(img_tensor)\n",
        "    img_tensor = torch.unsqueeze(img_tensor, 0)  # „Éê„ÉÉ„ÉÅÂØæÂøú\n",
        "\n",
        "\n",
        "    pred = model(img_tensor, visualize=False, augment=False)\n",
        "\n",
        "    pred = non_max_suppression(pred, conf_thres=0.25, iou_thres=0.45, classes=None,  max_det=1000)\n",
        "\n",
        "    print(f\"pred: {pred}\")\n",
        "\n",
        "    return pred\n",
        "\n",
        "\n",
        "def show_results(img_cv2):\n",
        "    class_names = {0:\"cont\", 1:\"grav\"}\n",
        "    pred = interference(img_cv2, YOLOv5_model_path)\n",
        "\n",
        "    # output result\n",
        "    x1, y1, x2, y2, prob, class_num = torch.round(pred[0][0])\n",
        "\n",
        "    # probability\n",
        "    prob = pred[0][0][4].item()\n",
        "\n",
        "\n",
        "    # class\n",
        "    class_name = class_names[pred[0][0][5].item()]\n",
        "\n",
        "    print(\"Ë®∫Êñ≠„ÅØ %s„ÄÅÁ¢∫Áéá„ÅØ%.1fÔºÖ„Åß„Åô„ÄÇ\" %(class_name, prob*100))\n",
        "\n",
        "    # Ê®™ÂπÖ„Åå640px„Å´„Å™„Çã„Çà„ÅÜ„Å´„É™„Çµ„Ç§„Ç∫\n",
        "    height, width, _ = img_cv2.shape\n",
        "    resize_width = 640\n",
        "    resize_height = int((height / width) * resize_width)\n",
        "    resize_size = (resize_width, resize_height)\n",
        "    img_cv2 = cv2.resize(img_cv2, resize_size)\n",
        "\n",
        "    # calculate coordinates of the bounding box (640*640„Å´padding„Åï„Çå„Å¶„ÅÑ„ÇãÂàÜ„ÅÆÂ∫ßÊ®ô„ÇíË∂≥„Åô)\n",
        "    img_height, img_width, _ = img_cv2.shape[:3]\n",
        "    print(f\"img_height: {img_height}, img_width: {img_width}\")\n",
        "    padding_x = (img_height - min(img_width, img_height))/2\n",
        "    padding_y = (img_width - min(img_width, img_height))/2\n",
        "    x1 = x1 - padding_x\n",
        "    y1 = y1 - padding_y\n",
        "    x2 = x2 - padding_x\n",
        "    y2 = y2 - padding_y\n",
        "    print(f\"x1: {x1}, y1: {y1}, x2: {x2}, y2: {y2}\")\n",
        "\n",
        "\n",
        "    # draw bounding box\n",
        "    cv2.rectangle(img_cv2, (int(x1), int(y1)), (int(x2), int(y2)), (255, 0, 0), 2)\n",
        "\n",
        "    # show image\n",
        "    cv2_imshow(img_cv2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVATsjDDpd2k",
        "outputId": "e891ec48-5e4e-4470-dbed-2ce396ba4285"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv5 üöÄ v7.0-72-g064365d Python-3.10.6 torch-2.0.1+cu118 CPU\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete ‚úÖ (2 CPUs, 12.7 GB RAM, 24.4/225.8 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "\n",
        "# Specify the image path\n",
        "#image_path = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training/train/images/1010.JPG\"\n",
        "#image_path = \"/content/drive/MyDrive/Deep_learning/FishEye/sample_img.JPG\"\n",
        "image_path = \"/content/drive/MyDrive/Deep_learning/Olympia_dataset/dataset_500px/101.JPG\"\n",
        "\n",
        "# Read the image\n",
        "img = mpimg.imread(image_path)\n",
        "\n",
        "# „Åì„Çå„Çí„Ç∞„É©„ÉïÊèèÁîªÂâç„Å´„ÇÑ„Å£„Å¶„ÄÅ„É™„Çª„ÉÉ„Éà„Åô„Çã\n",
        "plt.clf()\n",
        "\n",
        "# Create a figure\n",
        "plt.figure()\n",
        "\n",
        "# Display the image along with axis\n",
        "imgplot = plt.imshow(img)\n",
        "\n",
        "# Show the colorbar\n",
        "plt.colorbar()\n",
        "\n",
        "# Show the grid\n",
        "plt.grid(True)\n",
        "\n",
        "# Show the image\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "GIaJz0oinA8e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Required Libraries\n",
        "import imageio\n",
        "import numpy as np\n",
        "from math import sqrt\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Specify your image path\n",
        "#image_path = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training/train/images/1010.JPG\"\n",
        "#image_path = \"/content/drive/MyDrive/Deep_learning/FishEye/sample_img.JPG\"\n",
        "image_path = \"/content/drive/MyDrive/Deep_learning/Olympia_dataset/dataset_500px/101.JPG\"\n",
        "\n",
        "\n",
        "# Fish Eye Filter Function\n",
        "def get_fish_xn_yn(source_x, source_y, radius, distortion):\n",
        "    if 1 - distortion*(radius**2) == 0:\n",
        "        return source_x, source_y\n",
        "    return source_x / (1 - (distortion*(radius**2))), source_y / (1 - (distortion*(radius**2)))\n",
        "\n",
        "def apply_fish_eye_filter(image_path, distortion_coefficient=0.5):\n",
        "    img = imageio.imread(image_path)\n",
        "    img = img[100:400, :]  # Crop the image as per the requirement\n",
        "    w, h = img.shape[0], img.shape[1]\n",
        "    if len(img.shape) == 2:\n",
        "        bw_channel = np.copy(img)\n",
        "        img = np.dstack((img, bw_channel))\n",
        "        img = np.dstack((img, bw_channel))\n",
        "    if len(img.shape) == 3 and img.shape[2] == 3:\n",
        "        img = np.dstack((img, np.full((w, h), 255)))\n",
        "    dstimg = np.zeros_like(img)\n",
        "    w, h = float(w), float(h)\n",
        "    for x in range(len(dstimg)):\n",
        "        for y in range(len(dstimg[x])):\n",
        "            xnd, ynd = float((2*x - w)/w), float((2*y - h)/h)\n",
        "            rd = sqrt(xnd**2 + ynd**2)\n",
        "            xdu, ydu = get_fish_xn_yn(xnd, ynd, rd, distortion_coefficient)\n",
        "            xu, yu = int(((xdu + 1)*w)/2), int(((ydu + 1)*h)/2)\n",
        "            if 0 <= xu and xu < img.shape[0] and 0 <= yu and yu < img.shape[1]:\n",
        "                dstimg[x][y] = img[xu][yu]\n",
        "    return dstimg.astype(np.uint8)\n",
        "\n",
        "# Define Distortion Coefficients Range\n",
        "distortion_coefficients = np.arange(-0.5, 0.6, 0.1)\n",
        "\n",
        "# # Create Subplots\n",
        "# fig, axs = plt.subplots(len(distortion_coefficients), figsize=(6, 6 * len(distortion_coefficients)))\n",
        "\n",
        "# # Apply Fish Eye Filter for each Distortion Coefficient\n",
        "# for ax, distortion_coefficient in zip(axs, distortion_coefficients):\n",
        "#     output_img = apply_fish_eye_filter(image_path, distortion_coefficient)\n",
        "#     ax.imshow(output_img)\n",
        "#     ax.set_title(f'Fish-eye Filter with Distortion Coefficient = {distortion_coefficient}')\n",
        "#     ax.axis('off')\n",
        "\n",
        "# plt.tight_layout()\n",
        "# plt.show()\n",
        "\n",
        "# „Åì„Çå„Çí„Ç∞„É©„ÉïÊèèÁîªÂâç„Å´„ÇÑ„Å£„Å¶„ÄÅ„É™„Çª„ÉÉ„Éà„Åô„Çã\n",
        "plt.clf()\n",
        "\n",
        "# Create subplots\n",
        "fig, axs = plt.subplots(len(distortion_coefficients), 2, figsize=(12, 6 * len(distortion_coefficients)))\n",
        "\n",
        "# Apply Fish Eye Filter for each Distortion Coefficient\n",
        "for i, distortion_coefficient in enumerate(distortion_coefficients):\n",
        "    output_img = apply_fish_eye_filter(image_path, distortion_coefficient)\n",
        "    axs[i, 0].imshow(output_img)\n",
        "    axs[i, 0].set_title(f'Fish-eye Filter with Distortion Coefficient = {distortion_coefficient}')\n",
        "    axs[i, 0].axis('off')\n",
        "\n",
        "    # Convert image to opencv format\n",
        "    output_img_cv = cv2.cvtColor(output_img, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "    # Perform inference on the distorted image\n",
        "    show_results(output_img_cv)\n",
        "\n",
        "    # Display the image with bounding box\n",
        "    output_img_bb = cv2.cvtColor(output_img_cv, cv2.COLOR_BGR2RGB)\n",
        "    axs[i, 1].imshow(output_img_bb)\n",
        "    axs[i, 1].set_title(f'Interference Result')\n",
        "    axs[i, 1].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "y2pquOuuBHn3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
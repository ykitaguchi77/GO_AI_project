{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPA311CF3y4uElZL8EKgG+d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykitaguchi77/GO_AI_project/blob/main/YOLOv8_to_EfficientNetV2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**YOLOv8 to EfficientNetv2 pipeline**"
      ],
      "metadata": {
        "id": "w2bPHz9wew6n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Olympia datasetから目を切り抜く（YOLOv8n）**\n",
        "#**切り抜いた目をEfficientNetV2で解析する**"
      ],
      "metadata": {
        "id": "LXWb3YtIFX1p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Olympia dataset\n",
        "Dlibで目が2つ検出されるものを抜き出す\n",
        "YOLOv8を用いて左右とバウンディングボックスを認識させる\n",
        "切り抜いたバウンディングボックス内の画像について、EfficientNetv2を用いて眼球突出度、MRD-1、MRD-2を回帰させる\n",
        "スマホに実装\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "UnyBedKNbfS3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7MdRVDhFJmO",
        "outputId": "d2a9a3fa-4128-4ea8-88e0-b24f9508c31d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import shutil\n",
        "import copy\n",
        "import pandas as pd\n",
        "import csv\n",
        "from tqdm import tqdm\n",
        "\n",
        "import glob\n",
        "import random\n",
        "from PIL import Image\n",
        "%matplotlib inline\n",
        "\n",
        "#サポートパッチのインポート\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "\n",
        "plt.ion()   # interactive mode\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#親フォルダ\n",
        "parent_dir = '/content/drive/MyDrive/Deep_learning/Olympia_dataset/dataset_uni_for_YOLOv8'\n",
        "\n",
        "#元画像フォルダ\n",
        "dataset_dir = '/content/drive/MyDrive/Deep_learning/Olympia_dataset/dataset'\n",
        "\n",
        "#元画像をコピー\n",
        "orig_dir = f\"{parent_dir}/dataset_orig\"\n",
        "\n",
        "#切りぬいた画像を保存するフォルダ\n",
        "out_dir = f\"{parent_dir}/dataset_uni\"\n",
        "\n",
        "#CSVファイルのフォルダ\n",
        "csv_path = f\"{parent_dir}/dataset_uni_for_YOLO8.csv\""
      ],
      "metadata": {
        "id": "_DI1wc0eF5uR"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "###################################\n",
        "# Reflesh folder (内容が削除されるので注意！！) #\n",
        "###################################\n",
        "\"\"\"\n",
        "\n",
        "# parent_dirがあれば削除する\n",
        "if os.path.exists(parent_dir):\n",
        "    shutil.rmtree(parent_dir)\n",
        "\n",
        "# 新しくparent_dirを作成する\n",
        "os.makedirs(parent_dir)\n",
        "\n",
        "# orig_dir, out_dirを新規に作成する\n",
        "os.makedirs(orig_dir)\n",
        "os.makedirs(out_dir)\n",
        "\n",
        "# orig_dirにdataset_dir直下のファイルをすべてコピーする\n",
        "file_list = os.listdir(dataset_dir)\n",
        "for filename in tqdm(file_list, desc=\"Copying files\", unit=\"file\"):\n",
        "    src_path = os.path.join(dataset_dir, filename)\n",
        "    dst_path = os.path.join(orig_dir, filename)\n",
        "    shutil.copy(src_path, dst_path)\n",
        "\n",
        "print(\"処理が完了しました。\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2ZGZkPOK84g",
        "outputId": "07fec511-58ed-4324-c341-c03cf2ccd77f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Copying files: 100%|██████████| 1016/1016 [00:48<00:00, 20.92file/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "処理が完了しました。\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**HaarCascadeを用いて目を検出**"
      ],
      "metadata": {
        "id": "6Y6OC0UoMOZv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# カスケードファイルのパス\n",
        "eye_cascade_path = '/content/drive/My Drive/Deep_learning/haarcascade_eye.xml'\n",
        "\n",
        "# カスケード分類器の特徴量取得\n",
        "eye_cascade = cv2.CascadeClassifier(eye_cascade_path)\n"
      ],
      "metadata": {
        "id": "f2rM0ZbTMN50"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**目が2つ以上検出されたものを抜き出す**"
      ],
      "metadata": {
        "id": "FWLibTiZc1Xw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(csv_path, 'w', newline='') as f:\n",
        "        #fieldnames = ['Number', 'Folder', 'FileName']\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow(['id','img_path', 'side R/L', 'ex', 'ey', 'ew', 'eh'])  #header\n",
        "\n",
        "        files = os.listdir(orig_dir)\n",
        "\n",
        "        k=0\n",
        "        for file in files:  #フォルダ数の分だけ\n",
        "              file_path = f\"{orig_dir}/{file}\"\n",
        "              id = os.path.splitext(os.path.basename(file_path))[0]\n",
        "\n",
        "              img = cv2.imread(file_path)\n",
        "              img2 = img.copy()\n",
        "\n",
        "              # 画像グレースケール化\n",
        "              grayscale_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "              #300pix以上のもので目に見えるものを抽出\n",
        "              eye_list = eye_cascade.detectMultiScale(grayscale_img, minSize=(300, 300))\n",
        "\n",
        "              # 眼検出判定\n",
        "              if len(eye_list) >= 1:\n",
        "                  print('目が' + str(len(eye_list)) +'個検出されました')\n",
        "              else:\n",
        "                  print(\"eye detection error\")\n",
        "\n",
        "              #画像の切り抜きと保存（2個以上検出の時に限る）\n",
        "              if len(eye_list) >= 2:\n",
        "                  for (ex, ey, ew, eh) in eye_list:\n",
        "                      print(f\"img_width: {img2.shape[1]}\")\n",
        "                      print(\"[ex,ey] = %d,%d [ew,eh] = %d,%d\" %(ex, ey, ew, eh))\n",
        "                      cv2.rectangle(img2, (ex, ey), (ex + ew, ey + eh), (0, 255, 0), 2)\n",
        "                      #img_cropped = img[int(ey-0.1*eh): int(ey+1.1*eh), int(ex-0.1*ew): int(ex+1.1*ew)] #本来の切り抜きより幅の0.1倍ずつ水増しする\n",
        "                      img_cropped = img[int(ey): int(ey+eh), int(ex): int(ex+ew)]\n",
        "\n",
        "\n",
        "                      if ex+eh*0.5 <= img2.shape[1]/2:\n",
        "                          side = \"R\" #横幅の半分より左にあるのは右眼\n",
        "                      else:\n",
        "                          side = \"L\" #横幅の半分よりより右にあるのは左眼\n",
        "\n",
        "                      print(f\"side: {side}\")\n",
        "                      print(\"\")\n",
        "\n",
        "                      cv2.imwrite(f\"{out_dir}/{id}_{side}.png\", img_cropped)\n",
        "\n",
        "                      #対応表の作成\n",
        "                      writer.writerow([id, file_path, side, ex+round(ew/2), ey+round(eh/2), ew, eh])\n",
        "                  else:\n",
        "                      pass\n"
      ],
      "metadata": {
        "id": "pnVFMJJVMW8n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**ここで、目以外が誤検出されているものを手動で抜き出して削除する**"
      ],
      "metadata": {
        "id": "tm4HsJszc9VX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "不適切な画像があれば、左右まとめて消す\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "v3abWZGGe9sA",
        "outputId": "b7c5d277-9dcd-4101-c5e2-6fb1d298bd86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n不適切な画像があれば、左右まとめて消す\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#CSVのリストと画像フォルダを見比べて、消した画像を判別。CSVを修正する。\n",
        "import pandas as pd\n",
        "\n",
        "# Load the CSV\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# Get a list of unique ids\n",
        "csv_id_list = df['id'].unique().tolist()\n",
        "\n",
        "print(f\"csv_id_list: {csv_id_list}\")\n",
        "\n",
        "\n",
        "# Construct the output directory path\n",
        "out_dir = f\"{parent_dir}/dataset_uni\"\n",
        "\n",
        "# Get a list of all image file names in the directory\n",
        "image_file_names = os.listdir(out_dir)\n",
        "\n",
        "# Split each file name at \"_\" and take the first part, then make sure the list is unique\n",
        "image_id_list = list(set([int(name.split('_')[0]) for name in image_file_names]))\n",
        "print(f\"image_id_list: {image_id_list}\")\n",
        "\n",
        "# Find the ids that are in the CSV list but not in the image file list\n",
        "missing_ids = [id for id in csv_id_list if id not in image_id_list]\n",
        "print(f\"missing_ids: {missing_ids}\")\n",
        "\n",
        "\n",
        "\n",
        "# Remove the rows with ids in missing_ids\n",
        "df = df[~df['id'].isin(missing_ids)]\n",
        "\n",
        "# Save the dataframe back to a CSV\n",
        "df.to_csv(f\"{parent_dir}/dataset_uni_for_YOLO8_modified.csv\", index=False)"
      ],
      "metadata": {
        "id": "aGVqU2n9i3wR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "①\"/content/drive/MyDrive/Deep_learning/Olympia_dataset/dataset_uni_for_YOLOv8/dataset_orig\"のファイル名（1.jpgとすると1）と、②\"/content/drive/MyDrive/Deep_learning/Olympia_dataset/dataset_uni_for_YOLOv8/dataset_uni\"のアンダーバーの手前（1_R.jpgとすると1)を見比べる\n",
        "\n",
        "\"/content/drive/MyDrive/Deep_learning/Olympia_dataset/dataset_uni_for_YOLOv8/dataset_dlib_detected\"というフォルダを作成\n",
        "①と②で一致するもの(2つ目が検出されたもの)に関して、①の画像（コピー）を一辺512pixの黒塗りletterboxにして変換し、新しく作成したフォルダに保存する\n",
        "...ではなくletterboxは使わずそのままコピーすることとした\n",
        "\"\"\"\n",
        "\n",
        "import shutil\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "# def letterbox_image(image, size):\n",
        "#     \"\"\"\n",
        "#     画像を指定したサイズの黒塗りletterboxに変換する関数\n",
        "#     :param image: 変換する画像（PIL Image）\n",
        "#     :param size: 変換後のサイズ（幅, 高さ）のタプル\n",
        "#     :return: 変換後の画像（PIL Image）\n",
        "#     \"\"\"\n",
        "#     new_width, new_height = size\n",
        "#     old_width, old_height = image.size\n",
        "#     ratio = min(new_width / old_width, new_height / old_height)\n",
        "#     new_width = int(old_width * ratio)\n",
        "#     new_height = int(old_height * ratio)\n",
        "#     resized_image = image.resize((new_width, new_height), Image.LANCZOS)\n",
        "#     boxed_image = Image.new(\"RGB\", size, (0, 0, 0))\n",
        "#     boxed_image.paste(resized_image, ((size[0] - new_width) // 2, (size[1] - new_height) // 2))\n",
        "#     return boxed_image\n",
        "\n",
        "def main():\n",
        "    # 保存先フォルダのパス\n",
        "    output_folder = \"/content/drive/MyDrive/Deep_learning/Olympia_dataset/dataset_uni_for_YOLOv8/dataset_dlib_detected\"\n",
        "\n",
        "    # フォルダが存在しない場合は作成\n",
        "    if os.path.exists(output_folder):\n",
        "        shutil.rmtree(output_folder)\n",
        "    os.makedirs(output_folder)\n",
        "\n",
        "    # ①のフォルダ内のファイル名を取得して、1.jpgのような形式に変換\n",
        "    orig_folder = \"/content/drive/MyDrive/Deep_learning/Olympia_dataset/dataset_uni_for_YOLOv8/dataset_orig\"\n",
        "    orig_files = os.listdir(orig_folder)\n",
        "    orig_filenames = [os.path.splitext(filename)[0] for filename in orig_files]\n",
        "\n",
        "    # ②のフォルダ内のファイル名からアンダーバーの手前を取得して、1_R.jpgのような形式に変換\n",
        "    uni_folder = \"/content/drive/MyDrive/Deep_learning/Olympia_dataset/dataset_uni_for_YOLOv8/dataset_uni\"\n",
        "    uni_files = os.listdir(uni_folder)\n",
        "    uni_filenames = [filename.split(\"_\")[0] for filename in uni_files]\n",
        "\n",
        "    # ①と②で一致するファイルを探して、処理を実行\n",
        "    orig_set = set(orig_filenames)\n",
        "    uni_set = set(uni_filenames)\n",
        "\n",
        "    common_filenames = orig_set.intersection(uni_set)\n",
        "\n",
        "    print(f\"In {len(common_filenames)} images, both eyes were detected. Copy files to the folder 'dataset_dlib_detected'.\")\n",
        "\n",
        "    for filename in tqdm(common_filenames, desc=\"Processing Images\"):\n",
        "        orig_file_path = os.path.join(orig_folder, filename + \".JPG\")\n",
        "        #uni_file_path = os.path.join(uni_folder, filename + \"_R.JPG\")  # \"R\"を指定していますが、\"L\"の場合もあるかもしれません\n",
        "        output_file_path = os.path.join(output_folder, filename + \".JPG\")  # 拡張子を.JPGに変更\n",
        "\n",
        "\n",
        "        print(f\"output_file_path: {output_file_path}\")\n",
        "\n",
        "        # # ①の画像を読み込み\n",
        "        # orig_image = Image.open(orig_file_path)\n",
        "        # # 一辺512pxの黒塗りletterboxに変換\n",
        "        # new_image = letterbox_image(orig_image, (512, 512))\n",
        "        # # 変換後の画像を保存\n",
        "        # new_image.save(output_file_path)\n",
        "\n",
        "        #リサイズせずにそのままコピーする\n",
        "        shutil.copy(orig_file_path, output_file_path)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "JsWZBevoSmhG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num = os.listdir(\"/content/drive/MyDrive/Deep_learning/Olympia_dataset/dataset_uni_for_YOLOv8/dataset_dlib_detected\")\n",
        "print(len(num))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BgphB4aDYNx_",
        "outputId": "f45f6110-acf1-41e1-d9f6-331b76e94f02"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "961\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**YOLOv8 annotations**"
      ],
      "metadata": {
        "id": "FdvZB6GrKCe_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#親フォルダ\n",
        "parent_dir = '/content/drive/MyDrive/Deep_learning/Olympia_dataset/dataset_uni_for_YOLOv8'\n",
        "\n",
        "#元画像フォルダ\n",
        "dataset_dir = '/content/drive/MyDrive/Deep_learning/Olympia_dataset/dataset'\n",
        "\n",
        "#元画像をコピー\n",
        "orig_dir = f\"{parent_dir}/dataset_orig\"\n",
        "\n",
        "\n",
        "#切りぬいた画像を保存するフォルダ\n",
        "out_dir = f\"{parent_dir}/dataset_uni\"\n",
        "\n",
        "#切りぬいた画像を保存するフォルダ\n",
        "dlib_detected_dir = f\"{parent_dir}/dataset_dlib_datected\"\n",
        "\n",
        "#CSVファイルのフォルダ\n",
        "csv_path = f\"{parent_dir}/dataset_uni_for_YOLO8_modified.csv\""
      ],
      "metadata": {
        "id": "t3x7BL3UKGc6"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CSVファイルを読み込んでDataFrameに格納\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# 前処理済みのフォルダを指定\n",
        "df_dlib_detected = df\n",
        "df_dlib_detected[\"img_path\"] = df_dlib_detected[\"img_path\"].str.replace(\"dataset_orig\", \"dataset_dlib_detected\")\n",
        "\n",
        "# R/Lを数字に変更\n",
        "df_dlib_detected[\"side R/L\"] = df_dlib_detected[\"side R/L\"].replace({\"R\": 0, \"L\": 1})\n",
        "\n",
        "# DataFrameの内容を表示\n",
        "df_dlib_detected"
      ],
      "metadata": {
        "id": "EXDkoZoVKuwW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 重複のないidの確認\n",
        "unique_ids = list(set(df[\"id\"].tolist()))\n",
        "print(unique_ids)\n",
        "len(unique_ids)"
      ],
      "metadata": {
        "id": "n9m_dg7jf_Uy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##########################\n",
        "# 画像フォルダ内に同名のYOLO形式txtを作成する\n",
        "##########################\n",
        "\n",
        "from PIL import Image\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "def xywh_to_yolo(class_label, img_width, img_height, x, y, w, h):\n",
        "    x_center = x / img_width\n",
        "    y_center = y / img_height\n",
        "    width = w / img_width\n",
        "    height = h / img_height\n",
        "\n",
        "    print(f\"img_width: {img_width}\")\n",
        "    print(f\"x,y,w,h: {x}, {y}, {w}, {h}\")\n",
        "\n",
        "    return f\"{class_label} {x_center} {y_center} {width} {height}\"\n",
        "\n",
        "def create_yolo_txt(df):\n",
        "    grouped_data = df.groupby('id')\n",
        "\n",
        "    for group_id, group_df in grouped_data:\n",
        "        txt_file_path = os.path.join(os.path.dirname(group_df.iloc[0]['img_path']), f\"{group_id}.txt\")\n",
        "\n",
        "        with open(txt_file_path, 'w') as txt_file:\n",
        "            for _, row in group_df.iterrows():\n",
        "                img_path = row['img_path']\n",
        "                class_label = row['side R/L']\n",
        "                x, y, w, h = row['ex'], row['ey'], row['ew'], row['eh']\n",
        "\n",
        "                try:\n",
        "                    img = Image.open(img_path)\n",
        "                    img_width, img_height = img.size\n",
        "                except Exception as e:\n",
        "                    print(f\"Error: Failed to open '{img_path}' or get image dimensions. Skipping annotation.\")\n",
        "                    continue\n",
        "\n",
        "                # YOLO形式に変換\n",
        "                yolo_annotation = xywh_to_yolo(class_label, img_width, img_height, x, y, w, h)\n",
        "\n",
        "                # ファイルに書き込み\n",
        "                yolo_annotation += '\\n'  # 改行を追加\n",
        "                txt_file.write(yolo_annotation)        # ファイル内容を参照する\n",
        "\n",
        "        with open(txt_file_path, 'r') as txt_file_read:\n",
        "            file_contents = txt_file_read.read()\n",
        "            print(f\"Contents of '{txt_file_path}':\\n{file_contents}\")\n",
        "\n",
        "# YOLO形式のテキストファイルを作成して保存\n",
        "df_sample = df_dlib_detected[0:]\n",
        "create_yolo_txt(df_sample)\n"
      ],
      "metadata": {
        "id": "cjbhluZHLyQJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_dlib_detected"
      ],
      "metadata": {
        "id": "dBylsWVIxSxk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **YOLOv8_training**"
      ],
      "metadata": {
        "id": "DX_lR8bf2QSE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "parent_dir = '/content/drive/MyDrive/Deep_learning/Olympia_dataset/dataset_uni_for_YOLOv8'\n",
        "eyecrop_dir = os.path.join(parent_dir, 'for_eyecrop_training')\n",
        "\n",
        "\n",
        "# もし既に\"eyecrop\"フォルダが存在する場合、削除します\n",
        "if os.path.exists(eyecrop_dir):\n",
        "    try:\n",
        "        shutil.rmtree(eyecrop_dir)  # 空のフォルダならこれで削除できます\n",
        "    except OSError as e:\n",
        "        print(f\"削除に失敗しました: {e}\")\n",
        "else:\n",
        "    print(\"フォルダが存在しませんでした。新しく作成します。\")\n",
        "\n",
        "# \"eyecrop\"フォルダを作成します\n",
        "try:\n",
        "    os.mkdir(eyecrop_dir)\n",
        "    print(\"eyecropフォルダが作成されました。\")\n",
        "except OSError as e:\n",
        "    print(f\"フォルダの作成に失敗しました: {e}\")\n",
        "\n",
        "# \"train\"フォルダを作成します\n",
        "train_dir = os.path.join(eyecrop_dir, 'train')\n",
        "try:\n",
        "    os.mkdir(train_dir)\n",
        "    print(\"trainフォルダが作成されました。\")\n",
        "except OSError as e:\n",
        "    print(f\"フォルダの作成に失敗しました: {e}\")\n",
        "\n",
        "# \"val\"フォルダを作成します\n",
        "val_dir = os.path.join(eyecrop_dir, 'val')\n",
        "try:\n",
        "    os.mkdir(val_dir)\n",
        "    print(\"valフォルダが作成されました。\")\n",
        "except OSError as e:\n",
        "    print(f\"フォルダの作成に失敗しました: {e}\")\n",
        "\n",
        "\n",
        "# YAMLファイルの設定\"\n",
        "yaml_file_path = os.path.join(eyecrop_dir, 'data.yaml')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "esqHHl4R8giz",
        "outputId": "19be9830-029d-4054-fa13-7ac5d4d7882a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "フォルダが存在しませんでした。新しく作成します。\n",
            "eyecropフォルダが作成されました。\n",
            "trainフォルダが作成されました。\n",
            "valフォルダが作成されました。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# YAML ファイルの内容を設定\n",
        "%%writefile $yaml_file_path\n",
        "# train and val data as 1) directory: path/images/, 2) file: path/images.txt, or 3) list: [path1/images/, path2/images/]\n",
        "train: /content/drive/MyDrive/Deep_learning/Olympia_dataset/dataset_uni_for_YOLOv8/for_eyecrop_training/train\n",
        "val: /content/drive/MyDrive/Deep_learning/Olympia_dataset/dataset_uni_for_YOLOv8/for_eyecrop_training/val\n",
        "\n",
        "# number of classes\n",
        "nc: 2\n",
        "\n",
        "# class names\n",
        "names: ['R', 'L']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iECkqqgu71rl",
        "outputId": "97aec80b-a6ea-47da-e336-0e77bf70f0d4"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/drive/MyDrive/Deep_learning/Olympia_dataset/dataset_uni_for_YOLOv8/for_eyecrop_training/data.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "データセットを７：３に分割\n",
        "\n",
        "Deep_learning\n",
        "└── Olympia_dataset\n",
        "    └── dataset_uni_for_YOLOv8\n",
        "        └── for_eyecrop_training\n",
        "            ├── train\n",
        "            ├── val\n",
        "            └── data.yaml\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "import glob\n",
        "import shutil\n",
        "import os\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "\n",
        "# 再現性を確保するためのrandom_state\n",
        "random.seed(42)\n",
        "\n",
        "# 入力ディレクトリと出力ディレクトリのパス\n",
        "src_dir = '/content/drive/MyDrive/Deep_learning/Olympia_dataset/dataset_uni_for_YOLOv8/dataset_dlib_detected'\n",
        "train_dir = '/content/drive/MyDrive/Deep_learning/Olympia_dataset/dataset_uni_for_YOLOv8/for_eyecrop_training/train'\n",
        "val_dir = '/content/drive/MyDrive/Deep_learning/Olympia_dataset/dataset_uni_for_YOLOv8/for_eyecrop_training/val'\n",
        "\n",
        "# 入力ディレクトリからJPGファイルのリストを取得\n",
        "jpg_files = glob.glob(os.path.join(src_dir, '*.JPG'))\n",
        "\n",
        "# ファイルをランダムにシャッフル\n",
        "random.shuffle(jpg_files)\n",
        "\n",
        "# ファイルを70%:30%に分割\n",
        "split_point = int(len(jpg_files) * 0.7)\n",
        "train_files = jpg_files[:split_point]\n",
        "val_files = jpg_files[split_point:]\n",
        "\n",
        "# ファイルをそれぞれのディレクトリにコピー\n",
        "for file_path in tqdm(train_files, desc=\"Copying train files\"):\n",
        "    shutil.copy2(file_path, train_dir)\n",
        "    txt_file = os.path.splitext(file_path)[0] + '.txt'\n",
        "    shutil.copy2(txt_file, train_dir)\n",
        "\n",
        "for file_path in tqdm(val_files, desc=\"Copying validation files\"):\n",
        "    shutil.copy2(file_path, val_dir)\n",
        "    txt_file = os.path.splitext(file_path)[0] + '.txt'\n",
        "    shutil.copy2(txt_file, val_dir)\n"
      ],
      "metadata": {
        "id": "AhIlcPgZCOGE",
        "outputId": "ac093e65-c8de-4cd5-8974-52de0983fb76",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Copying train files: 100%|██████████| 672/672 [00:14<00:00, 45.15it/s]\n",
            "Copying validation files: 100%|██████████| 289/289 [00:06<00:00, 44.39it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# YOLOv8 setup\n",
        "%pip install ultralytics\n",
        "import ultralytics\n",
        "ultralytics.checks()"
      ],
      "metadata": {
        "id": "O6SawQZdE5DV",
        "outputId": "376f0a73-97f0-4d4c-892b-a8276c8fe570",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ultralytics YOLOv8.0.157 🚀 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Setup complete ✅ (8 CPUs, 51.0 GB RAM, 31.9/166.8 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "yaml_file_path = '/content/drive/MyDrive/Deep_learning/Olympia_dataset/dataset_uni_for_YOLOv8/for_eyecrop_training/data.yaml'\n",
        "\n",
        "%cd /content/drive/MyDrive/Deep_learning/Olympia_dataset/dataset_uni_for_YOLOv8/for_eyecrop_training"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0y_l04WrGVKs",
        "outputId": "1189383a-65c2-4f9a-970e-3b06a3016879"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Deep_learning/Olympia_dataset/dataset_uni_for_YOLOv8/for_eyecrop_training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!yolo task=detect mode=train model=yolov8n.pt data=$yaml_file_path epochs=100 imgsz=640\n"
      ],
      "metadata": {
        "id": "MVhZngabFHOL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#続きのトレーニング\n",
        "from ultralytics import YOLO\n",
        "\n",
        "yaml_file_path = '/content/drive/MyDrive/Deep_learning/Olympia_dataset/dataset_uni_for_YOLOv8/for_eyecrop_training/data.yaml'\n",
        "\n",
        "# Load a model\n",
        "model = YOLO('/content/drive/MyDrive/Deep_learning/Olympia_dataset/dataset_uni_for_YOLOv8/for_eyecrop_training/yolov8n.pt')  # load a pretrained model (recommended for training)\n",
        "\n",
        "# Train the model\n",
        "model.train(data=yaml_file_path, epochs=100, imgsz=640, resume=True)"
      ],
      "metadata": {
        "id": "PNjb7qWNPW-1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**YOLOv8 interference**"
      ],
      "metadata": {
        "id": "ySmQamVspQKC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOLOv8 setup\n",
        "%pip install ultralytics\n",
        "import ultralytics\n",
        "ultralytics.checks()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uh0dYAFu3vjY",
        "outputId": "68db6ebc-9c40-4727-b653-07df059d3433"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ultralytics YOLOv8.0.143 🚀 Python-3.10.6 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Setup complete ✅ (4 CPUs, 25.5 GB RAM, 24.2/166.8 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "dataset_orig_dir = \"/content/drive/MyDrive/Deep_learning/Olympia_dataset/dataset_uni_for_YOLOv8/dataset_orig\"\n",
        "sample_img = random.choice(glob.glob(f\"{dataset_orig_dir}/*\"))\n",
        "\n"
      ],
      "metadata": {
        "id": "Zk5NbELPMCDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from ultralytics import YOLO\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from IPython.display import Image as DisplayImage\n",
        "from IPython.display import display\n",
        "import cv2\n",
        "\n",
        "sample_img = \"/content/drive/MyDrive/Deep_learning/Olympia_dataset/dataset_uni_for_YOLOv8/dataset_orig/10.JPG\"\n",
        "\n",
        "\n",
        "# 事前学習済みのモデルを読み込み(detectionモデルを使用)\n",
        "model = YOLO('/content/drive/MyDrive/Deep_learning/Olympia_dataset/dataset_uni_for_YOLOv8/for_eyecrop_training/yolov8n.pt')\n",
        "# predictモードを実行 (結果だけ欲しいので、project・name・exist_okはなくてもOK)\n",
        "results = model.predict(source=sample_img)\n",
        "# Resultsオブジェクトから描画に必要な情報を取得\n",
        "coordinate_bbox = results[0].boxes.xyxy #bbox\n",
        "classes=results[0].boxes.cls # 検出クラス\n",
        "#classes_map = results[0].names # クラス番号と名称\n",
        "classes_map = {0: 'R',1: 'L'} # クラス番号と名称\n",
        "\n",
        "\n",
        "# 画像の読み込み\n",
        "img = Image.open(results[0].path)\n",
        "# 色の指定 (クラスごとにランダムに色を選択する場合使う)\n",
        "# colors = ['red', 'green', 'blue', 'yellow', 'cyan', 'magenta', 'olive', 'purple']\n",
        "# colors = [(255, 0, 0), (0, 255, 0), (0, 0, 255), (255, 255, 0), (0, 255, 255), (255, 0, 255), (128, 128, 0), (128, 0, 128)]\n",
        "# 描画コンテントの取得\n",
        "draw = ImageDraw.Draw(img)\n",
        "\"\"\"\n",
        "フォントの設定。Macだと/System/Library/Fontsに色々あるのでここから選んだ。\n",
        "bboxだけの描画であれば必要ない。必要ない場合はdraw.text(font=font)のfont部分を消す。\n",
        "エラーが出る場合はフォントファイルへのフルパス(/System/Library/Fonts/ヒラギノ丸ゴ ProN W4.ttc)で設定してあげる\n",
        "\"\"\"\n",
        "font = ImageFont.truetype('/usr/share/fonts/truetype/liberation/LiberationSans-Regular.ttf', 4000)\n",
        "# バウンディングボックスの描画\n",
        "i=1\n",
        "for bbox, cls in zip(coordinate_bbox, classes):\n",
        "    x1, y1, x2, y2 = map(int, bbox)\n",
        "    #color = colors[int(cls) % len(colors)] 今回は色を直接指定するので使わない\n",
        "    color=(255,0,0) # red\n",
        "    # bboxの描画\n",
        "    draw.rectangle([x1, y1, x2, y2], outline=color, width=5)\n",
        "    cls_text = classes_map.get(int(cls))\n",
        "    # 検出クラス名の描画\n",
        "    draw.text((x1, y1 - 50), cls_text+\"#\"+str(i), fill=\"orange\")\n",
        "    print(f\"class: {cls_text}\")\n",
        "    print(f\"x1: {x1}, y1: {y1}, x2: {x2}, y2: {y2}\")\n",
        "    i += 1\n",
        "# 画像のリサイズ (必要であれば)\n",
        "#img = img.resize((640,640))\n",
        "# 出力先フォルダの作成。model.predictで作成させてもOK。\n",
        "directories = ['/content/predict']\n",
        "for directory in directories:\n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "# 画像の保存 (存在しないフォルダだとFileNotFoundErrorになるので注意)\n",
        "img.save('/content/test.png')\n",
        "# 画像の表示\n",
        "display(DisplayImage(filename='/content/test.png'))"
      ],
      "metadata": {
        "id": "q4mjNJMIMCF5",
        "outputId": "cbcd7860-ec8a-4b04-e688-bd73d531bcf5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "image 1/1 /content/drive/MyDrive/Deep_learning/Olympia_dataset/dataset_uni_for_YOLOv8/dataset_orig/10.JPG: 448x640 1 person, 1 donut, 7.4ms\n",
            "Speed: 2.8ms preprocess, 7.4ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "class: R\n",
            "x1: 4, y1: 5, x2: 2585, y2: 1704\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-516acf7cb4d4>\u001b[0m in \u001b[0;36m<cell line: 37>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mcls_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclasses_map\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;31m# 検出クラス名の描画\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0mdraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls_text\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"#\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"orange\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"class: {cls_text}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"x1: {x1}, y1: {y1}, x2: {x2}, y2: {y2}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'NoneType' and 'str'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classes_map"
      ],
      "metadata": {
        "id": "C6pKCGXWIIch",
        "outputId": "5524c74a-51ed-4c3c-b888-948ad35943ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'person',\n",
              " 1: 'bicycle',\n",
              " 2: 'car',\n",
              " 3: 'motorcycle',\n",
              " 4: 'airplane',\n",
              " 5: 'bus',\n",
              " 6: 'train',\n",
              " 7: 'truck',\n",
              " 8: 'boat',\n",
              " 9: 'traffic light',\n",
              " 10: 'fire hydrant',\n",
              " 11: 'stop sign',\n",
              " 12: 'parking meter',\n",
              " 13: 'bench',\n",
              " 14: 'bird',\n",
              " 15: 'cat',\n",
              " 16: 'dog',\n",
              " 17: 'horse',\n",
              " 18: 'sheep',\n",
              " 19: 'cow',\n",
              " 20: 'elephant',\n",
              " 21: 'bear',\n",
              " 22: 'zebra',\n",
              " 23: 'giraffe',\n",
              " 24: 'backpack',\n",
              " 25: 'umbrella',\n",
              " 26: 'handbag',\n",
              " 27: 'tie',\n",
              " 28: 'suitcase',\n",
              " 29: 'frisbee',\n",
              " 30: 'skis',\n",
              " 31: 'snowboard',\n",
              " 32: 'sports ball',\n",
              " 33: 'kite',\n",
              " 34: 'baseball bat',\n",
              " 35: 'baseball glove',\n",
              " 36: 'skateboard',\n",
              " 37: 'surfboard',\n",
              " 38: 'tennis racket',\n",
              " 39: 'bottle',\n",
              " 40: 'wine glass',\n",
              " 41: 'cup',\n",
              " 42: 'fork',\n",
              " 43: 'knife',\n",
              " 44: 'spoon',\n",
              " 45: 'bowl',\n",
              " 46: 'banana',\n",
              " 47: 'apple',\n",
              " 48: 'sandwich',\n",
              " 49: 'orange',\n",
              " 50: 'broccoli',\n",
              " 51: 'carrot',\n",
              " 52: 'hot dog',\n",
              " 53: 'pizza',\n",
              " 54: 'donut',\n",
              " 55: 'cake',\n",
              " 56: 'chair',\n",
              " 57: 'couch',\n",
              " 58: 'potted plant',\n",
              " 59: 'bed',\n",
              " 60: 'dining table',\n",
              " 61: 'toilet',\n",
              " 62: 'tv',\n",
              " 63: 'laptop',\n",
              " 64: 'mouse',\n",
              " 65: 'remote',\n",
              " 66: 'keyboard',\n",
              " 67: 'cell phone',\n",
              " 68: 'microwave',\n",
              " 69: 'oven',\n",
              " 70: 'toaster',\n",
              " 71: 'sink',\n",
              " 72: 'refrigerator',\n",
              " 73: 'book',\n",
              " 74: 'clock',\n",
              " 75: 'vase',\n",
              " 76: 'scissors',\n",
              " 77: 'teddy bear',\n",
              " 78: 'hair drier',\n",
              " 79: 'toothbrush'}"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results[0].names"
      ],
      "metadata": {
        "id": "szujxTxnwV5B",
        "outputId": "6a43f8cc-dce7-4ea4-eb13-28d9af1563a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'person',\n",
              " 1: 'bicycle',\n",
              " 2: 'car',\n",
              " 3: 'motorcycle',\n",
              " 4: 'airplane',\n",
              " 5: 'bus',\n",
              " 6: 'train',\n",
              " 7: 'truck',\n",
              " 8: 'boat',\n",
              " 9: 'traffic light',\n",
              " 10: 'fire hydrant',\n",
              " 11: 'stop sign',\n",
              " 12: 'parking meter',\n",
              " 13: 'bench',\n",
              " 14: 'bird',\n",
              " 15: 'cat',\n",
              " 16: 'dog',\n",
              " 17: 'horse',\n",
              " 18: 'sheep',\n",
              " 19: 'cow',\n",
              " 20: 'elephant',\n",
              " 21: 'bear',\n",
              " 22: 'zebra',\n",
              " 23: 'giraffe',\n",
              " 24: 'backpack',\n",
              " 25: 'umbrella',\n",
              " 26: 'handbag',\n",
              " 27: 'tie',\n",
              " 28: 'suitcase',\n",
              " 29: 'frisbee',\n",
              " 30: 'skis',\n",
              " 31: 'snowboard',\n",
              " 32: 'sports ball',\n",
              " 33: 'kite',\n",
              " 34: 'baseball bat',\n",
              " 35: 'baseball glove',\n",
              " 36: 'skateboard',\n",
              " 37: 'surfboard',\n",
              " 38: 'tennis racket',\n",
              " 39: 'bottle',\n",
              " 40: 'wine glass',\n",
              " 41: 'cup',\n",
              " 42: 'fork',\n",
              " 43: 'knife',\n",
              " 44: 'spoon',\n",
              " 45: 'bowl',\n",
              " 46: 'banana',\n",
              " 47: 'apple',\n",
              " 48: 'sandwich',\n",
              " 49: 'orange',\n",
              " 50: 'broccoli',\n",
              " 51: 'carrot',\n",
              " 52: 'hot dog',\n",
              " 53: 'pizza',\n",
              " 54: 'donut',\n",
              " 55: 'cake',\n",
              " 56: 'chair',\n",
              " 57: 'couch',\n",
              " 58: 'potted plant',\n",
              " 59: 'bed',\n",
              " 60: 'dining table',\n",
              " 61: 'toilet',\n",
              " 62: 'tv',\n",
              " 63: 'laptop',\n",
              " 64: 'mouse',\n",
              " 65: 'remote',\n",
              " 66: 'keyboard',\n",
              " 67: 'cell phone',\n",
              " 68: 'microwave',\n",
              " 69: 'oven',\n",
              " 70: 'toaster',\n",
              " 71: 'sink',\n",
              " 72: 'refrigerator',\n",
              " 73: 'book',\n",
              " 74: 'clock',\n",
              " 75: 'vase',\n",
              " 76: 'scissors',\n",
              " 77: 'teddy bear',\n",
              " 78: 'hair drier',\n",
              " 79: 'toothbrush'}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rhyAS02tMCIT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Mp0v-saxOElF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Qk3r2PCCOEno"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_N89zEa_OEqG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget /content https://pds.exblog.jp/logo/1/197001/01/18/b043001820221113221721.jpg\n",
        "!wget /content https://plugins-media.makeupar.com/smb/blog/post/2023-06-15/37011ea9-289b-4700-9e61-6a1429128ae6.jpg\n",
        "!wget /content https://www.city.gosen.lg.jp/material/images/group/5/chugatasu.JPG\n",
        "img_path = [\"/content/b043001820221113221721.jpg\", \"37011ea9-289b-4700-9e61-6a1429128ae6.jpg\", \"chugatasu.JPG\"]"
      ],
      "metadata": {
        "id": "GZ1Pi39p4D2I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from ultralytics import YOLO\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from IPython.display import Image as DisplayImage\n",
        "from IPython.display import display\n",
        "import cv2\n",
        "# 事前学習済みのモデルを読み込み(detectionモデルを使用)\n",
        "model = YOLO('yolov8n.pt')\n",
        "# predictモードを実行 (結果だけ欲しいので、project・name・exist_okはなくてもOK)\n",
        "results = model.predict(source=img_path[2])\n",
        "# Resultsオブジェクトから描画に必要な情報を取得\n",
        "coordinate_bbox = results[0].boxes.xyxy #bbox\n",
        "classes=results[0].boxes.cls # 検出クラス\n",
        "classes_map = results[0].names # クラス番号と名称\n",
        "# 画像の読み込み\n",
        "img = Image.open(results[0].path)\n",
        "# 色の指定 (クラスごとにランダムに色を選択する場合使う)\n",
        "# colors = ['red', 'green', 'blue', 'yellow', 'cyan', 'magenta', 'olive', 'purple']\n",
        "# colors = [(255, 0, 0), (0, 255, 0), (0, 0, 255), (255, 255, 0), (0, 255, 255), (255, 0, 255), (128, 128, 0), (128, 0, 128)]\n",
        "# 描画コンテントの取得\n",
        "draw = ImageDraw.Draw(img)\n",
        "\"\"\"\n",
        "フォントの設定。Macだと/System/Library/Fontsに色々あるのでここから選んだ。\n",
        "bboxだけの描画であれば必要ない。必要ない場合はdraw.text(font=font)のfont部分を消す。\n",
        "エラーが出る場合はフォントファイルへのフルパス(/System/Library/Fonts/ヒラギノ丸ゴ ProN W4.ttc)で設定してあげる\n",
        "\"\"\"\n",
        "font = ImageFont.truetype('/usr/share/fonts/truetype/liberation/LiberationSans-Regular.ttf', 4000)\n",
        "# バウンディングボックスの描画\n",
        "i=1\n",
        "for bbox, cls in zip(coordinate_bbox, classes):\n",
        "    x1, y1, x2, y2 = map(int, bbox)\n",
        "    #color = colors[int(cls) % len(colors)] 今回は色を直接指定するので使わない\n",
        "    color=(255,0,0) # red\n",
        "    # bboxの描画\n",
        "    draw.rectangle([x1, y1, x2, y2], outline=color, width=5)\n",
        "    cls_text = classes_map.get(int(cls))\n",
        "    # 検出クラス名の描画\n",
        "    draw.text((x1, y1 - 50), cls_text+\"#\"+str(i), fill=\"orange\")\n",
        "    print(f\"class: {cls_text}\")\n",
        "    print(f\"x1: {x1}, y1: {y1}, x2: {x2}, y2: {y2}\")\n",
        "    i += 1\n",
        "# 画像のリサイズ (必要であれば)\n",
        "#img = img.resize((640,640))\n",
        "# 出力先フォルダの作成。model.predictで作成させてもOK。\n",
        "directories = ['/Users/hinomaruc/Desktop/blog/dataset/yolov8/runs/mypredict']\n",
        "for directory in directories:\n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "# 画像の保存 (存在しないフォルダだとFileNotFoundErrorになるので注意)\n",
        "img.save('/Users/hinomaruc/Desktop/blog/dataset/yolov8/runs/mypredict/sample_bbox.png')\n",
        "# 画像の表示\n",
        "display(DisplayImage(filename='/Users/hinomaruc/Desktop/blog/dataset/yolov8/runs/mypredict/sample_bbox.png'))"
      ],
      "metadata": {
        "id": "2zTw01xTZlu2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "outputId": "9f39e7da-7e8a-4418-9d7f-3c2fda623ad5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt to 'yolov8n.pt'...\n",
            "100%|██████████| 6.23M/6.23M [00:00<00:00, 6.72MB/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-a993d544b0ca>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mYOLO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'yolov8n.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# predictモードを実行 (結果だけ欲しいので、project・name・exist_okはなくてもOK)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;31m# Resultsオブジェクトから描画に必要な情報を取得\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mcoordinate_bbox\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxyxy\u001b[0m \u001b[0;31m#bbox\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'img_path' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os\n",
        "from ultralytics import YOLO\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from IPython.display import Image as DisplayImage\n",
        "from IPython.display import display\n",
        "\n",
        "# 事前学習済みのモデルを読み込み(detectionモデルを使用)\n",
        "model = YOLO('yolov8n.pt')\n",
        "# predictモードを実行 (結果だけ欲しいので、project・name・exist_okはなくてもOK)\n",
        "results = model.predict(source=img_path[1])\n",
        "# Resultsオブジェクトから描画に必要な情報を取得\n",
        "coordinate_bbox = results[0].boxes.xyxy #bbox\n",
        "classes=results[0].boxes.cls # 検出クラス\n",
        "classes_map = results[0].names # クラス番号と名称\n",
        "\n",
        "# Open the image file\n",
        "img_cv2 = cv2.imread(results[0].path)\n",
        "\n",
        "# Set the font scale and thickness\n",
        "font_scale = 3\n",
        "font_thickness = 2\n",
        "\n",
        "# Loop through each bounding box\n",
        "i=1\n",
        "for bbox, cls in zip(coordinate_bbox, classes):\n",
        "    print(bbox)\n",
        "\n",
        "    x1, y1, x2, y2 = map(int, bbox)\n",
        "    color=(0,0,255) # red\n",
        "    # Draw the bounding box\n",
        "    cv2.rectangle(img_cv2, (x1, y1), (x2, y2), color, 5)\n",
        "    cls_text = classes_map.get(int(cls))\n",
        "    # Put the class label text\n",
        "    cv2.putText(img_cv2, cls_text+\"#\"+str(i), (x1, y1 - 50), cv2.FONT_HERSHEY_SIMPLEX, font_scale, color, font_thickness)\n",
        "    i += 1\n",
        "\n",
        "# Save the image\n",
        "cv2.imwrite('/Users/hinomaruc/Desktop/blog/dataset/yolov8/runs/mypredict/sample_bbox.png', img_cv2)\n",
        "\n",
        "\n",
        "#plt.imshow(cv2.cvtColor(img_cv2, cv2.COLOR_BGR2RGB))\n",
        "# Convert the color from BGR to RGB\n",
        "img_rgb = cv2.cvtColor(img_cv2, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Use matplotlib to display the image\n",
        "plt.imshow(img_rgb)\n",
        "\n",
        "# Show the axes\n",
        "plt.axis('on')\n",
        "\n",
        "# Show the image\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "aTBwFQPBet5H"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
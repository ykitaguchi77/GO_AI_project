{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOVp2ZNTvLbr9Iuy2VAlVQ6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykitaguchi77/GO_AI_project/blob/main/YOLOv8_to_EfficientNetV2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**YOLOv8 to EfficientNetv2 pipeline**"
      ],
      "metadata": {
        "id": "w2bPHz9wew6n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Olympia datasetから目を切り抜く（YOLOv8n）**\n",
        "#**切り抜いた目をEfficientNetV2で解析する**"
      ],
      "metadata": {
        "id": "LXWb3YtIFX1p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Olympia dataset\n",
        "Dlibで目が2つ検出されるものを抜き出す\n",
        "YOLOv8を用いて左右とバウンディングボックスを認識させる\n",
        "切り抜いたバウンディングボックス内の画像について、EfficientNetv2を用いて眼球突出度、MRD-1、MRD-2を回帰させる\n",
        "スマホに実装\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "UnyBedKNbfS3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7MdRVDhFJmO",
        "outputId": "87e7818b-a018-45e0-c80a-e8b9bdb7434a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import shutil\n",
        "import copy\n",
        "import pandas as pd\n",
        "import csv\n",
        "from tqdm import tqdm\n",
        "\n",
        "import glob\n",
        "import random\n",
        "from PIL import Image\n",
        "%matplotlib inline\n",
        "\n",
        "#サポートパッチのインポート\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "\n",
        "plt.ion()   # interactive mode\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#親フォルダ\n",
        "parent_dir = '/content/drive/MyDrive/Deep_learning/Olympia_dataset/dataset_uni_for_YOLOv8'\n",
        "\n",
        "#元画像フォルダ\n",
        "dataset_dir = '/content/drive/MyDrive/Deep_learning/Olympia_dataset/dataset'\n",
        "\n",
        "#元画像をコピー\n",
        "orig_dir = f\"{parent_dir}/dataset_orig\"\n",
        "\n",
        "#切りぬいた画像を保存するフォルダ\n",
        "out_dir = f\"{parent_dir}/dataset_uni\"\n",
        "\n",
        "#CSVファイルのフォルダ\n",
        "csv_path = f\"{parent_dir}/dataset_uni_for_YOLO8.csv\""
      ],
      "metadata": {
        "id": "_DI1wc0eF5uR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# parent_dirがあれば削除する\n",
        "if os.path.exists(parent_dir):\n",
        "    shutil.rmtree(parent_dir)\n",
        "\n",
        "# 新しくparent_dirを作成する\n",
        "os.makedirs(parent_dir)\n",
        "\n",
        "# orig_dir, out_dirを新規に作成する\n",
        "os.makedirs(orig_dir)\n",
        "os.makedirs(out_dir)\n",
        "\n",
        "# orig_dirにdataset_dir直下のファイルをすべてコピーする\n",
        "file_list = os.listdir(dataset_dir)\n",
        "for filename in tqdm(file_list, desc=\"Copying files\", unit=\"file\"):\n",
        "    src_path = os.path.join(dataset_dir, filename)\n",
        "    dst_path = os.path.join(orig_dir, filename)\n",
        "    shutil.copy(src_path, dst_path)\n",
        "\n",
        "print(\"処理が完了しました。\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2ZGZkPOK84g",
        "outputId": "0f2558fd-b5d6-4236-f0e3-1856972b7051"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Copying files: 100%|██████████| 1016/1016 [00:53<00:00, 19.03file/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "処理が完了しました。\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**HaarCascadeを用いて目を検出**"
      ],
      "metadata": {
        "id": "6Y6OC0UoMOZv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# カスケードファイルのパス\n",
        "eye_cascade_path = '/content/drive/My Drive/Deep_learning/haarcascade_eye.xml'\n",
        "\n",
        "# カスケード分類器の特徴量取得\n",
        "eye_cascade = cv2.CascadeClassifier(eye_cascade_path)\n"
      ],
      "metadata": {
        "id": "f2rM0ZbTMN50"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**目が2つ以上検出されたものを抜き出す**"
      ],
      "metadata": {
        "id": "FWLibTiZc1Xw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(csv_path, 'w', newline='') as f:\n",
        "        #fieldnames = ['Number', 'Folder', 'FileName']\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow(['id','img_path', 'side R/L', 'ex', 'ey', 'ew', 'eh'])  #header\n",
        "\n",
        "        files = os.listdir(orig_dir)\n",
        "\n",
        "        k=0\n",
        "        for file in files:  #フォルダ数の分だけ\n",
        "              file_path = f\"{orig_dir}/{file}\"\n",
        "              id = os.path.splitext(os.path.basename(file_path))[0]\n",
        "\n",
        "              img = cv2.imread(file_path)\n",
        "              img2 = img.copy()\n",
        "\n",
        "              # 画像グレースケール化\n",
        "              grayscale_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "              #300pix以上のもので目に見えるものを抽出\n",
        "              eye_list = eye_cascade.detectMultiScale(grayscale_img, minSize=(300, 300))\n",
        "\n",
        "              # 眼検出判定\n",
        "              if len(eye_list) >= 1:\n",
        "                  print('目が' + str(len(eye_list)) +'個検出されました')\n",
        "              else:\n",
        "                  print(\"eye detection error\")\n",
        "\n",
        "              #画像の切り抜きと保存（2個以上検出の時に限る）\n",
        "              if len(eye_list) >= 2:\n",
        "                  for (ex, ey, ew, eh) in eye_list:\n",
        "                      print(f\"img_width: {img2.shape[1]}\")\n",
        "                      print(\"[ex,ey] = %d,%d [ew,eh] = %d,%d\" %(ex, ey, ew, eh))\n",
        "                      cv2.rectangle(img2, (ex, ey), (ex + ew, ey + eh), (0, 255, 0), 2)\n",
        "                      #img_cropped = img[int(ey-0.1*eh): int(ey+1.1*eh), int(ex-0.1*ew): int(ex+1.1*ew)] #本来の切り抜きより幅の0.1倍ずつ水増しする\n",
        "                      img_cropped = img[int(ey): int(ey+eh), int(ex): int(ex+ew)]\n",
        "\n",
        "\n",
        "                      if ex+eh*0.5 <= img2.shape[1]/2:\n",
        "                          side = \"R\" #横幅の半分より左にあるのは右眼\n",
        "                      else:\n",
        "                          side = \"L\" #横幅の半分よりより右にあるのは左眼\n",
        "\n",
        "                      print(f\"side: {side}\")\n",
        "                      print(\"\")\n",
        "\n",
        "                      cv2.imwrite(f\"{out_dir}/{id}_{side}.png\", img_cropped)\n",
        "\n",
        "                      #対応表の作成\n",
        "                      writer.writerow([id, file_path, side, ex, ey, ew, eh])\n",
        "                  else:\n",
        "                      pass\n"
      ],
      "metadata": {
        "id": "pnVFMJJVMW8n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**ここで、目以外が誤検出されているものを手動で抜き出して削除する**"
      ],
      "metadata": {
        "id": "tm4HsJszc9VX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "不適切な画像があれば、左右まとめて消す\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "v3abWZGGe9sA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#CSVのリストと画像フォルダを見比べて、消した画像を判別。CSVを修正する。\n",
        "import pandas as pd\n",
        "\n",
        "# Load the CSV\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# Get a list of unique ids\n",
        "csv_id_list = df['id'].unique().tolist()\n",
        "\n",
        "print(f\"csv_id_list: {csv_id_list}\")\n",
        "\n",
        "\n",
        "# Construct the output directory path\n",
        "out_dir = f\"{parent_dir}/dataset_uni\"\n",
        "\n",
        "# Get a list of all image file names in the directory\n",
        "image_file_names = os.listdir(out_dir)\n",
        "\n",
        "# Split each file name at \"_\" and take the first part, then make sure the list is unique\n",
        "image_id_list = list(set([int(name.split('_')[0]) for name in image_file_names]))\n",
        "print(f\"image_id_list: {image_id_list}\")\n",
        "\n",
        "# Find the ids that are in the CSV list but not in the image file list\n",
        "missing_ids = [id for id in csv_id_list if id not in image_id_list]\n",
        "print(f\"missing_ids: {missing_ids}\")\n",
        "\n",
        "\n",
        "\n",
        "# Remove the rows with ids in missing_ids\n",
        "df = df[~df['id'].isin(missing_ids)]\n",
        "\n",
        "# Save the dataframe back to a CSV\n",
        "df.to_csv(f\"{os.path.splitext(os.path.basename(csv_path))[0]}_modified.csv\", index=False)"
      ],
      "metadata": {
        "id": "aGVqU2n9i3wR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "①\"/content/drive/MyDrive/Deep_learning/Olympia_dataset/dataset_uni_for_YOLOv8/dataset_orig\"のファイル名（1.jpgとすると1）と、②\"/content/drive/MyDrive/Deep_learning/Olympia_dataset/dataset_uni_for_YOLOv8/dataset_uni\"のアンダーバーの手前（1_R.jpgとすると1)を見比べる\n",
        "\n",
        "\"/content/drive/MyDrive/Deep_learning/Olympia_dataset/dataset_uni_for_YOLOv8/dataset_dlib_detected\"というフォルダを作成\n",
        "①と②で一致するものに関して、①の画像（コピー）を一辺512pixの黒塗りletterboxにして変換し、新しく作成したフォルダに保存する\n",
        "\"\"\"\n",
        "\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "def letterbox_image(image, size):\n",
        "    \"\"\"\n",
        "    画像を指定したサイズの黒塗りletterboxに変換する関数\n",
        "    :param image: 変換する画像（PIL Image）\n",
        "    :param size: 変換後のサイズ（幅, 高さ）のタプル\n",
        "    :return: 変換後の画像（PIL Image）\n",
        "    \"\"\"\n",
        "    new_width, new_height = size\n",
        "    old_width, old_height = image.size\n",
        "    ratio = min(new_width / old_width, new_height / old_height)\n",
        "    new_width = int(old_width * ratio)\n",
        "    new_height = int(old_height * ratio)\n",
        "    resized_image = image.resize((new_width, new_height), Image.LANCZOS)\n",
        "    boxed_image = Image.new(\"RGB\", size, (0, 0, 0))\n",
        "    boxed_image.paste(resized_image, ((size[0] - new_width) // 2, (size[1] - new_height) // 2))\n",
        "    return boxed_image\n",
        "\n",
        "def main():\n",
        "    # 保存先フォルダのパス\n",
        "    output_folder = \"/content/drive/MyDrive/Deep_learning/Olympia_dataset/dataset_uni_for_YOLOv8/dataset_dlib_detected\"\n",
        "\n",
        "    # フォルダが存在しない場合は作成\n",
        "    if os.path.exists(output_folder):\n",
        "        shutil.rmtree(output_folder)\n",
        "    os.makedirs(output_folder)\n",
        "\n",
        "    # ①のフォルダ内のファイル名を取得して、1.jpgのような形式に変換\n",
        "    orig_folder = \"/content/drive/MyDrive/Deep_learning/Olympia_dataset/dataset_uni_for_YOLOv8/dataset_orig\"\n",
        "    orig_files = os.listdir(orig_folder)\n",
        "    orig_filenames = [os.path.splitext(filename)[0] for filename in orig_files]\n",
        "\n",
        "    # ②のフォルダ内のファイル名からアンダーバーの手前を取得して、1_R.jpgのような形式に変換\n",
        "    uni_folder = \"/content/drive/MyDrive/Deep_learning/Olympia_dataset/dataset_uni_for_YOLOv8/dataset_uni\"\n",
        "    uni_files = os.listdir(uni_folder)\n",
        "    uni_filenames = [filename.split(\"_\")[0] for filename in uni_files]\n",
        "\n",
        "    # ①と②で一致するファイルを探して、処理を実行\n",
        "    orig_set = set(orig_filenames)\n",
        "    uni_set = set(uni_filenames)\n",
        "\n",
        "    common_filenames = orig_set.intersection(uni_set)\n",
        "\n",
        "    print(f\"In {len(common_filenames)} images, both eyes were detected. Copy files to the folder 'dataset_dlib_detected'.\")\n",
        "\n",
        "    for filename in tqdm(common_filenames, desc=\"Processing Images\"):\n",
        "        orig_file_path = os.path.join(orig_folder, filename + \".JPG\")\n",
        "        uni_file_path = os.path.join(uni_folder, filename + \"_R.JPG\")  # \"R\"を指定していますが、\"L\"の場合もあるかもしれません\n",
        "        output_file_path = os.path.join(output_folder, filename + \".JPG\")  # 拡張子を.JPGに変更\n",
        "\n",
        "\n",
        "        print(f\"output_file_path: {output_file_path}\")\n",
        "\n",
        "        # try:\n",
        "        # ①の画像を読み込み\n",
        "        orig_image = Image.open(orig_file_path)\n",
        "        # 一辺512pxの黒塗りletterboxに変換\n",
        "        new_image = letterbox_image(orig_image, (512, 512))\n",
        "        # 変換後の画像を保存\n",
        "        new_image.save(output_file_path)\n",
        "        # except Exception as e:\n",
        "        #     print(f\"Error: Failed to process image '{orig_file_path}' or save '{output_file_path}'. Skipping.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JsWZBevoSmhG",
        "outputId": "cb3a18f2-c167-4b09-b8c0-91f096e7c377"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "output_file_path: /content/drive/MyDrive/Deep_learning/Olympia_dataset/dataset_uni_for_YOLOv8/dataset_dlib_detected/864.JPG\n",
            "output_file_path: /content/drive/MyDrive/Deep_learning/Olympia_dataset/dataset_uni_for_YOLOv8/dataset_dlib_detected/915.JPG\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Images:  95%|█████████▌| 912/958 [03:23<00:08,  5.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "output_file_path: /content/drive/MyDrive/Deep_learning/Olympia_dataset/dataset_uni_for_YOLOv8/dataset_dlib_detected/111.JPG\n",
            "output_file_path: /content/drive/MyDrive/Deep_learning/Olympia_dataset/dataset_uni_for_YOLOv8/dataset_dlib_detected/713.JPG\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Images:  95%|█████████▌| 914/958 [03:23<00:08,  5.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "output_file_path: /content/drive/MyDrive/Deep_learning/Olympia_dataset/dataset_uni_for_YOLOv8/dataset_dlib_detected/791.JPG\n",
            "output_file_path: /content/drive/MyDrive/Deep_learning/Olympia_dataset/dataset_uni_for_YOLOv8/dataset_dlib_detected/151.JPG\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Images:  96%|█████████▌| 916/958 [03:23<00:08,  5.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "output_file_path: /content/drive/MyDrive/Deep_learning/Olympia_dataset/dataset_uni_for_YOLOv8/dataset_dlib_detected/769.JPG\n",
            "output_file_path: /content/drive/MyDrive/Deep_learning/Olympia_dataset/dataset_uni_for_YOLOv8/dataset_dlib_detected/539.JPG\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Images:  96%|█████████▌| 918/958 [03:24<00:07,  5.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "output_file_path: /content/drive/MyDrive/Deep_learning/Olympia_dataset/dataset_uni_for_YOLOv8/dataset_dlib_detected/1004.JPG\n",
            "output_file_path: /content/drive/MyDrive/Deep_learning/Olympia_dataset/dataset_uni_for_YOLOv8/dataset_dlib_detected/776.JPG\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Images:  96%|█████████▌| 920/958 [03:24<00:07,  5.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "output_file_path: /content/drive/MyDrive/Deep_learning/Olympia_dataset/dataset_uni_for_YOLOv8/dataset_dlib_detected/533.JPG\n",
            "output_file_path: /content/drive/MyDrive/Deep_learning/Olympia_dataset/dataset_uni_for_YOLOv8/dataset_dlib_detected/940.JPG\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Images:  96%|█████████▌| 922/958 [03:25<00:06,  5.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "output_file_path: /content/drive/MyDrive/Deep_learning/Olympia_dataset/dataset_uni_for_YOLOv8/dataset_dlib_detected/873.JPG\n",
            "output_file_path: /content/drive/MyDrive/Deep_learning/Olympia_dataset/dataset_uni_for_YOLOv8/dataset_dlib_detected/7.JPG\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Images:  96%|█████████▋| 924/958 [03:25<00:06,  5.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "output_file_path: /content/drive/MyDrive/Deep_learning/Olympia_dataset/dataset_uni_for_YOLOv8/dataset_dlib_detected/46.JPG\n",
            "output_file_path: /content/drive/MyDrive/Deep_learning/Olympia_dataset/dataset_uni_for_YOLOv8/dataset_dlib_detected/656.JPG\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Images:  97%|█████████▋| 926/958 [03:25<00:06,  5.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "output_file_path: /content/drive/MyDrive/Deep_learning/Olympia_dataset/dataset_uni_for_YOLOv8/dataset_dlib_detected/846.JPG\n",
            "output_file_path: /content/drive/MyDrive/Deep_learning/Olympia_dataset/dataset_uni_for_YOLOv8/dataset_dlib_detected/241.JPG\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num = os.listdir(\"/content/drive/MyDrive/Deep_learning/Olympia_dataset/dataset_uni_for_YOLOv8/dataset_dlib_detected\")\n",
        "print(len(num))"
      ],
      "metadata": {
        "id": "BgphB4aDYNx_",
        "outputId": "d109e5b2-7bd7-4e54-a5e8-4b0da440cef8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "959\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**YOLOv8 annotations**"
      ],
      "metadata": {
        "id": "FdvZB6GrKCe_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#親フォルダ\n",
        "parent_dir = '/content/drive/MyDrive/Deep_learning/Olympia_dataset/dataset_uni_for_YOLOv8'\n",
        "\n",
        "#元画像フォルダ\n",
        "dataset_dir = '/content/drive/MyDrive/Deep_learning/Olympia_dataset/dataset'\n",
        "\n",
        "#元画像をコピー\n",
        "orig_dir = f\"{parent_dir}/dataset_orig\"\n",
        "\n",
        "#切りぬいた画像を保存するフォルダ\n",
        "out_dir = f\"{parent_dir}/dataset_uni\"\n",
        "\n",
        "#CSVファイルのフォルダ\n",
        "csv_path = f\"{parent_dir}/dataset_uni_for_YOLO8_modified.csv\""
      ],
      "metadata": {
        "id": "t3x7BL3UKGc6"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CSVファイルを読み込んでDataFrameに格納\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# DataFrameの内容を表示\n",
        "df"
      ],
      "metadata": {
        "id": "EXDkoZoVKuwW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(df)"
      ],
      "metadata": {
        "id": "H8EFFexjYg6U",
        "outputId": "604b0074-f5a2-4816-ba29-dd05029c4f92",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1925"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "def xywh_to_yolo(class_label, img_width, img_height, x, y, w, h):\n",
        "    x_center = x / img_width\n",
        "    y_center = y / img_height\n",
        "    width = w / img_width\n",
        "    height = h / img_height\n",
        "\n",
        "    return f\"{class_label} {x_center} {y_center} {width} {height}\"\n",
        "\n",
        "def create_yolo_txt(df):\n",
        "    grouped_data = df.groupby('id')\n",
        "\n",
        "    for group_id, group_df in grouped_data:\n",
        "        txt_file_path = os.path.join(os.path.dirname(group_df.iloc[0]['img_path']), f\"{group_id}.txt\")\n",
        "\n",
        "        with open(txt_file_path, 'w') as txt_file:\n",
        "            for _, row in group_df.iterrows():\n",
        "                img_path = row['img_path']\n",
        "                class_label = row['side R/L']\n",
        "                x, y, w, h = row['ex'], row['ey'], row['ew'], row['eh']\n",
        "\n",
        "                try:\n",
        "                    img = Image.open(img_path)\n",
        "                    img_width, img_height = img.size\n",
        "                except Exception as e:\n",
        "                    print(f\"Error: Failed to open '{img_path}' or get image dimensions. Skipping annotation.\")\n",
        "                    continue\n",
        "\n",
        "                # YOLO形式に変換\n",
        "                yolo_annotation = xywh_to_yolo(class_label, img_width, img_height, x, y, w, h)\n",
        "\n",
        "                # ファイルに書き込み\n",
        "                yolo_annotation += '\\n'  # 改行を追加\n",
        "                txt_file.write(yolo_annotation)        # ファイル内容を参照する\n",
        "\n",
        "        with open(txt_file_path, 'r') as txt_file_read:\n",
        "            file_contents = txt_file_read.read()\n",
        "            print(f\"Contents of '{txt_file_path}':\\n{file_contents}\")\n",
        "\n",
        "# YOLO形式のテキストファイルを作成して保存\n",
        "df_sample = df[0:6]\n",
        "create_yolo_txt(df_sample)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjbhluZHLyQJ",
        "outputId": "455304d4-fe49-4246-ebaa-3bc38f0bdcb0"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Contents of '/content/drive/MyDrive/Deep_learning/Olympia_dataset/dataset_uni_for_YOLOv8/dataset_orig/19.txt':\n",
            "R 0.06828703703703703 0.3628472222222222 0.26851851851851855 0.4027777777777778\n",
            "L 0.6111111111111112 0.3576388888888889 0.27314814814814814 0.4097222222222222\n",
            "\n",
            "Contents of '/content/drive/MyDrive/Deep_learning/Olympia_dataset/dataset_uni_for_YOLOv8/dataset_orig/20.txt':\n",
            "L 0.6057098765432098 0.3287037037037037 0.314429012345679 0.47164351851851855\n",
            "R 0.05864197530864197 0.3246527777777778 0.3028549382716049 0.4542824074074074\n",
            "\n",
            "Contents of '/content/drive/MyDrive/Deep_learning/Olympia_dataset/dataset_uni_for_YOLOv8/dataset_orig/21.txt':\n",
            "L 0.6311728395061729 0.35300925925925924 0.29205246913580246 0.4380787037037037\n",
            "R 0.08449074074074074 0.3628472222222222 0.2789351851851852 0.4184027777777778\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**YOLOv8 interference**"
      ],
      "metadata": {
        "id": "ySmQamVspQKC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOLOv8 setup\n",
        "%pip install ultralytics\n",
        "import ultralytics\n",
        "ultralytics.checks()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uh0dYAFu3vjY",
        "outputId": "16186673-1b00-47e0-9db4-814c2374da98"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ultralytics YOLOv8.0.142 🚀 Python-3.10.6 torch-2.0.1+cu118 CPU (Intel Xeon 2.20GHz)\n",
            "Setup complete ✅ (2 CPUs, 12.7 GB RAM, 24.3/225.8 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget /content https://pds.exblog.jp/logo/1/197001/01/18/b043001820221113221721.jpg\n",
        "!wget /content https://plugins-media.makeupar.com/smb/blog/post/2023-06-15/37011ea9-289b-4700-9e61-6a1429128ae6.jpg\n",
        "!wget /content https://www.city.gosen.lg.jp/material/images/group/5/chugatasu.JPG\n",
        "img_path = [\"/content/b043001820221113221721.jpg\", \"37011ea9-289b-4700-9e61-6a1429128ae6.jpg\", \"chugatasu.JPG\"]"
      ],
      "metadata": {
        "id": "GZ1Pi39p4D2I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from ultralytics import YOLO\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from IPython.display import Image as DisplayImage\n",
        "from IPython.display import display\n",
        "import cv2\n",
        "# 事前学習済みのモデルを読み込み(detectionモデルを使用)\n",
        "model = YOLO('yolov8n.pt')\n",
        "# predictモードを実行 (結果だけ欲しいので、project・name・exist_okはなくてもOK)\n",
        "results = model.predict(source=img_path[2])\n",
        "# Resultsオブジェクトから描画に必要な情報を取得\n",
        "coordinate_bbox = results[0].boxes.xyxy #bbox\n",
        "classes=results[0].boxes.cls # 検出クラス\n",
        "classes_map = results[0].names # クラス番号と名称\n",
        "# 画像の読み込み\n",
        "img = Image.open(results[0].path)\n",
        "# 色の指定 (クラスごとにランダムに色を選択する場合使う)\n",
        "# colors = ['red', 'green', 'blue', 'yellow', 'cyan', 'magenta', 'olive', 'purple']\n",
        "# colors = [(255, 0, 0), (0, 255, 0), (0, 0, 255), (255, 255, 0), (0, 255, 255), (255, 0, 255), (128, 128, 0), (128, 0, 128)]\n",
        "# 描画コンテントの取得\n",
        "draw = ImageDraw.Draw(img)\n",
        "\"\"\"\n",
        "フォントの設定。Macだと/System/Library/Fontsに色々あるのでここから選んだ。\n",
        "bboxだけの描画であれば必要ない。必要ない場合はdraw.text(font=font)のfont部分を消す。\n",
        "エラーが出る場合はフォントファイルへのフルパス(/System/Library/Fonts/ヒラギノ丸ゴ ProN W4.ttc)で設定してあげる\n",
        "\"\"\"\n",
        "font = ImageFont.truetype('/usr/share/fonts/truetype/liberation/LiberationSans-Regular.ttf', 4000)\n",
        "# バウンディングボックスの描画\n",
        "i=1\n",
        "for bbox, cls in zip(coordinate_bbox, classes):\n",
        "    x1, y1, x2, y2 = map(int, bbox)\n",
        "    #color = colors[int(cls) % len(colors)] 今回は色を直接指定するので使わない\n",
        "    color=(255,0,0) # red\n",
        "    # bboxの描画\n",
        "    draw.rectangle([x1, y1, x2, y2], outline=color, width=5)\n",
        "    cls_text = classes_map.get(int(cls))\n",
        "    # 検出クラス名の描画\n",
        "    draw.text((x1, y1 - 50), cls_text+\"#\"+str(i), fill=\"orange\")\n",
        "    print(f\"class: {cls_text}\")\n",
        "    print(f\"x1: {x1}, y1: {y1}, x2: {x2}, y2: {y2}\")\n",
        "    i += 1\n",
        "# 画像のリサイズ (必要であれば)\n",
        "#img = img.resize((640,640))\n",
        "# 出力先フォルダの作成。model.predictで作成させてもOK。\n",
        "directories = ['/Users/hinomaruc/Desktop/blog/dataset/yolov8/runs/mypredict']\n",
        "for directory in directories:\n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "# 画像の保存 (存在しないフォルダだとFileNotFoundErrorになるので注意)\n",
        "img.save('/Users/hinomaruc/Desktop/blog/dataset/yolov8/runs/mypredict/sample_bbox.png')\n",
        "# 画像の表示\n",
        "display(DisplayImage(filename='/Users/hinomaruc/Desktop/blog/dataset/yolov8/runs/mypredict/sample_bbox.png'))"
      ],
      "metadata": {
        "id": "2zTw01xTZlu2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os\n",
        "from ultralytics import YOLO\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from IPython.display import Image as DisplayImage\n",
        "from IPython.display import display\n",
        "\n",
        "# 事前学習済みのモデルを読み込み(detectionモデルを使用)\n",
        "model = YOLO('yolov8n.pt')\n",
        "# predictモードを実行 (結果だけ欲しいので、project・name・exist_okはなくてもOK)\n",
        "results = model.predict(source=img_path[1])\n",
        "# Resultsオブジェクトから描画に必要な情報を取得\n",
        "coordinate_bbox = results[0].boxes.xyxy #bbox\n",
        "classes=results[0].boxes.cls # 検出クラス\n",
        "classes_map = results[0].names # クラス番号と名称\n",
        "\n",
        "# Open the image file\n",
        "img_cv2 = cv2.imread(results[0].path)\n",
        "\n",
        "# Set the font scale and thickness\n",
        "font_scale = 3\n",
        "font_thickness = 2\n",
        "\n",
        "# Loop through each bounding box\n",
        "i=1\n",
        "for bbox, cls in zip(coordinate_bbox, classes):\n",
        "    print(bbox)\n",
        "\n",
        "    x1, y1, x2, y2 = map(int, bbox)\n",
        "    color=(0,0,255) # red\n",
        "    # Draw the bounding box\n",
        "    cv2.rectangle(img_cv2, (x1, y1), (x2, y2), color, 5)\n",
        "    cls_text = classes_map.get(int(cls))\n",
        "    # Put the class label text\n",
        "    cv2.putText(img_cv2, cls_text+\"#\"+str(i), (x1, y1 - 50), cv2.FONT_HERSHEY_SIMPLEX, font_scale, color, font_thickness)\n",
        "    i += 1\n",
        "\n",
        "# Save the image\n",
        "cv2.imwrite('/Users/hinomaruc/Desktop/blog/dataset/yolov8/runs/mypredict/sample_bbox.png', img_cv2)\n",
        "\n",
        "\n",
        "#plt.imshow(cv2.cvtColor(img_cv2, cv2.COLOR_BGR2RGB))\n",
        "# Convert the color from BGR to RGB\n",
        "img_rgb = cv2.cvtColor(img_cv2, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Use matplotlib to display the image\n",
        "plt.imshow(img_rgb)\n",
        "\n",
        "# Show the axes\n",
        "plt.axis('on')\n",
        "\n",
        "# Show the image\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "aTBwFQPBet5H"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
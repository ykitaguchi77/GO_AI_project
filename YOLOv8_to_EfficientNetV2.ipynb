{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNz/7vI00kcDf3Ww1WEo3KD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykitaguchi77/GO_AI_project/blob/main/YOLOv8_to_EfficientNetV2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**YOLOv8 to EfficientNetv2 pipeline**"
      ],
      "metadata": {
        "id": "w2bPHz9wew6n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Olympia datasetã‹ã‚‰ç›®ã‚’åˆ‡ã‚ŠæŠœãï¼ˆYOLOv8nï¼‰**\n",
        "#**åˆ‡ã‚ŠæŠœã„ãŸç›®ã‚’EfficientNetV2ã§è§£æã™ã‚‹**"
      ],
      "metadata": {
        "id": "LXWb3YtIFX1p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Olympia dataset\n",
        "Dlibã§ç›®ãŒ2ã¤æ¤œå‡ºã•ã‚Œã‚‹ã‚‚ã®ã‚’æŠœãå‡ºã™\n",
        "YOLOv8ã‚’ç”¨ã„ã¦å·¦å³ã¨ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã‚’èªè­˜ã•ã›ã‚‹\n",
        "åˆ‡ã‚ŠæŠœã„ãŸãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹å†…ã®ç”»åƒã«ã¤ã„ã¦ã€EfficientNetv2ã‚’ç”¨ã„ã¦çœ¼çƒçªå‡ºåº¦ã€MRD-1ã€MRD-2ã‚’å›å¸°ã•ã›ã‚‹\n",
        "ã‚¹ãƒãƒ›ã«å®Ÿè£…\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "UnyBedKNbfS3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7MdRVDhFJmO",
        "outputId": "87e7818b-a018-45e0-c80a-e8b9bdb7434a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import shutil\n",
        "import copy\n",
        "import pandas as pd\n",
        "import csv\n",
        "from tqdm import tqdm\n",
        "\n",
        "import glob\n",
        "import random\n",
        "from PIL import Image\n",
        "%matplotlib inline\n",
        "\n",
        "#ã‚µãƒãƒ¼ãƒˆãƒ‘ãƒƒãƒã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "\n",
        "plt.ion()   # interactive mode\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#è¦ªãƒ•ã‚©ãƒ«ãƒ€\n",
        "parent_dir = '/content/drive/MyDrive/Deep_learning/Olympia_dataset/dataset_uni_for_YOLOv8'\n",
        "\n",
        "#å…ƒç”»åƒãƒ•ã‚©ãƒ«ãƒ€\n",
        "dataset_dir = '/content/drive/MyDrive/Deep_learning/Olympia_dataset/dataset'\n",
        "\n",
        "#å…ƒç”»åƒã‚’ã‚³ãƒ”ãƒ¼\n",
        "orig_dir = f\"{parent_dir}/dataset_orig\"\n",
        "\n",
        "#åˆ‡ã‚Šã¬ã„ãŸç”»åƒã‚’ä¿å­˜ã™ã‚‹ãƒ•ã‚©ãƒ«ãƒ€\n",
        "out_dir = f\"{parent_dir}/dataset_uni\"\n",
        "\n",
        "#CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ•ã‚©ãƒ«ãƒ€\n",
        "csv_path = f\"{parent_dir}/dataset_uni_for_YOLO8.csv\""
      ],
      "metadata": {
        "id": "_DI1wc0eF5uR"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# parent_dirãŒã‚ã‚Œã°å‰Šé™¤ã™ã‚‹\n",
        "if os.path.exists(parent_dir):\n",
        "    shutil.rmtree(parent_dir)\n",
        "\n",
        "# æ–°ã—ãparent_dirã‚’ä½œæˆã™ã‚‹\n",
        "os.makedirs(parent_dir)\n",
        "\n",
        "# orig_dir, out_dirã‚’æ–°è¦ã«ä½œæˆã™ã‚‹\n",
        "os.makedirs(orig_dir)\n",
        "os.makedirs(out_dir)\n",
        "\n",
        "# orig_dirã«dataset_dirç›´ä¸‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã™ã¹ã¦ã‚³ãƒ”ãƒ¼ã™ã‚‹\n",
        "file_list = os.listdir(dataset_dir)\n",
        "for filename in tqdm(file_list, desc=\"Copying files\", unit=\"file\"):\n",
        "    src_path = os.path.join(dataset_dir, filename)\n",
        "    dst_path = os.path.join(orig_dir, filename)\n",
        "    shutil.copy(src_path, dst_path)\n",
        "\n",
        "print(\"å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸã€‚\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2ZGZkPOK84g",
        "outputId": "0f2558fd-b5d6-4236-f0e3-1856972b7051"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Copying files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1016/1016 [00:53<00:00, 19.03file/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸã€‚\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**HaarCascadeã‚’ç”¨ã„ã¦ç›®ã‚’æ¤œå‡º**"
      ],
      "metadata": {
        "id": "6Y6OC0UoMOZv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ã‚«ã‚¹ã‚±ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹\n",
        "eye_cascade_path = '/content/drive/My Drive/Deep_learning/haarcascade_eye.xml'\n",
        "\n",
        "# ã‚«ã‚¹ã‚±ãƒ¼ãƒ‰åˆ†é¡å™¨ã®ç‰¹å¾´é‡å–å¾—\n",
        "eye_cascade = cv2.CascadeClassifier(eye_cascade_path)\n"
      ],
      "metadata": {
        "id": "f2rM0ZbTMN50"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**ç›®ãŒ2ã¤ä»¥ä¸Šæ¤œå‡ºã•ã‚ŒãŸã‚‚ã®ã‚’æŠœãå‡ºã™**"
      ],
      "metadata": {
        "id": "FWLibTiZc1Xw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(csv_path, 'w', newline='') as f:\n",
        "        #fieldnames = ['Number', 'Folder', 'FileName']\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow(['id','img_path', 'side R/L', 'ex', 'ey', 'ew', 'eh'])  #header\n",
        "\n",
        "        files = os.listdir(orig_dir)\n",
        "\n",
        "        k=0\n",
        "        for file in files:  #ãƒ•ã‚©ãƒ«ãƒ€æ•°ã®åˆ†ã ã‘\n",
        "              file_path = f\"{orig_dir}/{file}\"\n",
        "              id = os.path.splitext(os.path.basename(file_path))[0]\n",
        "\n",
        "              img = cv2.imread(file_path)\n",
        "              img2 = img.copy()\n",
        "\n",
        "              # ç”»åƒã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«åŒ–\n",
        "              grayscale_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "              #300pixä»¥ä¸Šã®ã‚‚ã®ã§ç›®ã«è¦‹ãˆã‚‹ã‚‚ã®ã‚’æŠ½å‡º\n",
        "              eye_list = eye_cascade.detectMultiScale(grayscale_img, minSize=(300, 300))\n",
        "\n",
        "              # çœ¼æ¤œå‡ºåˆ¤å®š\n",
        "              if len(eye_list) >= 1:\n",
        "                  print('ç›®ãŒ' + str(len(eye_list)) +'å€‹æ¤œå‡ºã•ã‚Œã¾ã—ãŸ')\n",
        "              else:\n",
        "                  print(\"eye detection error\")\n",
        "\n",
        "              #ç”»åƒã®åˆ‡ã‚ŠæŠœãã¨ä¿å­˜ï¼ˆ2å€‹ä»¥ä¸Šæ¤œå‡ºã®æ™‚ã«é™ã‚‹ï¼‰\n",
        "              if len(eye_list) >= 2:\n",
        "                  for (ex, ey, ew, eh) in eye_list:\n",
        "                      print(f\"img_width: {img2.shape[1]}\")\n",
        "                      print(\"[ex,ey] = %d,%d [ew,eh] = %d,%d\" %(ex, ey, ew, eh))\n",
        "                      cv2.rectangle(img2, (ex, ey), (ex + ew, ey + eh), (0, 255, 0), 2)\n",
        "                      #img_cropped = img[int(ey-0.1*eh): int(ey+1.1*eh), int(ex-0.1*ew): int(ex+1.1*ew)] #æœ¬æ¥ã®åˆ‡ã‚ŠæŠœãã‚ˆã‚Šå¹…ã®0.1å€ãšã¤æ°´å¢—ã—ã™ã‚‹\n",
        "                      img_cropped = img[int(ey): int(ey+eh), int(ex): int(ex+ew)]\n",
        "\n",
        "\n",
        "                      if ex+eh*0.5 <= img2.shape[1]/2:\n",
        "                          side = \"R\" #æ¨ªå¹…ã®åŠåˆ†ã‚ˆã‚Šå·¦ã«ã‚ã‚‹ã®ã¯å³çœ¼\n",
        "                      else:\n",
        "                          side = \"L\" #æ¨ªå¹…ã®åŠåˆ†ã‚ˆã‚Šã‚ˆã‚Šå³ã«ã‚ã‚‹ã®ã¯å·¦çœ¼\n",
        "\n",
        "                      print(f\"side: {side}\")\n",
        "                      print(\"\")\n",
        "\n",
        "                      cv2.imwrite(f\"{out_dir}/{id}_{side}.png\", img_cropped)\n",
        "\n",
        "                      #å¯¾å¿œè¡¨ã®ä½œæˆ\n",
        "                      writer.writerow([id, file_path, side, ex, ey, ew, eh])\n",
        "                  else:\n",
        "                      pass\n"
      ],
      "metadata": {
        "id": "pnVFMJJVMW8n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**ã“ã“ã§ã€ç›®ä»¥å¤–ãŒèª¤æ¤œå‡ºã•ã‚Œã¦ã„ã‚‹ã‚‚ã®ã‚’æ‰‹å‹•ã§æŠœãå‡ºã—ã¦å‰Šé™¤ã™ã‚‹**"
      ],
      "metadata": {
        "id": "tm4HsJszc9VX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "ä¸é©åˆ‡ãªç”»åƒãŒã‚ã‚Œã°ã€å·¦å³ã¾ã¨ã‚ã¦æ¶ˆã™\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "v3abWZGGe9sA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#CSVã®ãƒªã‚¹ãƒˆã¨ç”»åƒãƒ•ã‚©ãƒ«ãƒ€ã‚’è¦‹æ¯”ã¹ã¦ã€æ¶ˆã—ãŸç”»åƒã‚’åˆ¤åˆ¥ã€‚CSVã‚’ä¿®æ­£ã™ã‚‹ã€‚\n",
        "import pandas as pd\n",
        "\n",
        "# Load the CSV\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# Get a list of unique ids\n",
        "csv_id_list = df['id'].unique().tolist()\n",
        "\n",
        "print(f\"csv_id_list: {csv_id_list}\")\n",
        "\n",
        "\n",
        "# Construct the output directory path\n",
        "out_dir = f\"{parent_dir}/dataset_uni\"\n",
        "\n",
        "# Get a list of all image file names in the directory\n",
        "image_file_names = os.listdir(out_dir)\n",
        "\n",
        "# Split each file name at \"_\" and take the first part, then make sure the list is unique\n",
        "image_id_list = list(set([int(name.split('_')[0]) for name in image_file_names]))\n",
        "print(f\"image_id_list: {image_id_list}\")\n",
        "\n",
        "# Find the ids that are in the CSV list but not in the image file list\n",
        "missing_ids = [id for id in csv_id_list if id not in image_id_list]\n",
        "print(f\"missing_ids: {missing_ids}\")\n",
        "\n",
        "\n",
        "\n",
        "# Remove the rows with ids in missing_ids\n",
        "df = df[~df['id'].isin(missing_ids)]\n",
        "\n",
        "# Save the dataframe back to a CSV\n",
        "df.to_csv(f\"{parent_dir}/dataset_uni_for_YOLO8_modified.csv\", index=False)"
      ],
      "metadata": {
        "id": "aGVqU2n9i3wR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2760df72-8dd9-47fe-f6a7-5887b189b2ba"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "csv_id_list: [19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 41, 45, 47, 46, 48, 49, 50, 52, 53, 54, 55, 56, 57, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 89, 88, 90, 91, 92, 93, 94, 95, 96, 97, 936, 99, 101, 100, 102, 103, 104, 105, 106, 107, 109, 112, 110, 111, 113, 115, 116, 937, 117, 118, 120, 121, 124, 123, 125, 122, 938, 126, 127, 128, 129, 939, 131, 133, 132, 134, 135, 137, 136, 940, 139, 138, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 156, 155, 941, 157, 158, 159, 160, 162, 161, 945, 163, 164, 165, 166, 167, 168, 169, 946, 170, 947, 171, 172, 173, 174, 175, 176, 177, 178, 948, 179, 949, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 200, 199, 201, 950, 202, 203, 951, 204, 205, 206, 208, 207, 210, 209, 212, 213, 214, 215, 952, 216, 217, 953, 219, 954, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 955, 234, 235, 236, 237, 239, 240, 241, 243, 242, 244, 245, 246, 247, 248, 249, 250, 957, 251, 252, 253, 254, 958, 255, 256, 959, 257, 258, 960, 259, 260, 261, 262, 263, 264, 266, 265, 267, 961, 268, 269, 270, 271, 272, 273, 274, 275, 276, 962, 278, 279, 280, 963, 282, 284, 283, 285, 287, 288, 964, 289, 290, 292, 965, 293, 294, 295, 296, 297, 298, 299, 300, 301, 303, 302, 304, 305, 306, 307, 966, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 322, 321, 323, 324, 325, 326, 328, 327, 967, 329, 330, 331, 332, 968, 333, 334, 335, 336, 337, 969, 338, 339, 340, 342, 343, 344, 970, 971, 345, 346, 347, 349, 350, 935, 351, 972, 353, 352, 354, 356, 357, 358, 360, 361, 362, 973, 363, 364, 974, 365, 367, 368, 369, 975, 371, 372, 373, 375, 374, 376, 377, 378, 379, 380, 381, 382, 383, 384, 976, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 977, 978, 399, 979, 400, 402, 403, 405, 404, 406, 407, 408, 410, 409, 980, 411, 981, 412, 413, 414, 416, 415, 417, 418, 419, 420, 421, 422, 982, 983, 425, 426, 428, 427, 429, 430, 431, 432, 434, 433, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 984, 445, 446, 449, 448, 447, 450, 451, 452, 453, 455, 454, 456, 457, 458, 459, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 488, 490, 489, 491, 987, 988, 492, 493, 494, 495, 496, 498, 499, 500, 989, 990, 501, 502, 503, 504, 505, 506, 507, 509, 508, 992, 993, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 528, 527, 529, 530, 994, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 995, 546, 996, 547, 548, 549, 551, 552, 997, 553, 554, 998, 556, 555, 557, 558, 559, 560, 561, 999, 562, 563, 564, 565, 566, 567, 1000, 568, 569, 570, 1001, 571, 572, 573, 1002, 574, 575, 1003, 576, 578, 579, 580, 581, 583, 582, 584, 585, 587, 588, 589, 590, 592, 593, 594, 595, 596, 597, 598, 599, 601, 600, 602, 1004, 603, 604, 605, 606, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 619, 618, 621, 622, 623, 625, 626, 627, 628, 629, 630, 631, 633, 635, 634, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 658, 657, 659, 660, 661, 1006, 662, 663, 2, 664, 665, 666, 667, 669, 670, 671, 673, 674, 675, 676, 677, 1007, 678, 679, 1008, 682, 683, 684, 688, 687, 689, 690, 691, 692, 693, 694, 695, 697, 698, 699, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 1, 714, 715, 716, 717, 718, 719, 1009, 720, 986, 1010, 1011, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 742, 743, 744, 745, 746, 748, 747, 750, 749, 751, 752, 753, 754, 755, 757, 758, 759, 760, 761, 1012, 762, 763, 764, 766, 765, 1014, 767, 768, 770, 769, 771, 772, 1017, 773, 774, 1018, 775, 776, 778, 777, 779, 1016, 780, 781, 782, 1019, 783, 784, 785, 787, 786, 788, 789, 791, 790, 792, 793, 794, 795, 796, 798, 799, 797, 800, 801, 802, 803, 804, 805, 806, 807, 808, 1020, 809, 810, 811, 812, 813, 1021, 814, 815, 816, 818, 819, 820, 821, 822, 823, 825, 824, 826, 827, 828, 829, 1022, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 852, 853, 854, 855, 856, 857, 858, 859, 1024, 1025, 861, 862, 864, 865, 866, 867, 1026, 1027, 1028, 868, 870, 869, 1029, 871, 872, 874, 873, 875, 876, 877, 878, 879, 1031, 883, 884, 886, 887, 885, 888, 889, 890, 891, 892, 894, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 918, 919, 917, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]\n",
            "image_id_list: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 99, 100, 101, 102, 103, 104, 105, 106, 107, 109, 110, 111, 112, 113, 115, 116, 117, 118, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 212, 213, 214, 215, 216, 217, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 278, 279, 280, 282, 283, 284, 285, 287, 288, 289, 290, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 342, 343, 344, 345, 346, 347, 349, 350, 351, 352, 353, 354, 356, 357, 358, 360, 361, 362, 363, 364, 365, 367, 368, 369, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 488, 489, 490, 491, 492, 493, 494, 495, 496, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 546, 547, 548, 549, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 578, 579, 580, 581, 582, 583, 584, 585, 587, 588, 589, 590, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 621, 622, 623, 625, 626, 627, 628, 629, 630, 631, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 669, 670, 671, 673, 674, 675, 676, 677, 678, 679, 682, 683, 684, 687, 688, 689, 690, 691, 692, 693, 694, 695, 697, 698, 699, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 852, 853, 854, 855, 856, 857, 858, 859, 861, 862, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 894, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 986, 987, 988, 989, 990, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1014, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1024, 1025, 1026, 1027, 1028, 1029, 1031]\n",
            "missing_ids: [146]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "â‘ \"/content/drive/MyDrive/Deep_learning/Olympia_dataset/dataset_uni_for_YOLOv8/dataset_orig\"ã®ãƒ•ã‚¡ã‚¤ãƒ«åï¼ˆ1.jpgã¨ã™ã‚‹ã¨1ï¼‰ã¨ã€â‘¡\"/content/drive/MyDrive/Deep_learning/Olympia_dataset/dataset_uni_for_YOLOv8/dataset_uni\"ã®ã‚¢ãƒ³ãƒ€ãƒ¼ãƒãƒ¼ã®æ‰‹å‰ï¼ˆ1_R.jpgã¨ã™ã‚‹ã¨1)ã‚’è¦‹æ¯”ã¹ã‚‹\n",
        "\n",
        "\"/content/drive/MyDrive/Deep_learning/Olympia_dataset/dataset_uni_for_YOLOv8/dataset_dlib_detected\"ã¨ã„ã†ãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆ\n",
        "â‘ ã¨â‘¡ã§ä¸€è‡´ã™ã‚‹ã‚‚ã®ã«é–¢ã—ã¦ã€â‘ ã®ç”»åƒï¼ˆã‚³ãƒ”ãƒ¼ï¼‰ã‚’ä¸€è¾º512pixã®é»’å¡—ã‚Šletterboxã«ã—ã¦å¤‰æ›ã—ã€æ–°ã—ãä½œæˆã—ãŸãƒ•ã‚©ãƒ«ãƒ€ã«ä¿å­˜ã™ã‚‹\n",
        "\"\"\"\n",
        "\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "def letterbox_image(image, size):\n",
        "    \"\"\"\n",
        "    ç”»åƒã‚’æŒ‡å®šã—ãŸã‚µã‚¤ã‚ºã®é»’å¡—ã‚Šletterboxã«å¤‰æ›ã™ã‚‹é–¢æ•°\n",
        "    :param image: å¤‰æ›ã™ã‚‹ç”»åƒï¼ˆPIL Imageï¼‰\n",
        "    :param size: å¤‰æ›å¾Œã®ã‚µã‚¤ã‚ºï¼ˆå¹…, é«˜ã•ï¼‰ã®ã‚¿ãƒ—ãƒ«\n",
        "    :return: å¤‰æ›å¾Œã®ç”»åƒï¼ˆPIL Imageï¼‰\n",
        "    \"\"\"\n",
        "    new_width, new_height = size\n",
        "    old_width, old_height = image.size\n",
        "    ratio = min(new_width / old_width, new_height / old_height)\n",
        "    new_width = int(old_width * ratio)\n",
        "    new_height = int(old_height * ratio)\n",
        "    resized_image = image.resize((new_width, new_height), Image.LANCZOS)\n",
        "    boxed_image = Image.new(\"RGB\", size, (0, 0, 0))\n",
        "    boxed_image.paste(resized_image, ((size[0] - new_width) // 2, (size[1] - new_height) // 2))\n",
        "    return boxed_image\n",
        "\n",
        "def main():\n",
        "    # ä¿å­˜å…ˆãƒ•ã‚©ãƒ«ãƒ€ã®ãƒ‘ã‚¹\n",
        "    output_folder = \"/content/drive/MyDrive/Deep_learning/Olympia_dataset/dataset_uni_for_YOLOv8/dataset_dlib_detected\"\n",
        "\n",
        "    # ãƒ•ã‚©ãƒ«ãƒ€ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ä½œæˆ\n",
        "    if os.path.exists(output_folder):\n",
        "        shutil.rmtree(output_folder)\n",
        "    os.makedirs(output_folder)\n",
        "\n",
        "    # â‘ ã®ãƒ•ã‚©ãƒ«ãƒ€å†…ã®ãƒ•ã‚¡ã‚¤ãƒ«åã‚’å–å¾—ã—ã¦ã€1.jpgã®ã‚ˆã†ãªå½¢å¼ã«å¤‰æ›\n",
        "    orig_folder = \"/content/drive/MyDrive/Deep_learning/Olympia_dataset/dataset_uni_for_YOLOv8/dataset_orig\"\n",
        "    orig_files = os.listdir(orig_folder)\n",
        "    orig_filenames = [os.path.splitext(filename)[0] for filename in orig_files]\n",
        "\n",
        "    # â‘¡ã®ãƒ•ã‚©ãƒ«ãƒ€å†…ã®ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰ã‚¢ãƒ³ãƒ€ãƒ¼ãƒãƒ¼ã®æ‰‹å‰ã‚’å–å¾—ã—ã¦ã€1_R.jpgã®ã‚ˆã†ãªå½¢å¼ã«å¤‰æ›\n",
        "    uni_folder = \"/content/drive/MyDrive/Deep_learning/Olympia_dataset/dataset_uni_for_YOLOv8/dataset_uni\"\n",
        "    uni_files = os.listdir(uni_folder)\n",
        "    uni_filenames = [filename.split(\"_\")[0] for filename in uni_files]\n",
        "\n",
        "    # â‘ ã¨â‘¡ã§ä¸€è‡´ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¢ã—ã¦ã€å‡¦ç†ã‚’å®Ÿè¡Œ\n",
        "    orig_set = set(orig_filenames)\n",
        "    uni_set = set(uni_filenames)\n",
        "\n",
        "    common_filenames = orig_set.intersection(uni_set)\n",
        "\n",
        "    print(f\"In {len(common_filenames)} images, both eyes were detected. Copy files to the folder 'dataset_dlib_detected'.\")\n",
        "\n",
        "    for filename in tqdm(common_filenames, desc=\"Processing Images\"):\n",
        "        orig_file_path = os.path.join(orig_folder, filename + \".JPG\")\n",
        "        uni_file_path = os.path.join(uni_folder, filename + \"_R.JPG\")  # \"R\"ã‚’æŒ‡å®šã—ã¦ã„ã¾ã™ãŒã€\"L\"ã®å ´åˆã‚‚ã‚ã‚‹ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“\n",
        "        output_file_path = os.path.join(output_folder, filename + \".JPG\")  # æ‹¡å¼µå­ã‚’.JPGã«å¤‰æ›´\n",
        "\n",
        "\n",
        "        print(f\"output_file_path: {output_file_path}\")\n",
        "\n",
        "        # try:\n",
        "        # â‘ ã®ç”»åƒã‚’èª­ã¿è¾¼ã¿\n",
        "        orig_image = Image.open(orig_file_path)\n",
        "        # ä¸€è¾º512pxã®é»’å¡—ã‚Šletterboxã«å¤‰æ›\n",
        "        new_image = letterbox_image(orig_image, (512, 512))\n",
        "        # å¤‰æ›å¾Œã®ç”»åƒã‚’ä¿å­˜\n",
        "        new_image.save(output_file_path)\n",
        "        # except Exception as e:\n",
        "        #     print(f\"Error: Failed to process image '{orig_file_path}' or save '{output_file_path}'. Skipping.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "JsWZBevoSmhG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num = os.listdir(\"/content/drive/MyDrive/Deep_learning/Olympia_dataset/dataset_uni_for_YOLOv8/dataset_dlib_detected\")\n",
        "print(len(num))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BgphB4aDYNx_",
        "outputId": "8368e7f2-c958-4ad4-b122-b514fa8572db"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "958\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**YOLOv8 annotations**"
      ],
      "metadata": {
        "id": "FdvZB6GrKCe_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#è¦ªãƒ•ã‚©ãƒ«ãƒ€\n",
        "parent_dir = '/content/drive/MyDrive/Deep_learning/Olympia_dataset/dataset_uni_for_YOLOv8'\n",
        "\n",
        "#å…ƒç”»åƒãƒ•ã‚©ãƒ«ãƒ€\n",
        "dataset_dir = '/content/drive/MyDrive/Deep_learning/Olympia_dataset/dataset'\n",
        "\n",
        "#å…ƒç”»åƒã‚’ã‚³ãƒ”ãƒ¼\n",
        "orig_dir = f\"{parent_dir}/dataset_orig\"\n",
        "\n",
        "#åˆ‡ã‚Šã¬ã„ãŸç”»åƒã‚’ä¿å­˜ã™ã‚‹ãƒ•ã‚©ãƒ«ãƒ€\n",
        "out_dir = f\"{parent_dir}/dataset_uni\"\n",
        "\n",
        "#CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ•ã‚©ãƒ«ãƒ€\n",
        "csv_path = f\"{parent_dir}/dataset_uni_for_YOLO8_modified.csv\""
      ],
      "metadata": {
        "id": "t3x7BL3UKGc6"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚“ã§DataFrameã«æ ¼ç´\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# DataFrameã®å†…å®¹ã‚’è¡¨ç¤º\n",
        "df"
      ],
      "metadata": {
        "id": "EXDkoZoVKuwW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8EFFexjYg6U",
        "outputId": "4c44e82c-be3d-49c0-9563-13e12251432d"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1922"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "def xywh_to_yolo(class_label, img_width, img_height, x, y, w, h):\n",
        "    x_center = x / img_width\n",
        "    y_center = y / img_height\n",
        "    width = w / img_width\n",
        "    height = h / img_height\n",
        "\n",
        "    return f\"{class_label} {x_center} {y_center} {width} {height}\"\n",
        "\n",
        "def create_yolo_txt(df):\n",
        "    grouped_data = df.groupby('id')\n",
        "\n",
        "    for group_id, group_df in grouped_data:\n",
        "        txt_file_path = os.path.join(os.path.dirname(group_df.iloc[0]['img_path']), f\"{group_id}.txt\")\n",
        "\n",
        "        with open(txt_file_path, 'w') as txt_file:\n",
        "            for _, row in group_df.iterrows():\n",
        "                img_path = row['img_path']\n",
        "                class_label = row['side R/L']\n",
        "                x, y, w, h = row['ex'], row['ey'], row['ew'], row['eh']\n",
        "\n",
        "                try:\n",
        "                    img = Image.open(img_path)\n",
        "                    img_width, img_height = img.size\n",
        "                except Exception as e:\n",
        "                    print(f\"Error: Failed to open '{img_path}' or get image dimensions. Skipping annotation.\")\n",
        "                    continue\n",
        "\n",
        "                # YOLOå½¢å¼ã«å¤‰æ›\n",
        "                yolo_annotation = xywh_to_yolo(class_label, img_width, img_height, x, y, w, h)\n",
        "\n",
        "                # ãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãè¾¼ã¿\n",
        "                yolo_annotation += '\\n'  # æ”¹è¡Œã‚’è¿½åŠ \n",
        "                txt_file.write(yolo_annotation)        # ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã‚’å‚ç…§ã™ã‚‹\n",
        "\n",
        "        with open(txt_file_path, 'r') as txt_file_read:\n",
        "            file_contents = txt_file_read.read()\n",
        "            print(f\"Contents of '{txt_file_path}':\\n{file_contents}\")\n",
        "\n",
        "# YOLOå½¢å¼ã®ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã¦ä¿å­˜\n",
        "df_sample = df[0:6]\n",
        "create_yolo_txt(df_sample)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjbhluZHLyQJ",
        "outputId": "455304d4-fe49-4246-ebaa-3bc38f0bdcb0"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Contents of '/content/drive/MyDrive/Deep_learning/Olympia_dataset/dataset_uni_for_YOLOv8/dataset_orig/19.txt':\n",
            "R 0.06828703703703703 0.3628472222222222 0.26851851851851855 0.4027777777777778\n",
            "L 0.6111111111111112 0.3576388888888889 0.27314814814814814 0.4097222222222222\n",
            "\n",
            "Contents of '/content/drive/MyDrive/Deep_learning/Olympia_dataset/dataset_uni_for_YOLOv8/dataset_orig/20.txt':\n",
            "L 0.6057098765432098 0.3287037037037037 0.314429012345679 0.47164351851851855\n",
            "R 0.05864197530864197 0.3246527777777778 0.3028549382716049 0.4542824074074074\n",
            "\n",
            "Contents of '/content/drive/MyDrive/Deep_learning/Olympia_dataset/dataset_uni_for_YOLOv8/dataset_orig/21.txt':\n",
            "L 0.6311728395061729 0.35300925925925924 0.29205246913580246 0.4380787037037037\n",
            "R 0.08449074074074074 0.3628472222222222 0.2789351851851852 0.4184027777777778\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**YOLOv8 interference**"
      ],
      "metadata": {
        "id": "ySmQamVspQKC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOLOv8 setup\n",
        "%pip install ultralytics\n",
        "import ultralytics\n",
        "ultralytics.checks()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uh0dYAFu3vjY",
        "outputId": "16186673-1b00-47e0-9db4-814c2374da98"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ultralytics YOLOv8.0.142 ğŸš€ Python-3.10.6 torch-2.0.1+cu118 CPU (Intel Xeon 2.20GHz)\n",
            "Setup complete âœ… (2 CPUs, 12.7 GB RAM, 24.3/225.8 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget /content https://pds.exblog.jp/logo/1/197001/01/18/b043001820221113221721.jpg\n",
        "!wget /content https://plugins-media.makeupar.com/smb/blog/post/2023-06-15/37011ea9-289b-4700-9e61-6a1429128ae6.jpg\n",
        "!wget /content https://www.city.gosen.lg.jp/material/images/group/5/chugatasu.JPG\n",
        "img_path = [\"/content/b043001820221113221721.jpg\", \"37011ea9-289b-4700-9e61-6a1429128ae6.jpg\", \"chugatasu.JPG\"]"
      ],
      "metadata": {
        "id": "GZ1Pi39p4D2I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from ultralytics import YOLO\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from IPython.display import Image as DisplayImage\n",
        "from IPython.display import display\n",
        "import cv2\n",
        "# äº‹å‰å­¦ç¿’æ¸ˆã¿ã®ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿(detectionãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨)\n",
        "model = YOLO('yolov8n.pt')\n",
        "# predictãƒ¢ãƒ¼ãƒ‰ã‚’å®Ÿè¡Œ (çµæœã ã‘æ¬²ã—ã„ã®ã§ã€projectãƒ»nameãƒ»exist_okã¯ãªãã¦ã‚‚OK)\n",
        "results = model.predict(source=img_path[2])\n",
        "# Resultsã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‹ã‚‰æç”»ã«å¿…è¦ãªæƒ…å ±ã‚’å–å¾—\n",
        "coordinate_bbox = results[0].boxes.xyxy #bbox\n",
        "classes=results[0].boxes.cls # æ¤œå‡ºã‚¯ãƒ©ã‚¹\n",
        "classes_map = results[0].names # ã‚¯ãƒ©ã‚¹ç•ªå·ã¨åç§°\n",
        "# ç”»åƒã®èª­ã¿è¾¼ã¿\n",
        "img = Image.open(results[0].path)\n",
        "# è‰²ã®æŒ‡å®š (ã‚¯ãƒ©ã‚¹ã”ã¨ã«ãƒ©ãƒ³ãƒ€ãƒ ã«è‰²ã‚’é¸æŠã™ã‚‹å ´åˆä½¿ã†)\n",
        "# colors = ['red', 'green', 'blue', 'yellow', 'cyan', 'magenta', 'olive', 'purple']\n",
        "# colors = [(255, 0, 0), (0, 255, 0), (0, 0, 255), (255, 255, 0), (0, 255, 255), (255, 0, 255), (128, 128, 0), (128, 0, 128)]\n",
        "# æç”»ã‚³ãƒ³ãƒ†ãƒ³ãƒˆã®å–å¾—\n",
        "draw = ImageDraw.Draw(img)\n",
        "\"\"\"\n",
        "ãƒ•ã‚©ãƒ³ãƒˆã®è¨­å®šã€‚Macã ã¨/System/Library/Fontsã«è‰²ã€…ã‚ã‚‹ã®ã§ã“ã“ã‹ã‚‰é¸ã‚“ã ã€‚\n",
        "bboxã ã‘ã®æç”»ã§ã‚ã‚Œã°å¿…è¦ãªã„ã€‚å¿…è¦ãªã„å ´åˆã¯draw.text(font=font)ã®fontéƒ¨åˆ†ã‚’æ¶ˆã™ã€‚\n",
        "ã‚¨ãƒ©ãƒ¼ãŒå‡ºã‚‹å ´åˆã¯ãƒ•ã‚©ãƒ³ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã¸ã®ãƒ•ãƒ«ãƒ‘ã‚¹(/System/Library/Fonts/ãƒ’ãƒ©ã‚®ãƒä¸¸ã‚´ ProN W4.ttc)ã§è¨­å®šã—ã¦ã‚ã’ã‚‹\n",
        "\"\"\"\n",
        "font = ImageFont.truetype('/usr/share/fonts/truetype/liberation/LiberationSans-Regular.ttf', 4000)\n",
        "# ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã®æç”»\n",
        "i=1\n",
        "for bbox, cls in zip(coordinate_bbox, classes):\n",
        "    x1, y1, x2, y2 = map(int, bbox)\n",
        "    #color = colors[int(cls) % len(colors)] ä»Šå›ã¯è‰²ã‚’ç›´æ¥æŒ‡å®šã™ã‚‹ã®ã§ä½¿ã‚ãªã„\n",
        "    color=(255,0,0) # red\n",
        "    # bboxã®æç”»\n",
        "    draw.rectangle([x1, y1, x2, y2], outline=color, width=5)\n",
        "    cls_text = classes_map.get(int(cls))\n",
        "    # æ¤œå‡ºã‚¯ãƒ©ã‚¹åã®æç”»\n",
        "    draw.text((x1, y1 - 50), cls_text+\"#\"+str(i), fill=\"orange\")\n",
        "    print(f\"class: {cls_text}\")\n",
        "    print(f\"x1: {x1}, y1: {y1}, x2: {x2}, y2: {y2}\")\n",
        "    i += 1\n",
        "# ç”»åƒã®ãƒªã‚µã‚¤ã‚º (å¿…è¦ã§ã‚ã‚Œã°)\n",
        "#img = img.resize((640,640))\n",
        "# å‡ºåŠ›å…ˆãƒ•ã‚©ãƒ«ãƒ€ã®ä½œæˆã€‚model.predictã§ä½œæˆã•ã›ã¦ã‚‚OKã€‚\n",
        "directories = ['/Users/hinomaruc/Desktop/blog/dataset/yolov8/runs/mypredict']\n",
        "for directory in directories:\n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "# ç”»åƒã®ä¿å­˜ (å­˜åœ¨ã—ãªã„ãƒ•ã‚©ãƒ«ãƒ€ã ã¨FileNotFoundErrorã«ãªã‚‹ã®ã§æ³¨æ„)\n",
        "img.save('/Users/hinomaruc/Desktop/blog/dataset/yolov8/runs/mypredict/sample_bbox.png')\n",
        "# ç”»åƒã®è¡¨ç¤º\n",
        "display(DisplayImage(filename='/Users/hinomaruc/Desktop/blog/dataset/yolov8/runs/mypredict/sample_bbox.png'))"
      ],
      "metadata": {
        "id": "2zTw01xTZlu2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os\n",
        "from ultralytics import YOLO\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from IPython.display import Image as DisplayImage\n",
        "from IPython.display import display\n",
        "\n",
        "# äº‹å‰å­¦ç¿’æ¸ˆã¿ã®ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿(detectionãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨)\n",
        "model = YOLO('yolov8n.pt')\n",
        "# predictãƒ¢ãƒ¼ãƒ‰ã‚’å®Ÿè¡Œ (çµæœã ã‘æ¬²ã—ã„ã®ã§ã€projectãƒ»nameãƒ»exist_okã¯ãªãã¦ã‚‚OK)\n",
        "results = model.predict(source=img_path[1])\n",
        "# Resultsã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‹ã‚‰æç”»ã«å¿…è¦ãªæƒ…å ±ã‚’å–å¾—\n",
        "coordinate_bbox = results[0].boxes.xyxy #bbox\n",
        "classes=results[0].boxes.cls # æ¤œå‡ºã‚¯ãƒ©ã‚¹\n",
        "classes_map = results[0].names # ã‚¯ãƒ©ã‚¹ç•ªå·ã¨åç§°\n",
        "\n",
        "# Open the image file\n",
        "img_cv2 = cv2.imread(results[0].path)\n",
        "\n",
        "# Set the font scale and thickness\n",
        "font_scale = 3\n",
        "font_thickness = 2\n",
        "\n",
        "# Loop through each bounding box\n",
        "i=1\n",
        "for bbox, cls in zip(coordinate_bbox, classes):\n",
        "    print(bbox)\n",
        "\n",
        "    x1, y1, x2, y2 = map(int, bbox)\n",
        "    color=(0,0,255) # red\n",
        "    # Draw the bounding box\n",
        "    cv2.rectangle(img_cv2, (x1, y1), (x2, y2), color, 5)\n",
        "    cls_text = classes_map.get(int(cls))\n",
        "    # Put the class label text\n",
        "    cv2.putText(img_cv2, cls_text+\"#\"+str(i), (x1, y1 - 50), cv2.FONT_HERSHEY_SIMPLEX, font_scale, color, font_thickness)\n",
        "    i += 1\n",
        "\n",
        "# Save the image\n",
        "cv2.imwrite('/Users/hinomaruc/Desktop/blog/dataset/yolov8/runs/mypredict/sample_bbox.png', img_cv2)\n",
        "\n",
        "\n",
        "#plt.imshow(cv2.cvtColor(img_cv2, cv2.COLOR_BGR2RGB))\n",
        "# Convert the color from BGR to RGB\n",
        "img_rgb = cv2.cvtColor(img_cv2, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Use matplotlib to display the image\n",
        "plt.imshow(img_rgb)\n",
        "\n",
        "# Show the axes\n",
        "plt.axis('on')\n",
        "\n",
        "# Show the image\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "aTBwFQPBet5H"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
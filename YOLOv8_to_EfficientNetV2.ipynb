{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPA311CF3y4uElZL8EKgG+d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykitaguchi77/GO_AI_project/blob/main/YOLOv8_to_EfficientNetV2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**YOLOv8 to EfficientNetv2 pipeline**"
      ],
      "metadata": {
        "id": "w2bPHz9wew6n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Olympia datasetã‹ã‚‰ç›®ã‚’åˆ‡ã‚ŠæŠœãï¼ˆYOLOv8nï¼‰**\n",
        "#**åˆ‡ã‚ŠæŠœã„ãŸç›®ã‚’EfficientNetV2ã§è§£æã™ã‚‹**"
      ],
      "metadata": {
        "id": "LXWb3YtIFX1p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Olympia dataset\n",
        "Dlibã§ç›®ãŒ2ã¤æ¤œå‡ºã•ã‚Œã‚‹ã‚‚ã®ã‚’æŠœãå‡ºã™\n",
        "YOLOv8ã‚’ç”¨ã„ã¦å·¦å³ã¨ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã‚’èªè­˜ã•ã›ã‚‹\n",
        "åˆ‡ã‚ŠæŠœã„ãŸãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹å†…ã®ç”»åƒã«ã¤ã„ã¦ã€EfficientNetv2ã‚’ç”¨ã„ã¦çœ¼çƒçªå‡ºåº¦ã€MRD-1ã€MRD-2ã‚’å›å¸°ã•ã›ã‚‹\n",
        "ã‚¹ãƒãƒ›ã«å®Ÿè£…\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "UnyBedKNbfS3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7MdRVDhFJmO",
        "outputId": "d2a9a3fa-4128-4ea8-88e0-b24f9508c31d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import shutil\n",
        "import copy\n",
        "import pandas as pd\n",
        "import csv\n",
        "from tqdm import tqdm\n",
        "\n",
        "import glob\n",
        "import random\n",
        "from PIL import Image\n",
        "%matplotlib inline\n",
        "\n",
        "#ã‚µãƒãƒ¼ãƒˆãƒ‘ãƒƒãƒã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "\n",
        "plt.ion()   # interactive mode\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#è¦ªãƒ•ã‚©ãƒ«ãƒ€\n",
        "parent_dir = '/content/drive/MyDrive/Deep_learning/Olympia_dataset/dataset_uni_for_YOLOv8'\n",
        "\n",
        "#å…ƒç”»åƒãƒ•ã‚©ãƒ«ãƒ€\n",
        "dataset_dir = '/content/drive/MyDrive/Deep_learning/Olympia_dataset/dataset'\n",
        "\n",
        "#å…ƒç”»åƒã‚’ã‚³ãƒ”ãƒ¼\n",
        "orig_dir = f\"{parent_dir}/dataset_orig\"\n",
        "\n",
        "#åˆ‡ã‚Šã¬ã„ãŸç”»åƒã‚’ä¿å­˜ã™ã‚‹ãƒ•ã‚©ãƒ«ãƒ€\n",
        "out_dir = f\"{parent_dir}/dataset_uni\"\n",
        "\n",
        "#CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ•ã‚©ãƒ«ãƒ€\n",
        "csv_path = f\"{parent_dir}/dataset_uni_for_YOLO8.csv\""
      ],
      "metadata": {
        "id": "_DI1wc0eF5uR"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "###################################\n",
        "# Reflesh folder (å†…å®¹ãŒå‰Šé™¤ã•ã‚Œã‚‹ã®ã§æ³¨æ„ï¼ï¼) #\n",
        "###################################\n",
        "\"\"\"\n",
        "\n",
        "# parent_dirãŒã‚ã‚Œã°å‰Šé™¤ã™ã‚‹\n",
        "if os.path.exists(parent_dir):\n",
        "    shutil.rmtree(parent_dir)\n",
        "\n",
        "# æ–°ã—ãparent_dirã‚’ä½œæˆã™ã‚‹\n",
        "os.makedirs(parent_dir)\n",
        "\n",
        "# orig_dir, out_dirã‚’æ–°è¦ã«ä½œæˆã™ã‚‹\n",
        "os.makedirs(orig_dir)\n",
        "os.makedirs(out_dir)\n",
        "\n",
        "# orig_dirã«dataset_dirç›´ä¸‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã™ã¹ã¦ã‚³ãƒ”ãƒ¼ã™ã‚‹\n",
        "file_list = os.listdir(dataset_dir)\n",
        "for filename in tqdm(file_list, desc=\"Copying files\", unit=\"file\"):\n",
        "    src_path = os.path.join(dataset_dir, filename)\n",
        "    dst_path = os.path.join(orig_dir, filename)\n",
        "    shutil.copy(src_path, dst_path)\n",
        "\n",
        "print(\"å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸã€‚\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2ZGZkPOK84g",
        "outputId": "07fec511-58ed-4324-c341-c03cf2ccd77f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Copying files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1016/1016 [00:48<00:00, 20.92file/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸã€‚\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**HaarCascadeã‚’ç”¨ã„ã¦ç›®ã‚’æ¤œå‡º**"
      ],
      "metadata": {
        "id": "6Y6OC0UoMOZv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ã‚«ã‚¹ã‚±ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹\n",
        "eye_cascade_path = '/content/drive/My Drive/Deep_learning/haarcascade_eye.xml'\n",
        "\n",
        "# ã‚«ã‚¹ã‚±ãƒ¼ãƒ‰åˆ†é¡å™¨ã®ç‰¹å¾´é‡å–å¾—\n",
        "eye_cascade = cv2.CascadeClassifier(eye_cascade_path)\n"
      ],
      "metadata": {
        "id": "f2rM0ZbTMN50"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**ç›®ãŒ2ã¤ä»¥ä¸Šæ¤œå‡ºã•ã‚ŒãŸã‚‚ã®ã‚’æŠœãå‡ºã™**"
      ],
      "metadata": {
        "id": "FWLibTiZc1Xw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(csv_path, 'w', newline='') as f:\n",
        "        #fieldnames = ['Number', 'Folder', 'FileName']\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow(['id','img_path', 'side R/L', 'ex', 'ey', 'ew', 'eh'])  #header\n",
        "\n",
        "        files = os.listdir(orig_dir)\n",
        "\n",
        "        k=0\n",
        "        for file in files:  #ãƒ•ã‚©ãƒ«ãƒ€æ•°ã®åˆ†ã ã‘\n",
        "              file_path = f\"{orig_dir}/{file}\"\n",
        "              id = os.path.splitext(os.path.basename(file_path))[0]\n",
        "\n",
        "              img = cv2.imread(file_path)\n",
        "              img2 = img.copy()\n",
        "\n",
        "              # ç”»åƒã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«åŒ–\n",
        "              grayscale_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "              #300pixä»¥ä¸Šã®ã‚‚ã®ã§ç›®ã«è¦‹ãˆã‚‹ã‚‚ã®ã‚’æŠ½å‡º\n",
        "              eye_list = eye_cascade.detectMultiScale(grayscale_img, minSize=(300, 300))\n",
        "\n",
        "              # çœ¼æ¤œå‡ºåˆ¤å®š\n",
        "              if len(eye_list) >= 1:\n",
        "                  print('ç›®ãŒ' + str(len(eye_list)) +'å€‹æ¤œå‡ºã•ã‚Œã¾ã—ãŸ')\n",
        "              else:\n",
        "                  print(\"eye detection error\")\n",
        "\n",
        "              #ç”»åƒã®åˆ‡ã‚ŠæŠœãã¨ä¿å­˜ï¼ˆ2å€‹ä»¥ä¸Šæ¤œå‡ºã®æ™‚ã«é™ã‚‹ï¼‰\n",
        "              if len(eye_list) >= 2:\n",
        "                  for (ex, ey, ew, eh) in eye_list:\n",
        "                      print(f\"img_width: {img2.shape[1]}\")\n",
        "                      print(\"[ex,ey] = %d,%d [ew,eh] = %d,%d\" %(ex, ey, ew, eh))\n",
        "                      cv2.rectangle(img2, (ex, ey), (ex + ew, ey + eh), (0, 255, 0), 2)\n",
        "                      #img_cropped = img[int(ey-0.1*eh): int(ey+1.1*eh), int(ex-0.1*ew): int(ex+1.1*ew)] #æœ¬æ¥ã®åˆ‡ã‚ŠæŠœãã‚ˆã‚Šå¹…ã®0.1å€ãšã¤æ°´å¢—ã—ã™ã‚‹\n",
        "                      img_cropped = img[int(ey): int(ey+eh), int(ex): int(ex+ew)]\n",
        "\n",
        "\n",
        "                      if ex+eh*0.5 <= img2.shape[1]/2:\n",
        "                          side = \"R\" #æ¨ªå¹…ã®åŠåˆ†ã‚ˆã‚Šå·¦ã«ã‚ã‚‹ã®ã¯å³çœ¼\n",
        "                      else:\n",
        "                          side = \"L\" #æ¨ªå¹…ã®åŠåˆ†ã‚ˆã‚Šã‚ˆã‚Šå³ã«ã‚ã‚‹ã®ã¯å·¦çœ¼\n",
        "\n",
        "                      print(f\"side: {side}\")\n",
        "                      print(\"\")\n",
        "\n",
        "                      cv2.imwrite(f\"{out_dir}/{id}_{side}.png\", img_cropped)\n",
        "\n",
        "                      #å¯¾å¿œè¡¨ã®ä½œæˆ\n",
        "                      writer.writerow([id, file_path, side, ex+round(ew/2), ey+round(eh/2), ew, eh])\n",
        "                  else:\n",
        "                      pass\n"
      ],
      "metadata": {
        "id": "pnVFMJJVMW8n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**ã“ã“ã§ã€ç›®ä»¥å¤–ãŒèª¤æ¤œå‡ºã•ã‚Œã¦ã„ã‚‹ã‚‚ã®ã‚’æ‰‹å‹•ã§æŠœãå‡ºã—ã¦å‰Šé™¤ã™ã‚‹**"
      ],
      "metadata": {
        "id": "tm4HsJszc9VX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "ä¸é©åˆ‡ãªç”»åƒãŒã‚ã‚Œã°ã€å·¦å³ã¾ã¨ã‚ã¦æ¶ˆã™\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "v3abWZGGe9sA",
        "outputId": "b7c5d277-9dcd-4101-c5e2-6fb1d298bd86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nä¸é©åˆ‡ãªç”»åƒãŒã‚ã‚Œã°ã€å·¦å³ã¾ã¨ã‚ã¦æ¶ˆã™\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#CSVã®ãƒªã‚¹ãƒˆã¨ç”»åƒãƒ•ã‚©ãƒ«ãƒ€ã‚’è¦‹æ¯”ã¹ã¦ã€æ¶ˆã—ãŸç”»åƒã‚’åˆ¤åˆ¥ã€‚CSVã‚’ä¿®æ­£ã™ã‚‹ã€‚\n",
        "import pandas as pd\n",
        "\n",
        "# Load the CSV\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# Get a list of unique ids\n",
        "csv_id_list = df['id'].unique().tolist()\n",
        "\n",
        "print(f\"csv_id_list: {csv_id_list}\")\n",
        "\n",
        "\n",
        "# Construct the output directory path\n",
        "out_dir = f\"{parent_dir}/dataset_uni\"\n",
        "\n",
        "# Get a list of all image file names in the directory\n",
        "image_file_names = os.listdir(out_dir)\n",
        "\n",
        "# Split each file name at \"_\" and take the first part, then make sure the list is unique\n",
        "image_id_list = list(set([int(name.split('_')[0]) for name in image_file_names]))\n",
        "print(f\"image_id_list: {image_id_list}\")\n",
        "\n",
        "# Find the ids that are in the CSV list but not in the image file list\n",
        "missing_ids = [id for id in csv_id_list if id not in image_id_list]\n",
        "print(f\"missing_ids: {missing_ids}\")\n",
        "\n",
        "\n",
        "\n",
        "# Remove the rows with ids in missing_ids\n",
        "df = df[~df['id'].isin(missing_ids)]\n",
        "\n",
        "# Save the dataframe back to a CSV\n",
        "df.to_csv(f\"{parent_dir}/dataset_uni_for_YOLO8_modified.csv\", index=False)"
      ],
      "metadata": {
        "id": "aGVqU2n9i3wR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "â‘ \"/content/drive/MyDrive/Deep_learning/Olympia_dataset/dataset_uni_for_YOLOv8/dataset_orig\"ã®ãƒ•ã‚¡ã‚¤ãƒ«åï¼ˆ1.jpgã¨ã™ã‚‹ã¨1ï¼‰ã¨ã€â‘¡\"/content/drive/MyDrive/Deep_learning/Olympia_dataset/dataset_uni_for_YOLOv8/dataset_uni\"ã®ã‚¢ãƒ³ãƒ€ãƒ¼ãƒãƒ¼ã®æ‰‹å‰ï¼ˆ1_R.jpgã¨ã™ã‚‹ã¨1)ã‚’è¦‹æ¯”ã¹ã‚‹\n",
        "\n",
        "\"/content/drive/MyDrive/Deep_learning/Olympia_dataset/dataset_uni_for_YOLOv8/dataset_dlib_detected\"ã¨ã„ã†ãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆ\n",
        "â‘ ã¨â‘¡ã§ä¸€è‡´ã™ã‚‹ã‚‚ã®(2ã¤ç›®ãŒæ¤œå‡ºã•ã‚ŒãŸã‚‚ã®)ã«é–¢ã—ã¦ã€â‘ ã®ç”»åƒï¼ˆã‚³ãƒ”ãƒ¼ï¼‰ã‚’ä¸€è¾º512pixã®é»’å¡—ã‚Šletterboxã«ã—ã¦å¤‰æ›ã—ã€æ–°ã—ãä½œæˆã—ãŸãƒ•ã‚©ãƒ«ãƒ€ã«ä¿å­˜ã™ã‚‹\n",
        "...ã§ã¯ãªãletterboxã¯ä½¿ã‚ãšãã®ã¾ã¾ã‚³ãƒ”ãƒ¼ã™ã‚‹ã“ã¨ã¨ã—ãŸ\n",
        "\"\"\"\n",
        "\n",
        "import shutil\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "# def letterbox_image(image, size):\n",
        "#     \"\"\"\n",
        "#     ç”»åƒã‚’æŒ‡å®šã—ãŸã‚µã‚¤ã‚ºã®é»’å¡—ã‚Šletterboxã«å¤‰æ›ã™ã‚‹é–¢æ•°\n",
        "#     :param image: å¤‰æ›ã™ã‚‹ç”»åƒï¼ˆPIL Imageï¼‰\n",
        "#     :param size: å¤‰æ›å¾Œã®ã‚µã‚¤ã‚ºï¼ˆå¹…, é«˜ã•ï¼‰ã®ã‚¿ãƒ—ãƒ«\n",
        "#     :return: å¤‰æ›å¾Œã®ç”»åƒï¼ˆPIL Imageï¼‰\n",
        "#     \"\"\"\n",
        "#     new_width, new_height = size\n",
        "#     old_width, old_height = image.size\n",
        "#     ratio = min(new_width / old_width, new_height / old_height)\n",
        "#     new_width = int(old_width * ratio)\n",
        "#     new_height = int(old_height * ratio)\n",
        "#     resized_image = image.resize((new_width, new_height), Image.LANCZOS)\n",
        "#     boxed_image = Image.new(\"RGB\", size, (0, 0, 0))\n",
        "#     boxed_image.paste(resized_image, ((size[0] - new_width) // 2, (size[1] - new_height) // 2))\n",
        "#     return boxed_image\n",
        "\n",
        "def main():\n",
        "    # ä¿å­˜å…ˆãƒ•ã‚©ãƒ«ãƒ€ã®ãƒ‘ã‚¹\n",
        "    output_folder = \"/content/drive/MyDrive/Deep_learning/Olympia_dataset/dataset_uni_for_YOLOv8/dataset_dlib_detected\"\n",
        "\n",
        "    # ãƒ•ã‚©ãƒ«ãƒ€ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ä½œæˆ\n",
        "    if os.path.exists(output_folder):\n",
        "        shutil.rmtree(output_folder)\n",
        "    os.makedirs(output_folder)\n",
        "\n",
        "    # â‘ ã®ãƒ•ã‚©ãƒ«ãƒ€å†…ã®ãƒ•ã‚¡ã‚¤ãƒ«åã‚’å–å¾—ã—ã¦ã€1.jpgã®ã‚ˆã†ãªå½¢å¼ã«å¤‰æ›\n",
        "    orig_folder = \"/content/drive/MyDrive/Deep_learning/Olympia_dataset/dataset_uni_for_YOLOv8/dataset_orig\"\n",
        "    orig_files = os.listdir(orig_folder)\n",
        "    orig_filenames = [os.path.splitext(filename)[0] for filename in orig_files]\n",
        "\n",
        "    # â‘¡ã®ãƒ•ã‚©ãƒ«ãƒ€å†…ã®ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰ã‚¢ãƒ³ãƒ€ãƒ¼ãƒãƒ¼ã®æ‰‹å‰ã‚’å–å¾—ã—ã¦ã€1_R.jpgã®ã‚ˆã†ãªå½¢å¼ã«å¤‰æ›\n",
        "    uni_folder = \"/content/drive/MyDrive/Deep_learning/Olympia_dataset/dataset_uni_for_YOLOv8/dataset_uni\"\n",
        "    uni_files = os.listdir(uni_folder)\n",
        "    uni_filenames = [filename.split(\"_\")[0] for filename in uni_files]\n",
        "\n",
        "    # â‘ ã¨â‘¡ã§ä¸€è‡´ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¢ã—ã¦ã€å‡¦ç†ã‚’å®Ÿè¡Œ\n",
        "    orig_set = set(orig_filenames)\n",
        "    uni_set = set(uni_filenames)\n",
        "\n",
        "    common_filenames = orig_set.intersection(uni_set)\n",
        "\n",
        "    print(f\"In {len(common_filenames)} images, both eyes were detected. Copy files to the folder 'dataset_dlib_detected'.\")\n",
        "\n",
        "    for filename in tqdm(common_filenames, desc=\"Processing Images\"):\n",
        "        orig_file_path = os.path.join(orig_folder, filename + \".JPG\")\n",
        "        #uni_file_path = os.path.join(uni_folder, filename + \"_R.JPG\")  # \"R\"ã‚’æŒ‡å®šã—ã¦ã„ã¾ã™ãŒã€\"L\"ã®å ´åˆã‚‚ã‚ã‚‹ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“\n",
        "        output_file_path = os.path.join(output_folder, filename + \".JPG\")  # æ‹¡å¼µå­ã‚’.JPGã«å¤‰æ›´\n",
        "\n",
        "\n",
        "        print(f\"output_file_path: {output_file_path}\")\n",
        "\n",
        "        # # â‘ ã®ç”»åƒã‚’èª­ã¿è¾¼ã¿\n",
        "        # orig_image = Image.open(orig_file_path)\n",
        "        # # ä¸€è¾º512pxã®é»’å¡—ã‚Šletterboxã«å¤‰æ›\n",
        "        # new_image = letterbox_image(orig_image, (512, 512))\n",
        "        # # å¤‰æ›å¾Œã®ç”»åƒã‚’ä¿å­˜\n",
        "        # new_image.save(output_file_path)\n",
        "\n",
        "        #ãƒªã‚µã‚¤ã‚ºã›ãšã«ãã®ã¾ã¾ã‚³ãƒ”ãƒ¼ã™ã‚‹\n",
        "        shutil.copy(orig_file_path, output_file_path)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "JsWZBevoSmhG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num = os.listdir(\"/content/drive/MyDrive/Deep_learning/Olympia_dataset/dataset_uni_for_YOLOv8/dataset_dlib_detected\")\n",
        "print(len(num))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BgphB4aDYNx_",
        "outputId": "f45f6110-acf1-41e1-d9f6-331b76e94f02"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "961\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**YOLOv8 annotations**"
      ],
      "metadata": {
        "id": "FdvZB6GrKCe_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#è¦ªãƒ•ã‚©ãƒ«ãƒ€\n",
        "parent_dir = '/content/drive/MyDrive/Deep_learning/Olympia_dataset/dataset_uni_for_YOLOv8'\n",
        "\n",
        "#å…ƒç”»åƒãƒ•ã‚©ãƒ«ãƒ€\n",
        "dataset_dir = '/content/drive/MyDrive/Deep_learning/Olympia_dataset/dataset'\n",
        "\n",
        "#å…ƒç”»åƒã‚’ã‚³ãƒ”ãƒ¼\n",
        "orig_dir = f\"{parent_dir}/dataset_orig\"\n",
        "\n",
        "\n",
        "#åˆ‡ã‚Šã¬ã„ãŸç”»åƒã‚’ä¿å­˜ã™ã‚‹ãƒ•ã‚©ãƒ«ãƒ€\n",
        "out_dir = f\"{parent_dir}/dataset_uni\"\n",
        "\n",
        "#åˆ‡ã‚Šã¬ã„ãŸç”»åƒã‚’ä¿å­˜ã™ã‚‹ãƒ•ã‚©ãƒ«ãƒ€\n",
        "dlib_detected_dir = f\"{parent_dir}/dataset_dlib_datected\"\n",
        "\n",
        "#CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ•ã‚©ãƒ«ãƒ€\n",
        "csv_path = f\"{parent_dir}/dataset_uni_for_YOLO8_modified.csv\""
      ],
      "metadata": {
        "id": "t3x7BL3UKGc6"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚“ã§DataFrameã«æ ¼ç´\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# å‰å‡¦ç†æ¸ˆã¿ã®ãƒ•ã‚©ãƒ«ãƒ€ã‚’æŒ‡å®š\n",
        "df_dlib_detected = df\n",
        "df_dlib_detected[\"img_path\"] = df_dlib_detected[\"img_path\"].str.replace(\"dataset_orig\", \"dataset_dlib_detected\")\n",
        "\n",
        "# R/Lã‚’æ•°å­—ã«å¤‰æ›´\n",
        "df_dlib_detected[\"side R/L\"] = df_dlib_detected[\"side R/L\"].replace({\"R\": 0, \"L\": 1})\n",
        "\n",
        "# DataFrameã®å†…å®¹ã‚’è¡¨ç¤º\n",
        "df_dlib_detected"
      ],
      "metadata": {
        "id": "EXDkoZoVKuwW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# é‡è¤‡ã®ãªã„idã®ç¢ºèª\n",
        "unique_ids = list(set(df[\"id\"].tolist()))\n",
        "print(unique_ids)\n",
        "len(unique_ids)"
      ],
      "metadata": {
        "id": "n9m_dg7jf_Uy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##########################\n",
        "# ç”»åƒãƒ•ã‚©ãƒ«ãƒ€å†…ã«åŒåã®YOLOå½¢å¼txtã‚’ä½œæˆã™ã‚‹\n",
        "##########################\n",
        "\n",
        "from PIL import Image\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "def xywh_to_yolo(class_label, img_width, img_height, x, y, w, h):\n",
        "    x_center = x / img_width\n",
        "    y_center = y / img_height\n",
        "    width = w / img_width\n",
        "    height = h / img_height\n",
        "\n",
        "    print(f\"img_width: {img_width}\")\n",
        "    print(f\"x,y,w,h: {x}, {y}, {w}, {h}\")\n",
        "\n",
        "    return f\"{class_label} {x_center} {y_center} {width} {height}\"\n",
        "\n",
        "def create_yolo_txt(df):\n",
        "    grouped_data = df.groupby('id')\n",
        "\n",
        "    for group_id, group_df in grouped_data:\n",
        "        txt_file_path = os.path.join(os.path.dirname(group_df.iloc[0]['img_path']), f\"{group_id}.txt\")\n",
        "\n",
        "        with open(txt_file_path, 'w') as txt_file:\n",
        "            for _, row in group_df.iterrows():\n",
        "                img_path = row['img_path']\n",
        "                class_label = row['side R/L']\n",
        "                x, y, w, h = row['ex'], row['ey'], row['ew'], row['eh']\n",
        "\n",
        "                try:\n",
        "                    img = Image.open(img_path)\n",
        "                    img_width, img_height = img.size\n",
        "                except Exception as e:\n",
        "                    print(f\"Error: Failed to open '{img_path}' or get image dimensions. Skipping annotation.\")\n",
        "                    continue\n",
        "\n",
        "                # YOLOå½¢å¼ã«å¤‰æ›\n",
        "                yolo_annotation = xywh_to_yolo(class_label, img_width, img_height, x, y, w, h)\n",
        "\n",
        "                # ãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãè¾¼ã¿\n",
        "                yolo_annotation += '\\n'  # æ”¹è¡Œã‚’è¿½åŠ \n",
        "                txt_file.write(yolo_annotation)        # ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã‚’å‚ç…§ã™ã‚‹\n",
        "\n",
        "        with open(txt_file_path, 'r') as txt_file_read:\n",
        "            file_contents = txt_file_read.read()\n",
        "            print(f\"Contents of '{txt_file_path}':\\n{file_contents}\")\n",
        "\n",
        "# YOLOå½¢å¼ã®ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã¦ä¿å­˜\n",
        "df_sample = df_dlib_detected[0:]\n",
        "create_yolo_txt(df_sample)\n"
      ],
      "metadata": {
        "id": "cjbhluZHLyQJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_dlib_detected"
      ],
      "metadata": {
        "id": "dBylsWVIxSxk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **YOLOv8_training**"
      ],
      "metadata": {
        "id": "DX_lR8bf2QSE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "parent_dir = '/content/drive/MyDrive/Deep_learning/Olympia_dataset/dataset_uni_for_YOLOv8'\n",
        "eyecrop_dir = os.path.join(parent_dir, 'for_eyecrop_training')\n",
        "\n",
        "\n",
        "# ã‚‚ã—æ—¢ã«\"eyecrop\"ãƒ•ã‚©ãƒ«ãƒ€ãŒå­˜åœ¨ã™ã‚‹å ´åˆã€å‰Šé™¤ã—ã¾ã™\n",
        "if os.path.exists(eyecrop_dir):\n",
        "    try:\n",
        "        shutil.rmtree(eyecrop_dir)  # ç©ºã®ãƒ•ã‚©ãƒ«ãƒ€ãªã‚‰ã“ã‚Œã§å‰Šé™¤ã§ãã¾ã™\n",
        "    except OSError as e:\n",
        "        print(f\"å‰Šé™¤ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}\")\n",
        "else:\n",
        "    print(\"ãƒ•ã‚©ãƒ«ãƒ€ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã§ã—ãŸã€‚æ–°ã—ãä½œæˆã—ã¾ã™ã€‚\")\n",
        "\n",
        "# \"eyecrop\"ãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆã—ã¾ã™\n",
        "try:\n",
        "    os.mkdir(eyecrop_dir)\n",
        "    print(\"eyecropãƒ•ã‚©ãƒ«ãƒ€ãŒä½œæˆã•ã‚Œã¾ã—ãŸã€‚\")\n",
        "except OSError as e:\n",
        "    print(f\"ãƒ•ã‚©ãƒ«ãƒ€ã®ä½œæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {e}\")\n",
        "\n",
        "# \"train\"ãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆã—ã¾ã™\n",
        "train_dir = os.path.join(eyecrop_dir, 'train')\n",
        "try:\n",
        "    os.mkdir(train_dir)\n",
        "    print(\"trainãƒ•ã‚©ãƒ«ãƒ€ãŒä½œæˆã•ã‚Œã¾ã—ãŸã€‚\")\n",
        "except OSError as e:\n",
        "    print(f\"ãƒ•ã‚©ãƒ«ãƒ€ã®ä½œæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {e}\")\n",
        "\n",
        "# \"val\"ãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆã—ã¾ã™\n",
        "val_dir = os.path.join(eyecrop_dir, 'val')\n",
        "try:\n",
        "    os.mkdir(val_dir)\n",
        "    print(\"valãƒ•ã‚©ãƒ«ãƒ€ãŒä½œæˆã•ã‚Œã¾ã—ãŸã€‚\")\n",
        "except OSError as e:\n",
        "    print(f\"ãƒ•ã‚©ãƒ«ãƒ€ã®ä½œæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {e}\")\n",
        "\n",
        "\n",
        "# YAMLãƒ•ã‚¡ã‚¤ãƒ«ã®è¨­å®š\"\n",
        "yaml_file_path = os.path.join(eyecrop_dir, 'data.yaml')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "esqHHl4R8giz",
        "outputId": "19be9830-029d-4054-fa13-7ac5d4d7882a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ãƒ•ã‚©ãƒ«ãƒ€ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã§ã—ãŸã€‚æ–°ã—ãä½œæˆã—ã¾ã™ã€‚\n",
            "eyecropãƒ•ã‚©ãƒ«ãƒ€ãŒä½œæˆã•ã‚Œã¾ã—ãŸã€‚\n",
            "trainãƒ•ã‚©ãƒ«ãƒ€ãŒä½œæˆã•ã‚Œã¾ã—ãŸã€‚\n",
            "valãƒ•ã‚©ãƒ«ãƒ€ãŒä½œæˆã•ã‚Œã¾ã—ãŸã€‚\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# YAML ãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’è¨­å®š\n",
        "%%writefile $yaml_file_path\n",
        "# train and val data as 1) directory: path/images/, 2) file: path/images.txt, or 3) list: [path1/images/, path2/images/]\n",
        "train: /content/drive/MyDrive/Deep_learning/Olympia_dataset/dataset_uni_for_YOLOv8/for_eyecrop_training/train\n",
        "val: /content/drive/MyDrive/Deep_learning/Olympia_dataset/dataset_uni_for_YOLOv8/for_eyecrop_training/val\n",
        "\n",
        "# number of classes\n",
        "nc: 2\n",
        "\n",
        "# class names\n",
        "names: ['R', 'L']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iECkqqgu71rl",
        "outputId": "97aec80b-a6ea-47da-e336-0e77bf70f0d4"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/drive/MyDrive/Deep_learning/Olympia_dataset/dataset_uni_for_YOLOv8/for_eyecrop_training/data.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ï¼—ï¼šï¼“ã«åˆ†å‰²\n",
        "\n",
        "Deep_learning\n",
        "â””â”€â”€ Olympia_dataset\n",
        "    â””â”€â”€ dataset_uni_for_YOLOv8\n",
        "        â””â”€â”€ for_eyecrop_training\n",
        "            â”œâ”€â”€ train\n",
        "            â”œâ”€â”€ val\n",
        "            â””â”€â”€ data.yaml\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "import glob\n",
        "import shutil\n",
        "import os\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "\n",
        "# å†ç¾æ€§ã‚’ç¢ºä¿ã™ã‚‹ãŸã‚ã®random_state\n",
        "random.seed(42)\n",
        "\n",
        "# å…¥åŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã¨å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ‘ã‚¹\n",
        "src_dir = '/content/drive/MyDrive/Deep_learning/Olympia_dataset/dataset_uni_for_YOLOv8/dataset_dlib_detected'\n",
        "train_dir = '/content/drive/MyDrive/Deep_learning/Olympia_dataset/dataset_uni_for_YOLOv8/for_eyecrop_training/train'\n",
        "val_dir = '/content/drive/MyDrive/Deep_learning/Olympia_dataset/dataset_uni_for_YOLOv8/for_eyecrop_training/val'\n",
        "\n",
        "# å…¥åŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰JPGãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒªã‚¹ãƒˆã‚’å–å¾—\n",
        "jpg_files = glob.glob(os.path.join(src_dir, '*.JPG'))\n",
        "\n",
        "# ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«ã‚·ãƒ£ãƒƒãƒ•ãƒ«\n",
        "random.shuffle(jpg_files)\n",
        "\n",
        "# ãƒ•ã‚¡ã‚¤ãƒ«ã‚’70%:30%ã«åˆ†å‰²\n",
        "split_point = int(len(jpg_files) * 0.7)\n",
        "train_files = jpg_files[:split_point]\n",
        "val_files = jpg_files[split_point:]\n",
        "\n",
        "# ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãã‚Œãã‚Œã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ã‚³ãƒ”ãƒ¼\n",
        "for file_path in tqdm(train_files, desc=\"Copying train files\"):\n",
        "    shutil.copy2(file_path, train_dir)\n",
        "    txt_file = os.path.splitext(file_path)[0] + '.txt'\n",
        "    shutil.copy2(txt_file, train_dir)\n",
        "\n",
        "for file_path in tqdm(val_files, desc=\"Copying validation files\"):\n",
        "    shutil.copy2(file_path, val_dir)\n",
        "    txt_file = os.path.splitext(file_path)[0] + '.txt'\n",
        "    shutil.copy2(txt_file, val_dir)\n"
      ],
      "metadata": {
        "id": "AhIlcPgZCOGE",
        "outputId": "ac093e65-c8de-4cd5-8974-52de0983fb76",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Copying train files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 672/672 [00:14<00:00, 45.15it/s]\n",
            "Copying validation files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 289/289 [00:06<00:00, 44.39it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# YOLOv8 setup\n",
        "%pip install ultralytics\n",
        "import ultralytics\n",
        "ultralytics.checks()"
      ],
      "metadata": {
        "id": "O6SawQZdE5DV",
        "outputId": "376f0a73-97f0-4d4c-892b-a8276c8fe570",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ultralytics YOLOv8.0.157 ğŸš€ Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Setup complete âœ… (8 CPUs, 51.0 GB RAM, 31.9/166.8 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "yaml_file_path = '/content/drive/MyDrive/Deep_learning/Olympia_dataset/dataset_uni_for_YOLOv8/for_eyecrop_training/data.yaml'\n",
        "\n",
        "%cd /content/drive/MyDrive/Deep_learning/Olympia_dataset/dataset_uni_for_YOLOv8/for_eyecrop_training"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0y_l04WrGVKs",
        "outputId": "1189383a-65c2-4f9a-970e-3b06a3016879"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Deep_learning/Olympia_dataset/dataset_uni_for_YOLOv8/for_eyecrop_training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!yolo task=detect mode=train model=yolov8n.pt data=$yaml_file_path epochs=100 imgsz=640\n"
      ],
      "metadata": {
        "id": "MVhZngabFHOL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ç¶šãã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°\n",
        "from ultralytics import YOLO\n",
        "\n",
        "yaml_file_path = '/content/drive/MyDrive/Deep_learning/Olympia_dataset/dataset_uni_for_YOLOv8/for_eyecrop_training/data.yaml'\n",
        "\n",
        "# Load a model\n",
        "model = YOLO('/content/drive/MyDrive/Deep_learning/Olympia_dataset/dataset_uni_for_YOLOv8/for_eyecrop_training/yolov8n.pt')  # load a pretrained model (recommended for training)\n",
        "\n",
        "# Train the model\n",
        "model.train(data=yaml_file_path, epochs=100, imgsz=640, resume=True)"
      ],
      "metadata": {
        "id": "PNjb7qWNPW-1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**YOLOv8 interference**"
      ],
      "metadata": {
        "id": "ySmQamVspQKC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOLOv8 setup\n",
        "%pip install ultralytics\n",
        "import ultralytics\n",
        "ultralytics.checks()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uh0dYAFu3vjY",
        "outputId": "68db6ebc-9c40-4727-b653-07df059d3433"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ultralytics YOLOv8.0.143 ğŸš€ Python-3.10.6 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Setup complete âœ… (4 CPUs, 25.5 GB RAM, 24.2/166.8 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "dataset_orig_dir = \"/content/drive/MyDrive/Deep_learning/Olympia_dataset/dataset_uni_for_YOLOv8/dataset_orig\"\n",
        "sample_img = random.choice(glob.glob(f\"{dataset_orig_dir}/*\"))\n",
        "\n"
      ],
      "metadata": {
        "id": "Zk5NbELPMCDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from ultralytics import YOLO\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from IPython.display import Image as DisplayImage\n",
        "from IPython.display import display\n",
        "import cv2\n",
        "\n",
        "sample_img = \"/content/drive/MyDrive/Deep_learning/Olympia_dataset/dataset_uni_for_YOLOv8/dataset_orig/10.JPG\"\n",
        "\n",
        "\n",
        "# äº‹å‰å­¦ç¿’æ¸ˆã¿ã®ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿(detectionãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨)\n",
        "model = YOLO('/content/drive/MyDrive/Deep_learning/Olympia_dataset/dataset_uni_for_YOLOv8/for_eyecrop_training/yolov8n.pt')\n",
        "# predictãƒ¢ãƒ¼ãƒ‰ã‚’å®Ÿè¡Œ (çµæœã ã‘æ¬²ã—ã„ã®ã§ã€projectãƒ»nameãƒ»exist_okã¯ãªãã¦ã‚‚OK)\n",
        "results = model.predict(source=sample_img)\n",
        "# Resultsã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‹ã‚‰æç”»ã«å¿…è¦ãªæƒ…å ±ã‚’å–å¾—\n",
        "coordinate_bbox = results[0].boxes.xyxy #bbox\n",
        "classes=results[0].boxes.cls # æ¤œå‡ºã‚¯ãƒ©ã‚¹\n",
        "#classes_map = results[0].names # ã‚¯ãƒ©ã‚¹ç•ªå·ã¨åç§°\n",
        "classes_map = {0: 'R',1: 'L'} # ã‚¯ãƒ©ã‚¹ç•ªå·ã¨åç§°\n",
        "\n",
        "\n",
        "# ç”»åƒã®èª­ã¿è¾¼ã¿\n",
        "img = Image.open(results[0].path)\n",
        "# è‰²ã®æŒ‡å®š (ã‚¯ãƒ©ã‚¹ã”ã¨ã«ãƒ©ãƒ³ãƒ€ãƒ ã«è‰²ã‚’é¸æŠã™ã‚‹å ´åˆä½¿ã†)\n",
        "# colors = ['red', 'green', 'blue', 'yellow', 'cyan', 'magenta', 'olive', 'purple']\n",
        "# colors = [(255, 0, 0), (0, 255, 0), (0, 0, 255), (255, 255, 0), (0, 255, 255), (255, 0, 255), (128, 128, 0), (128, 0, 128)]\n",
        "# æç”»ã‚³ãƒ³ãƒ†ãƒ³ãƒˆã®å–å¾—\n",
        "draw = ImageDraw.Draw(img)\n",
        "\"\"\"\n",
        "ãƒ•ã‚©ãƒ³ãƒˆã®è¨­å®šã€‚Macã ã¨/System/Library/Fontsã«è‰²ã€…ã‚ã‚‹ã®ã§ã“ã“ã‹ã‚‰é¸ã‚“ã ã€‚\n",
        "bboxã ã‘ã®æç”»ã§ã‚ã‚Œã°å¿…è¦ãªã„ã€‚å¿…è¦ãªã„å ´åˆã¯draw.text(font=font)ã®fontéƒ¨åˆ†ã‚’æ¶ˆã™ã€‚\n",
        "ã‚¨ãƒ©ãƒ¼ãŒå‡ºã‚‹å ´åˆã¯ãƒ•ã‚©ãƒ³ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã¸ã®ãƒ•ãƒ«ãƒ‘ã‚¹(/System/Library/Fonts/ãƒ’ãƒ©ã‚®ãƒä¸¸ã‚´ ProN W4.ttc)ã§è¨­å®šã—ã¦ã‚ã’ã‚‹\n",
        "\"\"\"\n",
        "font = ImageFont.truetype('/usr/share/fonts/truetype/liberation/LiberationSans-Regular.ttf', 4000)\n",
        "# ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã®æç”»\n",
        "i=1\n",
        "for bbox, cls in zip(coordinate_bbox, classes):\n",
        "    x1, y1, x2, y2 = map(int, bbox)\n",
        "    #color = colors[int(cls) % len(colors)] ä»Šå›ã¯è‰²ã‚’ç›´æ¥æŒ‡å®šã™ã‚‹ã®ã§ä½¿ã‚ãªã„\n",
        "    color=(255,0,0) # red\n",
        "    # bboxã®æç”»\n",
        "    draw.rectangle([x1, y1, x2, y2], outline=color, width=5)\n",
        "    cls_text = classes_map.get(int(cls))\n",
        "    # æ¤œå‡ºã‚¯ãƒ©ã‚¹åã®æç”»\n",
        "    draw.text((x1, y1 - 50), cls_text+\"#\"+str(i), fill=\"orange\")\n",
        "    print(f\"class: {cls_text}\")\n",
        "    print(f\"x1: {x1}, y1: {y1}, x2: {x2}, y2: {y2}\")\n",
        "    i += 1\n",
        "# ç”»åƒã®ãƒªã‚µã‚¤ã‚º (å¿…è¦ã§ã‚ã‚Œã°)\n",
        "#img = img.resize((640,640))\n",
        "# å‡ºåŠ›å…ˆãƒ•ã‚©ãƒ«ãƒ€ã®ä½œæˆã€‚model.predictã§ä½œæˆã•ã›ã¦ã‚‚OKã€‚\n",
        "directories = ['/content/predict']\n",
        "for directory in directories:\n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "# ç”»åƒã®ä¿å­˜ (å­˜åœ¨ã—ãªã„ãƒ•ã‚©ãƒ«ãƒ€ã ã¨FileNotFoundErrorã«ãªã‚‹ã®ã§æ³¨æ„)\n",
        "img.save('/content/test.png')\n",
        "# ç”»åƒã®è¡¨ç¤º\n",
        "display(DisplayImage(filename='/content/test.png'))"
      ],
      "metadata": {
        "id": "q4mjNJMIMCF5",
        "outputId": "cbcd7860-ec8a-4b04-e688-bd73d531bcf5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "image 1/1 /content/drive/MyDrive/Deep_learning/Olympia_dataset/dataset_uni_for_YOLOv8/dataset_orig/10.JPG: 448x640 1 person, 1 donut, 7.4ms\n",
            "Speed: 2.8ms preprocess, 7.4ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "class: R\n",
            "x1: 4, y1: 5, x2: 2585, y2: 1704\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-516acf7cb4d4>\u001b[0m in \u001b[0;36m<cell line: 37>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mcls_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclasses_map\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;31m# æ¤œå‡ºã‚¯ãƒ©ã‚¹åã®æç”»\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0mdraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls_text\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"#\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"orange\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"class: {cls_text}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"x1: {x1}, y1: {y1}, x2: {x2}, y2: {y2}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'NoneType' and 'str'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classes_map"
      ],
      "metadata": {
        "id": "C6pKCGXWIIch",
        "outputId": "5524c74a-51ed-4c3c-b888-948ad35943ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'person',\n",
              " 1: 'bicycle',\n",
              " 2: 'car',\n",
              " 3: 'motorcycle',\n",
              " 4: 'airplane',\n",
              " 5: 'bus',\n",
              " 6: 'train',\n",
              " 7: 'truck',\n",
              " 8: 'boat',\n",
              " 9: 'traffic light',\n",
              " 10: 'fire hydrant',\n",
              " 11: 'stop sign',\n",
              " 12: 'parking meter',\n",
              " 13: 'bench',\n",
              " 14: 'bird',\n",
              " 15: 'cat',\n",
              " 16: 'dog',\n",
              " 17: 'horse',\n",
              " 18: 'sheep',\n",
              " 19: 'cow',\n",
              " 20: 'elephant',\n",
              " 21: 'bear',\n",
              " 22: 'zebra',\n",
              " 23: 'giraffe',\n",
              " 24: 'backpack',\n",
              " 25: 'umbrella',\n",
              " 26: 'handbag',\n",
              " 27: 'tie',\n",
              " 28: 'suitcase',\n",
              " 29: 'frisbee',\n",
              " 30: 'skis',\n",
              " 31: 'snowboard',\n",
              " 32: 'sports ball',\n",
              " 33: 'kite',\n",
              " 34: 'baseball bat',\n",
              " 35: 'baseball glove',\n",
              " 36: 'skateboard',\n",
              " 37: 'surfboard',\n",
              " 38: 'tennis racket',\n",
              " 39: 'bottle',\n",
              " 40: 'wine glass',\n",
              " 41: 'cup',\n",
              " 42: 'fork',\n",
              " 43: 'knife',\n",
              " 44: 'spoon',\n",
              " 45: 'bowl',\n",
              " 46: 'banana',\n",
              " 47: 'apple',\n",
              " 48: 'sandwich',\n",
              " 49: 'orange',\n",
              " 50: 'broccoli',\n",
              " 51: 'carrot',\n",
              " 52: 'hot dog',\n",
              " 53: 'pizza',\n",
              " 54: 'donut',\n",
              " 55: 'cake',\n",
              " 56: 'chair',\n",
              " 57: 'couch',\n",
              " 58: 'potted plant',\n",
              " 59: 'bed',\n",
              " 60: 'dining table',\n",
              " 61: 'toilet',\n",
              " 62: 'tv',\n",
              " 63: 'laptop',\n",
              " 64: 'mouse',\n",
              " 65: 'remote',\n",
              " 66: 'keyboard',\n",
              " 67: 'cell phone',\n",
              " 68: 'microwave',\n",
              " 69: 'oven',\n",
              " 70: 'toaster',\n",
              " 71: 'sink',\n",
              " 72: 'refrigerator',\n",
              " 73: 'book',\n",
              " 74: 'clock',\n",
              " 75: 'vase',\n",
              " 76: 'scissors',\n",
              " 77: 'teddy bear',\n",
              " 78: 'hair drier',\n",
              " 79: 'toothbrush'}"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results[0].names"
      ],
      "metadata": {
        "id": "szujxTxnwV5B",
        "outputId": "6a43f8cc-dce7-4ea4-eb13-28d9af1563a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'person',\n",
              " 1: 'bicycle',\n",
              " 2: 'car',\n",
              " 3: 'motorcycle',\n",
              " 4: 'airplane',\n",
              " 5: 'bus',\n",
              " 6: 'train',\n",
              " 7: 'truck',\n",
              " 8: 'boat',\n",
              " 9: 'traffic light',\n",
              " 10: 'fire hydrant',\n",
              " 11: 'stop sign',\n",
              " 12: 'parking meter',\n",
              " 13: 'bench',\n",
              " 14: 'bird',\n",
              " 15: 'cat',\n",
              " 16: 'dog',\n",
              " 17: 'horse',\n",
              " 18: 'sheep',\n",
              " 19: 'cow',\n",
              " 20: 'elephant',\n",
              " 21: 'bear',\n",
              " 22: 'zebra',\n",
              " 23: 'giraffe',\n",
              " 24: 'backpack',\n",
              " 25: 'umbrella',\n",
              " 26: 'handbag',\n",
              " 27: 'tie',\n",
              " 28: 'suitcase',\n",
              " 29: 'frisbee',\n",
              " 30: 'skis',\n",
              " 31: 'snowboard',\n",
              " 32: 'sports ball',\n",
              " 33: 'kite',\n",
              " 34: 'baseball bat',\n",
              " 35: 'baseball glove',\n",
              " 36: 'skateboard',\n",
              " 37: 'surfboard',\n",
              " 38: 'tennis racket',\n",
              " 39: 'bottle',\n",
              " 40: 'wine glass',\n",
              " 41: 'cup',\n",
              " 42: 'fork',\n",
              " 43: 'knife',\n",
              " 44: 'spoon',\n",
              " 45: 'bowl',\n",
              " 46: 'banana',\n",
              " 47: 'apple',\n",
              " 48: 'sandwich',\n",
              " 49: 'orange',\n",
              " 50: 'broccoli',\n",
              " 51: 'carrot',\n",
              " 52: 'hot dog',\n",
              " 53: 'pizza',\n",
              " 54: 'donut',\n",
              " 55: 'cake',\n",
              " 56: 'chair',\n",
              " 57: 'couch',\n",
              " 58: 'potted plant',\n",
              " 59: 'bed',\n",
              " 60: 'dining table',\n",
              " 61: 'toilet',\n",
              " 62: 'tv',\n",
              " 63: 'laptop',\n",
              " 64: 'mouse',\n",
              " 65: 'remote',\n",
              " 66: 'keyboard',\n",
              " 67: 'cell phone',\n",
              " 68: 'microwave',\n",
              " 69: 'oven',\n",
              " 70: 'toaster',\n",
              " 71: 'sink',\n",
              " 72: 'refrigerator',\n",
              " 73: 'book',\n",
              " 74: 'clock',\n",
              " 75: 'vase',\n",
              " 76: 'scissors',\n",
              " 77: 'teddy bear',\n",
              " 78: 'hair drier',\n",
              " 79: 'toothbrush'}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rhyAS02tMCIT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Mp0v-saxOElF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Qk3r2PCCOEno"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_N89zEa_OEqG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget /content https://pds.exblog.jp/logo/1/197001/01/18/b043001820221113221721.jpg\n",
        "!wget /content https://plugins-media.makeupar.com/smb/blog/post/2023-06-15/37011ea9-289b-4700-9e61-6a1429128ae6.jpg\n",
        "!wget /content https://www.city.gosen.lg.jp/material/images/group/5/chugatasu.JPG\n",
        "img_path = [\"/content/b043001820221113221721.jpg\", \"37011ea9-289b-4700-9e61-6a1429128ae6.jpg\", \"chugatasu.JPG\"]"
      ],
      "metadata": {
        "id": "GZ1Pi39p4D2I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from ultralytics import YOLO\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from IPython.display import Image as DisplayImage\n",
        "from IPython.display import display\n",
        "import cv2\n",
        "# äº‹å‰å­¦ç¿’æ¸ˆã¿ã®ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿(detectionãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨)\n",
        "model = YOLO('yolov8n.pt')\n",
        "# predictãƒ¢ãƒ¼ãƒ‰ã‚’å®Ÿè¡Œ (çµæœã ã‘æ¬²ã—ã„ã®ã§ã€projectãƒ»nameãƒ»exist_okã¯ãªãã¦ã‚‚OK)\n",
        "results = model.predict(source=img_path[2])\n",
        "# Resultsã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‹ã‚‰æç”»ã«å¿…è¦ãªæƒ…å ±ã‚’å–å¾—\n",
        "coordinate_bbox = results[0].boxes.xyxy #bbox\n",
        "classes=results[0].boxes.cls # æ¤œå‡ºã‚¯ãƒ©ã‚¹\n",
        "classes_map = results[0].names # ã‚¯ãƒ©ã‚¹ç•ªå·ã¨åç§°\n",
        "# ç”»åƒã®èª­ã¿è¾¼ã¿\n",
        "img = Image.open(results[0].path)\n",
        "# è‰²ã®æŒ‡å®š (ã‚¯ãƒ©ã‚¹ã”ã¨ã«ãƒ©ãƒ³ãƒ€ãƒ ã«è‰²ã‚’é¸æŠã™ã‚‹å ´åˆä½¿ã†)\n",
        "# colors = ['red', 'green', 'blue', 'yellow', 'cyan', 'magenta', 'olive', 'purple']\n",
        "# colors = [(255, 0, 0), (0, 255, 0), (0, 0, 255), (255, 255, 0), (0, 255, 255), (255, 0, 255), (128, 128, 0), (128, 0, 128)]\n",
        "# æç”»ã‚³ãƒ³ãƒ†ãƒ³ãƒˆã®å–å¾—\n",
        "draw = ImageDraw.Draw(img)\n",
        "\"\"\"\n",
        "ãƒ•ã‚©ãƒ³ãƒˆã®è¨­å®šã€‚Macã ã¨/System/Library/Fontsã«è‰²ã€…ã‚ã‚‹ã®ã§ã“ã“ã‹ã‚‰é¸ã‚“ã ã€‚\n",
        "bboxã ã‘ã®æç”»ã§ã‚ã‚Œã°å¿…è¦ãªã„ã€‚å¿…è¦ãªã„å ´åˆã¯draw.text(font=font)ã®fontéƒ¨åˆ†ã‚’æ¶ˆã™ã€‚\n",
        "ã‚¨ãƒ©ãƒ¼ãŒå‡ºã‚‹å ´åˆã¯ãƒ•ã‚©ãƒ³ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã¸ã®ãƒ•ãƒ«ãƒ‘ã‚¹(/System/Library/Fonts/ãƒ’ãƒ©ã‚®ãƒä¸¸ã‚´ ProN W4.ttc)ã§è¨­å®šã—ã¦ã‚ã’ã‚‹\n",
        "\"\"\"\n",
        "font = ImageFont.truetype('/usr/share/fonts/truetype/liberation/LiberationSans-Regular.ttf', 4000)\n",
        "# ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã®æç”»\n",
        "i=1\n",
        "for bbox, cls in zip(coordinate_bbox, classes):\n",
        "    x1, y1, x2, y2 = map(int, bbox)\n",
        "    #color = colors[int(cls) % len(colors)] ä»Šå›ã¯è‰²ã‚’ç›´æ¥æŒ‡å®šã™ã‚‹ã®ã§ä½¿ã‚ãªã„\n",
        "    color=(255,0,0) # red\n",
        "    # bboxã®æç”»\n",
        "    draw.rectangle([x1, y1, x2, y2], outline=color, width=5)\n",
        "    cls_text = classes_map.get(int(cls))\n",
        "    # æ¤œå‡ºã‚¯ãƒ©ã‚¹åã®æç”»\n",
        "    draw.text((x1, y1 - 50), cls_text+\"#\"+str(i), fill=\"orange\")\n",
        "    print(f\"class: {cls_text}\")\n",
        "    print(f\"x1: {x1}, y1: {y1}, x2: {x2}, y2: {y2}\")\n",
        "    i += 1\n",
        "# ç”»åƒã®ãƒªã‚µã‚¤ã‚º (å¿…è¦ã§ã‚ã‚Œã°)\n",
        "#img = img.resize((640,640))\n",
        "# å‡ºåŠ›å…ˆãƒ•ã‚©ãƒ«ãƒ€ã®ä½œæˆã€‚model.predictã§ä½œæˆã•ã›ã¦ã‚‚OKã€‚\n",
        "directories = ['/Users/hinomaruc/Desktop/blog/dataset/yolov8/runs/mypredict']\n",
        "for directory in directories:\n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "# ç”»åƒã®ä¿å­˜ (å­˜åœ¨ã—ãªã„ãƒ•ã‚©ãƒ«ãƒ€ã ã¨FileNotFoundErrorã«ãªã‚‹ã®ã§æ³¨æ„)\n",
        "img.save('/Users/hinomaruc/Desktop/blog/dataset/yolov8/runs/mypredict/sample_bbox.png')\n",
        "# ç”»åƒã®è¡¨ç¤º\n",
        "display(DisplayImage(filename='/Users/hinomaruc/Desktop/blog/dataset/yolov8/runs/mypredict/sample_bbox.png'))"
      ],
      "metadata": {
        "id": "2zTw01xTZlu2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "outputId": "9f39e7da-7e8a-4418-9d7f-3c2fda623ad5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt to 'yolov8n.pt'...\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6.23M/6.23M [00:00<00:00, 6.72MB/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-a993d544b0ca>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mYOLO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'yolov8n.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# predictãƒ¢ãƒ¼ãƒ‰ã‚’å®Ÿè¡Œ (çµæœã ã‘æ¬²ã—ã„ã®ã§ã€projectãƒ»nameãƒ»exist_okã¯ãªãã¦ã‚‚OK)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;31m# Resultsã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‹ã‚‰æç”»ã«å¿…è¦ãªæƒ…å ±ã‚’å–å¾—\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mcoordinate_bbox\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxyxy\u001b[0m \u001b[0;31m#bbox\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'img_path' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os\n",
        "from ultralytics import YOLO\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from IPython.display import Image as DisplayImage\n",
        "from IPython.display import display\n",
        "\n",
        "# äº‹å‰å­¦ç¿’æ¸ˆã¿ã®ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿(detectionãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨)\n",
        "model = YOLO('yolov8n.pt')\n",
        "# predictãƒ¢ãƒ¼ãƒ‰ã‚’å®Ÿè¡Œ (çµæœã ã‘æ¬²ã—ã„ã®ã§ã€projectãƒ»nameãƒ»exist_okã¯ãªãã¦ã‚‚OK)\n",
        "results = model.predict(source=img_path[1])\n",
        "# Resultsã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‹ã‚‰æç”»ã«å¿…è¦ãªæƒ…å ±ã‚’å–å¾—\n",
        "coordinate_bbox = results[0].boxes.xyxy #bbox\n",
        "classes=results[0].boxes.cls # æ¤œå‡ºã‚¯ãƒ©ã‚¹\n",
        "classes_map = results[0].names # ã‚¯ãƒ©ã‚¹ç•ªå·ã¨åç§°\n",
        "\n",
        "# Open the image file\n",
        "img_cv2 = cv2.imread(results[0].path)\n",
        "\n",
        "# Set the font scale and thickness\n",
        "font_scale = 3\n",
        "font_thickness = 2\n",
        "\n",
        "# Loop through each bounding box\n",
        "i=1\n",
        "for bbox, cls in zip(coordinate_bbox, classes):\n",
        "    print(bbox)\n",
        "\n",
        "    x1, y1, x2, y2 = map(int, bbox)\n",
        "    color=(0,0,255) # red\n",
        "    # Draw the bounding box\n",
        "    cv2.rectangle(img_cv2, (x1, y1), (x2, y2), color, 5)\n",
        "    cls_text = classes_map.get(int(cls))\n",
        "    # Put the class label text\n",
        "    cv2.putText(img_cv2, cls_text+\"#\"+str(i), (x1, y1 - 50), cv2.FONT_HERSHEY_SIMPLEX, font_scale, color, font_thickness)\n",
        "    i += 1\n",
        "\n",
        "# Save the image\n",
        "cv2.imwrite('/Users/hinomaruc/Desktop/blog/dataset/yolov8/runs/mypredict/sample_bbox.png', img_cv2)\n",
        "\n",
        "\n",
        "#plt.imshow(cv2.cvtColor(img_cv2, cv2.COLOR_BGR2RGB))\n",
        "# Convert the color from BGR to RGB\n",
        "img_rgb = cv2.cvtColor(img_cv2, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Use matplotlib to display the image\n",
        "plt.imshow(img_rgb)\n",
        "\n",
        "# Show the axes\n",
        "plt.axis('on')\n",
        "\n",
        "# Show the image\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "aTBwFQPBet5H"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
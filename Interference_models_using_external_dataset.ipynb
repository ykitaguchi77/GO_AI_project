{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM1RaB0dL1hVcGnMhUEjhTl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykitaguchi77/GO_AI_project/blob/main/Interference_models_using_external_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Interference using pretrained models**"
      ],
      "metadata": {
        "id": "7bnfu3qWA2lX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TF6RLIRqARlg",
        "outputId": "c549eaf0-df7b-4dbf-c1af-9df534ab3aa1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete. Using torch 1.13.1+cu116 _CudaDeviceProperties(name='Tesla T4', major=7, minor=5, total_memory=15101MB, multi_processor_count=40)\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from IPython.display import Image, clear_output\n",
        "import os\n",
        "import shutil\n",
        "import glob\n",
        "\n",
        "clear_output()\n",
        "print('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "#GDriveをマウント\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_folder_path = \"/content/drive/MyDrive/Deep_learning/Olympia_dataset/for_validation\"\n",
        "\n",
        "mobileNet_model_path = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/250px_for_MobileNetV3_training/MobileNetV3_aug2.pth\"\n",
        "YOLOv5_model_path = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training/yolo5n_100epoch.pt\""
      ],
      "metadata": {
        "id": "laxJknZhCVBG"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# specify the image paths\n",
        "\n",
        "# 番号順に並べる\n",
        "# https://dlrecord.hatenablog.com/entry/2020/07/30/230234\n",
        "\n",
        "\n",
        "import re\n",
        "def atoi(text):\n",
        "    return int(text) if text.isdigit() else text\n",
        "def natural_keys(text):\n",
        "    return [ atoi(c) for c in re.split(r'(\\d+)', text) ]\n",
        "\n",
        "grav_list = sorted([i for i in glob.glob(f\"{dataset_folder_path}/treated_640px/*\")], key=natural_keys)\n",
        "cont_list = sorted([i for i in glob.glob(f\"{dataset_folder_path}/control_640px/*\")], key=natural_keys)\n",
        "image_list = grav_list + cont_list\n",
        "label_list = [1]*len(grav_list) + [0]*len(cont_list)\n",
        "\n",
        "image_list\n"
      ],
      "metadata": {
        "id": "y4-J8tuNA8RZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# show sample images\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "root = f\"{dataset_folder_path}/treated_640px\" #画像があるフォルダ。適宜変えてください\n",
        "lsdir = os.listdir(root)\n",
        "\n",
        "imgs = []\n",
        "for l in lsdir:\n",
        "    target = os.path.join(root,l)\n",
        "    img = cv2.imread(target)\n",
        "    img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB) #pyplotで表示するために色変換\n",
        "    imgs.append(img)\n",
        "\n",
        "shownumber = 6 #画像を並べる数\n",
        "showaxis = 1\n",
        "\n",
        "while(showaxis*showaxis < shownumber):\n",
        "    showaxis += 1\n",
        "\n",
        "cnt = 0\n",
        "while(1):\n",
        "    limit = 6\n",
        "    if cnt >= limit:\n",
        "       break\n",
        "    fig,axs = plt.subplots(showaxis,showaxis, figsize=(16.0, 12.0))\n",
        "    ar = axs.ravel()\n",
        "    for i in range(showaxis*showaxis):\n",
        "        ar[i].axis('off')\n",
        "        if i < shownumber:\n",
        "            ar[i].imshow(imgs[cnt])\n",
        "            cnt += 1\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "iACUWQq356Fk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**MobileNetV3 interference**"
      ],
      "metadata": {
        "id": "t4OiMurgHhRV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##########################\n",
        "# Load model \n",
        "##########################\n",
        "!pip install --quiet timm\n",
        "import timm\n",
        "import torch.nn as nn\n",
        "\n",
        "model_ft = timm.create_model('mobilenetv3_large_100', pretrained=True)\n",
        "num_ftrs = model_ft.classifier.in_features\n",
        "model_ft.classifier = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "#ネットワークの読み込み\n",
        "model_ft.load_state_dict(torch.load(mobileNet_model_path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0s6sfExHeeZ",
        "outputId": "55c44594-09ab-4358-8d88-bd0248afd873"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets, models, transforms\n",
        "from PIL import *\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "img_transforms = transforms.Compose([\n",
        "                #Expand2square((0,0,0)),\n",
        "                transforms.Resize(224),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "\n",
        "def image_loader(image_path):\n",
        "    \"\"\"load image, returns cuda tensor\"\"\"\n",
        "    image = Image.open(image_path)\n",
        "    image = img_transforms(image).float()\n",
        "    image = image.unsqueeze(0) \n",
        "    return image.to(device)\n",
        "\n",
        "def my_round(val, digit=0):\n",
        "    p = 10 ** digit\n",
        "    return (val * p * 2 + 1) // 2 / p\n",
        "\n",
        "def interference(image_list):\n",
        "    image_tensor = image_loader(path)\n",
        "\n",
        "    model_ft.to(device)\n",
        "    model_ft.eval()\n",
        "    output = model_ft(image_tensor)\n",
        "    _, pred = torch.max(output, 1) \n",
        "    pred = pred[0].to('cpu').detach().numpy().copy().tolist() \n",
        "\n",
        "    prob = nn.Softmax(dim=1)(output) #calculate probalility\n",
        "    prob = prob[0][1].cpu().detach().numpy().copy().tolist() #probalility of being positive\n",
        "    prob = my_round(prob, 3)\n",
        "\n",
        "    return pred, prob, image_tensor"
      ],
      "metadata": {
        "id": "vYhubvrbRid7"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# multiple image eval\n",
        "path_list, pred_list, prob_list = [], [], []\n",
        "for idx, path in enumerate(image_list, 1):\n",
        "    pred, prob, _ = interference(path)\n",
        "    path_list.append(os.path.basename(path)) \n",
        "    pred_list.append(pred)\n",
        "    prob_list.append(prob)\n",
        "print(label_list)\n",
        "print(pred_list)\n",
        "print(prob_list)\n",
        "\n",
        "df = pd.DataFrame(index=[], columns=[])\n",
        "df[\"path\"] = path_list\n",
        "df[\"label\"] = label_list\n",
        "df[\"pred_MobileNet\"] = pred_list\n",
        "df[\"prob_MobileNet\"] = prob_list\n",
        "df.to_csv('/content/interference.csv', header=True, index=False, encoding = \"utf-8\")\n",
        "\n",
        "pd.set_option('display.max_rows', 400)\n",
        "df\n",
        "\n"
      ],
      "metadata": {
        "id": "kmELszx_XJlb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_rows', None)\n",
        "df"
      ],
      "metadata": {
        "id": "9MpED4MQXKV5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# single image eval\n",
        "num = 5\n",
        "path = image_list[num]\n",
        "label = label_list[num]\n",
        "print(f\"path: {path}\")\n",
        "\n",
        "pred, prob, tensor = interference(path) \n",
        "print(f\"label: {label}, pred: {pred}, prob: {prob}\")\n",
        "print(tensor)"
      ],
      "metadata": {
        "id": "i4ChqsnIXgfj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**YOLOv5n interference**"
      ],
      "metadata": {
        "id": "CupAqAPuTS5w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup YOLOv5\n",
        "%cd /content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training\n",
        "!git clone https://github.com/ultralytics/yolov5\n",
        "%cd yolov5\n",
        "%pip install -qr requirements.txt\n",
        "\n",
        "import torch\n",
        "import utils\n",
        "display = utils.notebook_init()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vNvH_R8sTbKg",
        "outputId": "5739da4e-8fb3-4add-cc7c-a5086213d393"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv5 🚀 v7.0-72-g064365d Python-3.9.16 torch-1.13.1+cu116 CUDA:0 (Tesla T4, 15102MiB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete ✅ (2 CPUs, 12.7 GB RAM, 25.7/166.8 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Inference (folder内全部)\n",
        "# !python detect.py --weights $YOLOv5_model_path --img 640 --conf 0.25 --source {dataset_folder_path}/treated_640px\n"
      ],
      "metadata": {
        "id": "bniMvUF3TbMR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from models.common import DetectMultiBackend\n",
        "#from utils.datasets import IMG_FORMATS, VID_FORMATS, LoadImages, LoadStreams\n",
        "from utils.general import (LOGGER, check_file, check_img_size, check_imshow, check_requirements, colorstr,\n",
        "                           increment_path, non_max_suppression, print_args, strip_optimizer, xyxy2xywh)\n",
        "#from utils.plots import Annotator, colors, save_one_box\n",
        "from utils.torch_utils import select_device, time_sync\n",
        "from utils.augmentations import letterbox #padding\n",
        "\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torchvision import models, transforms\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "#サポートパッチのインポート\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "\n",
        "def interference(img, weight):\n",
        "    device = 'cpu'\n",
        "    device = select_device(device)\n",
        "    model = DetectMultiBackend(weight, device=device, dnn=False)\n",
        "    #stride, names, pt, jit, onnx, engine = model.stride, model.names, model.pt, model.jit, model.onnx, model.engine\n",
        "    #imgsz = check_img_size([640], s=stride)  # check image size\n",
        "\n",
        "    #class_names = {0:\"cont\", 1:\"grav\"}\n",
        "\n",
        "    # transform = transforms.Compose([\n",
        "    #             transforms.Resize(size=(480,640)),\n",
        "    #             transforms.ToTensor(),\n",
        "    #             # transforms.Normalize(\n",
        "    #             #     mean=[0.5, 0.5, 0.5],\n",
        "    #             #     std=[0.5, 0.5, 0.5]\n",
        "    #             #    )\n",
        "    #             ])\n",
        "\n",
        "    img_cv2 = cv2.imread(img) #CV2で開く\n",
        "    img_cv2 = letterbox(img_cv2, (640,640), stride=32, auto=False)[0] #resize, 上下padding (color 114)\n",
        "\n",
        "    #cv2_imshow(img_cv2)\n",
        "\n",
        "    img_cv2 = img_cv2.transpose((2, 0, 1))[::-1]  # HWC to CHW, BGR to RGB\n",
        "    img_cv2 = np.ascontiguousarray(img_cv2)\n",
        "    img_tensor = torch.from_numpy(img_cv2).float()\n",
        "\n",
        "    #img_tensor = transform(img_np)\n",
        "    img_tensor /= 255\n",
        "    #print(img_tensor.shape)\n",
        "\n",
        "    #print(img_tensor)\n",
        "    img_tensor = torch.unsqueeze(img_tensor, 0)  # バッチ対応\n",
        "\n",
        "\n",
        "    pred = model(img_tensor, visualize=False, augment=False)\n",
        "\n",
        "    pred = non_max_suppression(pred, conf_thres=0.25, iou_thres=0.45, classes=None,  max_det=1000)\n",
        "\n",
        "    print(f\"pred: {pred}\")\n",
        "\n",
        "    return pred"
      ],
      "metadata": {
        "id": "Aooz-_mLaLR3"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = image_list\n",
        "img = image_path[102]\n",
        "\n",
        "class_names = {0:\"cont\", 1:\"grav\"}\n",
        "pred = interference(img, YOLOv5_model_path)\n",
        "\n",
        "# output result\n",
        "x1, y1, x2, y2, prob, class_num = torch.round(pred[0][0])\n",
        "\n",
        "# probability\n",
        "prob = pred[0][0][4].item()\n",
        "\n",
        "# class\n",
        "class_name = class_names[pred[0][0][5].item()]\n",
        "\n",
        "print(\"診断は %s、確率は%.1f％です。\" %(class_name, prob*100))\n",
        "\n",
        "img_cv2 = cv2.imread(img) \n",
        "\n",
        "# 横幅が640pxになるようにリサイズ\n",
        "height, width, _ = img_cv2.shape\n",
        "resize_width = 640\n",
        "resize_height = int((height / width) * resize_width)\n",
        "resize_size = (resize_width, resize_height)\n",
        "img_cv2 = cv2.resize(img_cv2, resize_size)\n",
        "\n",
        "# calculate coordinates of the bounding box (640*640にpaddingされている分の座標を足す)\n",
        "img_height, img_width, _ = img_cv2.shape[:3]\n",
        "print(f\"img_height: {img_height}, img_width: {img_width}\")\n",
        "padding_x = (img_height - min(img_width, img_height))/2\n",
        "padding_y = (img_width - min(img_width, img_height))/2\n",
        "x1 = x1 - padding_x\n",
        "y1 = y1 - padding_y\n",
        "x2 = x2 - padding_x\n",
        "y2 = y2 - padding_y\n",
        "print(f\"x1: {x1}, y1: {y1}, x2: {x2}, y2: {y2}\")\n",
        "\n",
        "\n",
        "# draw bounding box\n",
        "cv2.rectangle(img_cv2, (int(x1), int(y1)), (int(x2), int(y2)), (255, 0, 0), 2)\n",
        "\n",
        "# show image\n",
        "cv2_imshow(img_cv2)"
      ],
      "metadata": {
        "id": "9twS6nUkTbOI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_list, prob_list = [], []\n",
        "\n",
        "for img in image_list:\n",
        "    pred = interference(img, YOLOv5_model_path)\n",
        "    # output result\n",
        "    # x1, y1, x2, y2, prob, class_num = torch.round(pred[0][0])\n",
        "\n",
        "    # class\n",
        "    prob = pred[0][0][4].item()\n",
        "    prob_list.append(class_num)\n",
        "    # class\n",
        "    class_num = pred[0][0][5].item()\n",
        "    pred_list.append(class_num)\n",
        "\n",
        "df[\"pred_YOLOv5\"] = pred_list\n",
        "df[\"prob_YOLOv5\"] = prob_list\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEq6-EfVjDXX",
        "outputId": "500b728c-576c-47d6-96d3-82f1c6529446"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv5 🚀 v7.0-72-g064365d Python-3.9.16 torch-1.13.1+cu116 CPU\n",
            "\n",
            "Fusing layers... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred: [tensor([[1.10324e+00, 1.78229e+02, 6.42105e+02, 4.75062e+02, 6.35522e-01, 0.00000e+00]])]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Model summary: 157 layers, 1761871 parameters, 0 gradients, 4.1 GFLOPs\n",
            "YOLOv5 🚀 v7.0-72-g064365d Python-3.9.16 torch-1.13.1+cu116 CPU\n",
            "\n",
            "Fusing layers... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred: [tensor([[  8.05603, 137.93996, 638.26044, 417.41803,   0.92406,   1.00000]])]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Model summary: 157 layers, 1761871 parameters, 0 gradients, 4.1 GFLOPs\n",
            "YOLOv5 🚀 v7.0-72-g064365d Python-3.9.16 torch-1.13.1+cu116 CPU\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 1761871 parameters, 0 gradients, 4.1 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred: [tensor([[  4.08194, 182.75610, 640.09119, 493.26459,   0.91441,   0.00000]])]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv5 🚀 v7.0-72-g064365d Python-3.9.16 torch-1.13.1+cu116 CPU\n",
            "\n",
            "Fusing layers... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred: [tensor([[  1.43250, 212.77280, 630.25757, 496.08511,   0.75823,   0.00000]])]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Model summary: 157 layers, 1761871 parameters, 0 gradients, 4.1 GFLOPs\n",
            "YOLOv5 🚀 v7.0-72-g064365d Python-3.9.16 torch-1.13.1+cu116 CPU\n",
            "\n",
            "Fusing layers... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred: [tensor([[-5.11688e-01,  1.91015e+02,  6.40644e+02,  4.83375e+02,  6.45190e-01,  0.00000e+00]])]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Model summary: 157 layers, 1761871 parameters, 0 gradients, 4.1 GFLOPs\n",
            "YOLOv5 🚀 v7.0-72-g064365d Python-3.9.16 torch-1.13.1+cu116 CPU\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 1761871 parameters, 0 gradients, 4.1 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred: [tensor([[  1.75583, 125.21432, 634.25061, 427.89737,   0.91925,   1.00000]])]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv5 🚀 v7.0-72-g064365d Python-3.9.16 torch-1.13.1+cu116 CPU\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 1761871 parameters, 0 gradients, 4.1 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred: [tensor([[  8.13025, 136.54361, 642.20337, 457.52518,   0.90790,   1.00000]])]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv5 🚀 v7.0-72-g064365d Python-3.9.16 torch-1.13.1+cu116 CPU\n",
            "\n",
            "Fusing layers... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred: [tensor([[  4.16724, 231.13962, 638.42010, 501.87375,   0.80263,   1.00000]])]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Model summary: 157 layers, 1761871 parameters, 0 gradients, 4.1 GFLOPs\n",
            "YOLOv5 🚀 v7.0-72-g064365d Python-3.9.16 torch-1.13.1+cu116 CPU\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**ROC curve**"
      ],
      "metadata": {
        "id": "zBb8ButdWWE1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import roc_curve, auc, confusion_matrix, accuracy_score, recall_score, precision_score, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# 真陽性率（TPR）、偽陽性率（FPR）、しきい値（thresholds）を計算する\n",
        "fpr, tpr, thresholds = roc_curve(df['label'], df['prob'])\n",
        "\n",
        "# AUCスコアを計算する\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "# ROC曲線をプロットする\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (AUC = %0.2f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver operating characteristic')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "cm = confusion_matrix(df['label'], df['pred'])\n",
        "accuracy = accuracy_score(df['label'], df['pred'])\n",
        "sensitivity = recall_score(df['label'], df['pred'])\n",
        "specificity = cm[0,0] / (cm[0,0] + cm[0,1])\n",
        "ppv = precision_score(df['label'], df['pred'])\n",
        "f1 = f1_score(df['label'], df['pred'])\n",
        "\n",
        "print('Confusion Matrix:\\n', cm) # 混同行列\n",
        "print('Accuracy:', accuracy) # 正解率\n",
        "print('Sensitivity:', sensitivity) # 感度\n",
        "print('Specificity:', specificity) # 特異度\n",
        "print('Positive Predictive Value:', ppv) # 陽性的中率\n",
        "print('F1-Score:', f1) # F1スコア"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        },
        "id": "5P0_yZzxWZH3",
        "outputId": "86d5ed3a-7ab9-418c-c2bd-55ac502051de"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            " [[ 74  95]\n",
            " [ 12 157]]\n",
            "Accuracy: 0.6834319526627219\n",
            "Sensitivity: 0.9289940828402367\n",
            "Specificity: 0.4378698224852071\n",
            "Positive Predictive Value: 0.623015873015873\n",
            "F1-Score: 0.7458432304038004\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "deYJXnANWZJt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Output CoreML**"
      ],
      "metadata": {
        "id": "kGUYCKO6pe-i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###########################\n",
        "# Output as CoreML_example\n",
        "###########################\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "import torchvision\n",
        "!pip install --quiet coremltools\n",
        "import coremltools as ct\n",
        "import numpy as np\n",
        "!pip install --quiet timm\n",
        "\n",
        "\n",
        "# Load a pre-trained version of MobileNetV3\n",
        "\n",
        "base_model = timm.create_model('mobilenetv3_large_100', pretrained=True)\n",
        "\n",
        "class TorchClassificationModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(TorchClassificationModel, self).__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            base_model,\n",
        "            nn.Softmax(dim=1)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "\n",
        "# Set the model in evaluation mode\n",
        "torch_model = TorchClassificationModel().eval()\n",
        "\n",
        "# Trace with random data\n",
        "example_input = torch.rand(1, 3, 224, 224) # after test, will get 'size mismatch' error message with size 256x256\n",
        "traced_model = torch.jit.trace(torch_model, example_input)\n",
        "\n",
        "\n",
        "# Download class labels (from a separate file)\n",
        "import urllib\n",
        "label_url = 'https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt'\n",
        "class_labels = urllib.request.urlopen(label_url).read().decode(\"utf-8\").splitlines()\n",
        "class_labels = class_labels[1:] # remove the first class which is background\n",
        "assert len(class_labels) == 1000\n",
        "\n",
        "\n",
        "#Set the image scale and bias for input image preprocessing.\n",
        "scale = 1.0 / (255.0 * 0.226)\n",
        "red_bias = -0.485 / 0.226\n",
        "green_bias = -0.456 / 0.226\n",
        "blue_bias = -0.406 / 0.226\n",
        "\n",
        "image_input = ct.ImageType(name=\"input_1\",\n",
        "                           shape=example_input.shape,\n",
        "                           scale=scale,\n",
        "                           bias=[red_bias, green_bias, blue_bias])\n",
        "\n",
        "# Convert to Core ML using the Unified Conversion API\n",
        "mlmodel = ct.convert(\n",
        "    traced_model,\n",
        "    inputs=[image_input], \n",
        "    classifier_config = ct.ClassifierConfig(class_labels), \n",
        "    compute_units=ct.ComputeUnit.CPU_ONLY,\n",
        ")\n",
        "\n",
        "# Save model\n",
        "mlmodel.save(\"MobileNetV3_pytorch.mlmodel\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EN85pcwkeznp",
        "outputId": "0c982481-601f-41b3-9217-bcf08c6ad63f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |▏                               | 10 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |▍                               | 20 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |▋                               | 30 kB 9.6 MB/s eta 0:00:01\r\u001b[K     |▉                               | 40 kB 5.8 MB/s eta 0:00:01\r\u001b[K     |█                               | 51 kB 5.9 MB/s eta 0:00:01\r\u001b[K     |█▎                              | 61 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 71 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 81 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██                              | 92 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 102 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 112 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 122 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |██▉                             | 133 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |███                             | 143 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 153 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 163 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 174 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |████                            | 184 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 194 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 204 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 215 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 225 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |█████                           | 235 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 245 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 256 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 266 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |██████                          | 276 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 286 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 296 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 307 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 317 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |███████                         | 327 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 337 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 348 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 358 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 368 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |████████                        | 378 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 389 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 399 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 409 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 419 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 430 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 440 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 450 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 460 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 471 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 481 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 491 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 501 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 512 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 522 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 532 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 542 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 552 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 563 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 573 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 583 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 593 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 604 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 614 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 624 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 634 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 645 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 655 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 665 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 675 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 686 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 696 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 706 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 716 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 727 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 737 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 747 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 757 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 768 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 778 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 788 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 798 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 808 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 819 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 829 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 839 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 849 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 860 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 870 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 880 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 890 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 901 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 911 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 921 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 931 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 942 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 952 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 962 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 972 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 983 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 993 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 1.0 MB 6.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 1.0 MB 6.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 1.0 MB 6.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.0 MB 6.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 1.0 MB 6.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 1.1 MB 6.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 1.1 MB 6.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.1 MB 6.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 1.1 MB 6.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 1.1 MB 6.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 1.1 MB 6.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 1.1 MB 6.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.1 MB 6.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 1.1 MB 6.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 1.1 MB 6.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.2 MB 6.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.2 MB 6.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.2 MB 6.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 1.2 MB 6.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 1.2 MB 6.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 1.2 MB 6.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.2 MB 6.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 1.2 MB 6.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 1.2 MB 6.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.2 MB 6.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.3 MB 6.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 1.3 MB 6.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 1.3 MB 6.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 1.3 MB 6.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.3 MB 6.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.3 MB 6.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 1.3 MB 6.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 1.3 MB 6.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 1.3 MB 6.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.4 MB 6.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.4 MB 6.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.4 MB 6.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.4 MB 6.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.4 MB 6.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.4 MB 6.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 1.4 MB 6.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 1.4 MB 6.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.4 MB 6.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.4 MB 6.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.5 MB 6.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.5 MB 6.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.5 MB 6.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.5 MB 6.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.5 MB 6.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.5 MB 6.8 MB/s \n",
            "\u001b[?25h"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:TensorFlow version 2.9.2 has not been tested with coremltools. You may run into unexpected errors. TensorFlow 2.8.0 is the most recent version that has been tested.\n",
            "Converting PyTorch Frontend ==> MIL Ops: 100%|█████████▉| 467/468 [00:00<00:00, 1244.78 ops/s]\n",
            "Running MIL Common passes:   0%|          | 0/38 [00:00<?, ? passes/s]/usr/local/lib/python3.7/dist-packages/coremltools/converters/mil/mil/passes/name_sanitization_utils.py:129: UserWarning: Output, '879', of the source model, has been renamed to 'var_879' in the Core ML model.\n",
            "  warnings.warn(msg.format(var.name, new_name))\n",
            "Running MIL Common passes: 100%|██████████| 38/38 [00:00<00:00, 59.40 passes/s]\n",
            "Running MIL Clean up passes: 100%|██████████| 11/11 [00:00<00:00, 84.66 passes/s]\n",
            "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 665/665 [00:00<00:00, 1466.69 ops/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MzxTtZprVcAv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###########################\n",
        "# Output as CoreML 飛ばして下さい\n",
        "###########################\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "!pip install --quiet coremltools\n",
        "import coremltools as ct\n",
        "\n",
        "# Load a pre-trained version of MobileNetV3\n",
        "class TorchClassificationModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(TorchClassificationModel, self).__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            model_ft,\n",
        "            nn.Softmax(dim=1)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "\n",
        "\n",
        "# Set the model in evaluation mode\n",
        "torch_model = TorchClassificationModel().eval()\n",
        "torch_model = torch_model.to(\"cpu\")\n",
        "\n",
        "\n",
        "# Trace with random data\n",
        "example_input = torch.rand(1, 3, 224, 224) # after test, will get 'size mismatch' error message with size 256x256\n",
        "traced_model = torch.jit.trace(torch_model, example_input)\n",
        "\n",
        "\n",
        "# Download class labels (from a separate file)\n",
        "#import urllib\n",
        "#label_url = 'https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt'\n",
        "#class_labels = urllib.request.urlopen(label_url).read().decode(\"utf-8\").splitlines()\n",
        "class_labels = [\"cont\", \"grav\"]\n",
        "\n",
        "\n",
        "#Set the image scale and bias for input image preprocessing.\n",
        "scale = 1.0 / (255.0 * 0.226)\n",
        "red_bias = -0.485 / 0.226\n",
        "green_bias = -0.456 / 0.226\n",
        "blue_bias = -0.406 / 0.226\n",
        "\n",
        "image_input = ct.ImageType(name=\"input_1\",\n",
        "                           shape=example_input.shape,\n",
        "                           scale=scale,\n",
        "                           bias=[red_bias, green_bias, blue_bias])\n",
        "\n",
        "# Convert to Core ML using the Unified Conversion API\n",
        "mlmodel = ct.convert(\n",
        "    traced_model,\n",
        "    inputs=[image_input], \n",
        "    classifier_config = ct.ClassifierConfig(class_labels), \n",
        "    compute_units=ct.ComputeUnit.CPU_ONLY,\n",
        ")\n",
        "\n",
        "\n",
        "# # Convert to Core ML using the Unified Conversion API\n",
        "# mlmodel = ct.convert(\n",
        "#     traced_model,\n",
        "#     inputs=[ct.ImageType(name=\"input_1\", shape=example_input.shape)], #name \"input_1\" is used in 'quickstart'\n",
        "#     classifier_config = ct.ClassifierConfig(class_labels) # provide only if step 2 was performed\n",
        "# )\n",
        "\n",
        "# Save model\n",
        "mlmodel.save(\"/content/gravcont_mobilenetv3.mlmodel\")\n"
      ],
      "metadata": {
        "id": "nggE6m1ah8G0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1da4890-761a-48ae-b83f-df7c1e9e8727"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Converting PyTorch Frontend ==> MIL Ops: 100%|█████████▉| 467/468 [00:00<00:00, 2482.53 ops/s]\n",
            "Running MIL Common passes: 100%|██████████| 38/38 [00:00<00:00, 60.42 passes/s]\n",
            "Running MIL Clean up passes: 100%|██████████| 11/11 [00:00<00:00, 83.79 passes/s]\n",
            "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 665/665 [00:00<00:00, 1744.69 ops/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "################################\n",
        "### Output as CoreML (Tensor type) ###\n",
        "################################\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "!pip install --quiet coremltools\n",
        "import coremltools as ct\n",
        "\n",
        "# Load a pre-trained version of MobileNetV3\n",
        "class TorchClassificationModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(TorchClassificationModel, self).__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            model_ft,\n",
        "            nn.Softmax(dim=1)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "\n",
        "\n",
        "# Set the model in evaluation mode\n",
        "torch_model = TorchClassificationModel().eval()\n",
        "torch_model = torch_model.to(\"cpu\")\n",
        "\n",
        "\n",
        "# Trace with random data\n",
        "example_input = torch.rand(1, 3, 224, 224) # after test, will get 'size mismatch' error message with size 256x256\n",
        "traced_model = torch.jit.trace(torch_model, example_input)\n",
        "\n",
        "\n",
        "# Download class labels (from a separate file)\n",
        "#import urllib\n",
        "#label_url = 'https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt'\n",
        "#class_labels = urllib.request.urlopen(label_url).read().decode(\"utf-8\").splitlines()\n",
        "class_labels = [\"cont\", \"grav\"]\n",
        "\n",
        "# Convert to Core ML using the Unified Conversion API\n",
        "mlmodel = ct.convert(\n",
        "    traced_model,\n",
        "    inputs=[ct.TensorType(name=\"input_1\", shape=example_input.shape)], #name \"input_1\" is used in 'quickstart'\n",
        "    classifier_config = ct.ClassifierConfig(class_labels) # provide only if step 2 was performed\n",
        ")\n",
        "\n",
        "# Save model\n",
        "mlmodel.save(\"/content/gravcont_mobilenetv3.mlmodel\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndvCOs4aGQ18",
        "outputId": "a4ef679d-adf7-4799-9993-ecf8bfff7f82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Converting PyTorch Frontend ==> MIL Ops: 100%|█████████▉| 467/468 [00:00<00:00, 2451.94 ops/s]\n",
            "Running MIL Common passes:   0%|          | 0/38 [00:00<?, ? passes/s]/usr/local/lib/python3.7/dist-packages/coremltools/converters/mil/mil/passes/name_sanitization_utils.py:129: UserWarning: Output, '879', of the source model, has been renamed to 'var_879' in the Core ML model.\n",
            "  warnings.warn(msg.format(var.name, new_name))\n",
            "Running MIL Common passes: 100%|██████████| 38/38 [00:00<00:00, 60.45 passes/s]\n",
            "Running MIL Clean up passes: 100%|██████████| 11/11 [00:00<00:00, 85.48 passes/s]\n",
            "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 665/665 [00:00<00:00, 1717.72 ops/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Interference on CoreML model**"
      ],
      "metadata": {
        "id": "a8hqka6ery11"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This script can be used in Mac only\n",
        "\n",
        "##https://gist.github.com/ozgurshn/85cf74558d82c831827e12f015f752a1\n",
        "##https://github.com/apple/coremltools/blob/master/examples/APIExamples.md\n",
        "import coremltools\n",
        "import numpy as np\n",
        "import PIL.Image\n",
        "\n",
        "# load a model whose input type is \"Image\"\n",
        "model = coremltools.models.MLModel('/content/gravcont_mobilenetv3.mlmodel')\n",
        "\n",
        "Height = 224  # use the correct input image height\n",
        "Width = 224  # use the correct input image width\n",
        "\n",
        "\n",
        "# Scenario 1: load an image from disk\n",
        "def load_image(path, resize_to=None):\n",
        "    # resize_to: (Width, Height)\n",
        "    img = PIL.Image.open(path)\n",
        "    if resize_to is not None:\n",
        "        img = img.resize(resize_to, PIL.Image.ANTIALIAS)\n",
        "    img_np = np.array(img).astype(np.float32)\n",
        "    return img_np, img\n",
        "\n",
        "\n",
        "# load the image and resize using PIL utilities\n",
        "_, img = load_image('/content/drive/MyDrive/Deep_learning/GO_extended_dataset/GO_newPatient_250px/スライド1.jpeg', resize_to=(Width, Height))\n",
        "out_dict = model.predict({'image': img})\n",
        "\n",
        "# Scenario 2: load an image from a numpy array\n",
        "shape = (Height, Width, 3)  # height x width x RGB\n",
        "data = np.zeros(shape, dtype=np.uint8)\n",
        "# manipulate numpy data\n",
        "pil_img = PIL.Image.fromarray(data)\n",
        "out_dict = model.predict({'image': pil_img})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "mlesVk5aQln-",
        "outputId": "2fe8cb94-f9c7-457d-e587-080f18fac2ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "Exception",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-c0ccb8862f10>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# load the image and resize using PIL utilities\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Deep_learning/GO_extended_dataset/GO_newPatient_250px/スライド1.jpeg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresize_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHeight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mout_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m# Scenario 2: load an image from a numpy array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/coremltools/models/model.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    522\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0m_macos_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m13\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m                 raise Exception(\n\u001b[0;32m--> 524\u001b[0;31m                     \u001b[0;34m\"Model prediction is only supported on macOS version 10.13 or later.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    525\u001b[0m                 )\n\u001b[1;32m    526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mException\u001b[0m: Model prediction is only supported on macOS version 10.13 or later."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Interference without Mac**"
      ],
      "metadata": {
        "id": "UMIWSpNBr8A7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#https://tvm.apache.org/docs/how_to/compile_models/from_coreml.html\n",
        "!pip install --quiet apache-tvm\n",
        "!pip install --quiet coremltools\n",
        "import tvm\n",
        "from tvm import te\n",
        "import tvm.relay as relay\n",
        "from tvm.contrib.download import download_testdata\n",
        "import coremltools as cm\n",
        "import numpy as np\n",
        "from PIL import Image"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dK8mOh84o3Ih",
        "outputId": "aee9507e-41fc-4c37-828d-96b2ee08006c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 42.8 MB 1.2 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Load the model**"
      ],
      "metadata": {
        "id": "5S-9HAe7qjC1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_url = \"https://docs-assets.developer.apple.com/coreml/models/MobileNet.mlmodel\"\n",
        "model_file = \"mobilenet.mlmodel\"\n",
        "model_path = download_testdata(model_url, model_file, module=\"coreml\")\n",
        "# Now you have mobilenet.mlmodel on disk\n",
        "mlmodel = cm.models.MLModel(model_path)"
      ],
      "metadata": {
        "id": "1k6jpavuqFHs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Load the test image**"
      ],
      "metadata": {
        "id": "hEI_hbRbqJdF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_url = \"https://github.com/dmlc/mxnet.js/blob/main/data/cat.png?raw=true\"\n",
        "img_path = download_testdata(img_url, \"cat.png\", module=\"data\")\n",
        "img = Image.open(img_path).resize((224, 224))\n",
        "# Mobilenet.mlmodel's input is BGR format\n",
        "img_bgr = np.array(img)[:, :, ::-1]\n",
        "x = np.transpose(img_bgr, (2, 0, 1))[np.newaxis, :]"
      ],
      "metadata": {
        "id": "kCriDoPpqfxM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Compile model on relay**"
      ],
      "metadata": {
        "id": "_uTYH_-prJ5d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target = \"llvm\"\n",
        "shape_dict = {\"image\": x.shape}\n",
        "\n",
        "# Parse CoreML model and convert into Relay computation graph\n",
        "mod, params = relay.frontend.from_coreml(mlmodel, shape_dict)\n",
        "\n",
        "with tvm.transform.PassContext(opt_level=3):\n",
        "    lib = relay.build(mod, target, params=params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kD584_4lqPGX",
        "outputId": "385a912a-3d2b-44c8-85e7-692141e2d62e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tvm/driver/build_module.py:268: UserWarning: target_host parameter is going to be deprecated. Please pass in tvm.target.Target(target, host=target_host) instead.\n",
            "  \"target_host parameter is going to be deprecated. \"\n",
            "WARNING:autotvm:One or more operators have not been tuned. Please tune your model for better performance. Use DEBUG logging level to see more details.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Execute on TVM (これはサンプルの通り)\n",
        "from tvm.contrib import graph_executor\n",
        "\n",
        "dev = tvm.cpu(0)\n",
        "dtype = \"float32\"\n",
        "m = graph_executor.GraphModule(lib[\"default\"](dev))\n",
        "# set inputs\n",
        "m.set_input(\"image\", tvm.nd.array(x.astype(dtype)))\n",
        "# execute\n",
        "m.run()\n",
        "# get outputs\n",
        "tvm_output = m.get_output(0)\n",
        "top1 = np.argmax(tvm_output.numpy()[0])"
      ],
      "metadata": {
        "id": "eEVnsfV8rU5_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Look up system name**"
      ],
      "metadata": {
        "id": "10OvE25urm0C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "synset_url = \"\".join(\n",
        "    [\n",
        "        \"https://gist.githubusercontent.com/zhreshold/\",\n",
        "        \"4d0b62f3d01426887599d4f7ede23ee5/raw/\",\n",
        "        \"596b27d23537e5a1b5751d2b0481ef172f58b539/\",\n",
        "        \"imagenet1000_clsid_to_human.txt\",\n",
        "    ]\n",
        ")\n",
        "synset_name = \"imagenet1000_clsid_to_human.txt\"\n",
        "synset_path = download_testdata(synset_url, synset_name, module=\"data\")\n",
        "with open(synset_path) as f:\n",
        "    synset = eval(f.read())\n",
        "# You should see the following result: Top-1 id 282 class name tiger cat\n",
        "print(\"Top-1 id\", top1, \"class name\", synset[top1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNZsGci-rhPY",
        "outputId": "e1ac8a1c-d2bd-497c-a63b-c5d7e2cac521"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top-1 id 282 class name tiger cat\n"
          ]
        }
      ]
    }
  ]
}